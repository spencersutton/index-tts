# pyright: reportAny=false, reportExplicitAny=false, reportUnknownParameterType=false, reportMissingParameterType=false
"""
This type stub file was generated by pyright.
"""

import torch
import torch.nn as nn

from .env import AttrDict

class DiscriminatorP(torch.nn.Module):
    def __init__(
        self, h: AttrDict, period: list[int], kernel_size: int = ..., stride: int = ..., use_spectral_norm: bool = ...
    ) -> None: ...
    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, list[torch.Tensor]]: ...

class MultiPeriodDiscriminator(torch.nn.Module):
    def __init__(self, h: AttrDict) -> None: ...
    def forward(
        self, y: torch.Tensor, y_hat: torch.Tensor
    ) -> tuple[
        list[torch.Tensor],
        list[torch.Tensor],
        list[list[torch.Tensor]],
        list[list[torch.Tensor]],
    ]: ...

class DiscriminatorR(nn.Module):
    def __init__(self, cfg: AttrDict, resolution: list[list[int]]) -> None: ...
    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, list[torch.Tensor]]: ...
    def spectrogram(self, x: torch.Tensor) -> torch.Tensor: ...

class MultiResolutionDiscriminator(nn.Module):
    def __init__(self, cfg, debug=...) -> None: ...
    def forward(
        self, y: torch.Tensor, y_hat: torch.Tensor
    ) -> tuple[
        list[torch.Tensor],
        list[torch.Tensor],
        list[list[torch.Tensor]],
        list[list[torch.Tensor]],
    ]: ...

class DiscriminatorB(nn.Module):
    def __init__(
        self,
        window_length: int,
        channels: int = ...,
        hop_factor: float = ...,
        bands: tuple[tuple[float, float], ...] = ...,
    ) -> None: ...
    def spectrogram(self, x: torch.Tensor) -> list[torch.Tensor]: ...
    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, list[torch.Tensor]]: ...

class MultiBandDiscriminator(nn.Module):
    def __init__(self, h) -> None:
        """
        Multi-band multi-scale STFT discriminator, with the architecture based on https://github.com/descriptinc/descript-audio-codec.
        and the modified code adapted from https://github.com/gemelo-ai/vocos.
        """

    def forward(
        self, y: torch.Tensor, y_hat: torch.Tensor
    ) -> tuple[
        list[torch.Tensor],
        list[torch.Tensor],
        list[list[torch.Tensor]],
        list[list[torch.Tensor]],
    ]: ...

class DiscriminatorCQT(nn.Module):
    def __init__(self, cfg: AttrDict, hop_length: int, n_octaves: int, bins_per_octave: int) -> None: ...
    def get_2d_padding(self, kernel_size: tuple[int, int], dilation: tuple[int, int] = ...) -> tuple[int, int]: ...
    def forward(self, x: torch.tensor) -> tuple[torch.Tensor, list[torch.Tensor]]: ...

class MultiScaleSubbandCQTDiscriminator(nn.Module):
    def __init__(self, cfg: AttrDict) -> None: ...
    def forward(
        self, y: torch.Tensor, y_hat: torch.Tensor
    ) -> tuple[
        list[torch.Tensor],
        list[torch.Tensor],
        list[list[torch.Tensor]],
        list[list[torch.Tensor]],
    ]: ...

class CombinedDiscriminator(nn.Module):
    """
    Wrapper of chaining multiple discrimiantor architectures.
    Example: combine mbd and cqtd as a single class
    """
    def __init__(self, list_discriminator: list[nn.Module]) -> None: ...
    def forward(
        self, y: torch.Tensor, y_hat: torch.Tensor
    ) -> tuple[
        list[torch.Tensor],
        list[torch.Tensor],
        list[list[torch.Tensor]],
        list[list[torch.Tensor]],
    ]: ...
