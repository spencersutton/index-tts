import torch.nn as nn
from audiotools import ml

def WNConv1d(*args, **kwargs):  # -> Conv1d | Sequential:
    ...
def WNConv2d(*args, **kwargs):  # -> Conv2d | Sequential:
    ...

class MPD(nn.Module):
    def __init__(self, period) -> None: ...
    def pad_to_period(self, x):  # -> Tensor:
        ...
    def forward(self, x):  # -> list[Any]:
        ...

class MSD(nn.Module):
    def __init__(self, rate: int = ..., sample_rate: int = ...) -> None: ...
    def forward(self, x):  # -> list[Any]:
        ...

BANDS = ...

class MRD(nn.Module):
    def __init__(
        self,
        window_length: int,
        hop_factor: float = ...,
        sample_rate: int = ...,
        bands: list = ...,
    ) -> None: ...
    def spectrogram(self, x):  # -> list[Tensor]:
        ...
    def forward(self, x):  # -> list[Any]:
        ...

class Discriminator(ml.BaseModel):
    def __init__(
        self,
        rates: list = ...,
        periods: list = ...,
        fft_sizes: list = ...,
        sample_rate: int = ...,
        bands: list = ...,
    ) -> None: ...
    def preprocess(self, y): ...
    def forward(self, x):  # -> list[Any]:
        ...

if __name__ == "__main__":
    disc = ...
    x = ...
    results = ...
