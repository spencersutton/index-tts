"""
This type stub file was generated by pyright.
"""

import httpx
from gradio import components
from huggingface_hub import ImageClassificationOutputElement, InferenceClient

"""Utility function for gradio/external.py, designed for internal use."""

def get_model_info(model_name, token=...):  # -> tuple[str | None, List[str] | None]:
    ...
def get_tabular_examples(model_name: str) -> dict[str, list[float]]: ...
def cols_to_rows(example_data: dict[str, list[float | str] | None]) -> tuple[list[str], list[list[float]]]: ...
def rows_to_cols(incoming_data: dict) -> dict[str, dict[str, dict[str, list[str]]]]: ...
def postprocess_label(scores: list[ImageClassificationOutputElement]) -> dict: ...
def postprocess_mask_tokens(scores: list[dict[str, str | float]]) -> dict: ...
def postprocess_question_answering(answer: dict) -> tuple[str, dict]: ...
def postprocess_visual_question_answering(scores: list[dict[str, str | float]]) -> dict: ...
def zero_shot_classification_wrapper(
    client: InferenceClient,
):  # -> Callable[..., List[ZeroShotClassificationOutputElement]]:
    ...
def sentence_similarity_wrapper(client: InferenceClient):  # -> Callable[..., List[float]]:
    ...
def text_generation_wrapper(client: InferenceClient):  # -> Callable[..., str]:
    ...
def conversational_wrapper(client: InferenceClient):  # -> Callable[..., Generator[str, Any, None]]:
    ...
def encode_to_base64(r: httpx.Response) -> str: ...
def format_ner_list(
    input_string: str, ner_groups: list[dict[str, str | int]]
):  # -> list[tuple[str, None]] | list[Any]:
    ...
def token_classification_wrapper(client: InferenceClient):  # -> Callable[..., list[tuple[str, None]] | list[Any]]:
    ...
def object_detection_wrapper(
    client: InferenceClient,
):  # -> Callable[..., tuple[str, list[tuple[tuple[Any, Any, Any, Any], Any]]]]:
    ...
def image_text_to_text_wrapper(client: InferenceClient):  # -> Callable[..., str | None]:
    ...
def chatbot_preprocess(text, state):  # -> tuple[Any, list[Any], list[Any]] | tuple[Any, Any, Any]:
    ...
def chatbot_postprocess(response):  # -> tuple[list[tuple[Any, Any]], Any]:
    ...
def tabular_wrapper(client: InferenceClient, pipeline: str):  # -> Callable[..., List[str] | List[float]]:
    ...
def streamline_spaces_interface(config: dict) -> dict:
    """Streamlines the interface config dictionary to remove unnecessary keys."""
    ...

def handle_hf_error(e: Exception): ...
def create_endpoint_fn(
    endpoint_path: str, endpoint_method: str, endpoint_operation: dict, base_url: str, auth_token: str | None = ...
):  # -> Callable[..., Any | dict[str, str | int] | str]:
    ...
def component_from_parameter_schema(param_info: dict) -> components.Component: ...
def resolve_schema_ref(schema: dict, spec: dict) -> dict:
    """Resolve schema references in OpenAPI spec."""
    ...

def component_from_request_body_schema(request_body: dict, spec: dict) -> components.Component | None:
    """Create a Gradio component from an OpenAPI request body schema."""
    ...

def method_box(method: str) -> str: ...
