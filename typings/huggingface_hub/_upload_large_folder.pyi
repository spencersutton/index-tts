import enum
from pathlib import Path

from ._commit_api import CommitOperationAdd
from ._local_folder import LocalUploadFileMetadata, LocalUploadFilePaths
from .hf_api import HfApi

logger = ...
WAITING_TIME_IF_NO_TASKS = ...
MAX_NB_FILES_FETCH_UPLOAD_MODE = ...
COMMIT_SIZE_SCALE: list[int] = ...
UPLOAD_BATCH_SIZE_XET = ...
UPLOAD_BATCH_SIZE_LFS = ...
MAX_FILES_PER_REPO = ...
MAX_FILES_PER_FOLDER = ...
MAX_FILE_SIZE_GB = ...
RECOMMENDED_FILE_SIZE_GB = ...

def upload_large_folder_internal(
    api: HfApi,
    repo_id: str,
    folder_path: str | Path,
    *,
    repo_type: str,
    revision: str | None = ...,
    private: bool | None = ...,
    allow_patterns: list[str] | str | None = ...,
    ignore_patterns: list[str] | str | None = ...,
    num_workers: int | None = ...,
    print_report: bool = ...,
    print_report_every: int = ...,
):  # -> None:
    ...

class WorkerJob(enum.Enum):
    SHA256 = ...
    GET_UPLOAD_MODE = ...
    PREUPLOAD_LFS = ...
    COMMIT = ...
    WAIT = ...

type JOB_ITEM_T = tuple[LocalUploadFilePaths, LocalUploadFileMetadata]

class LargeUploadStatus:
    def __init__(self, items: list[JOB_ITEM_T], upload_batch_size: int = ...) -> None: ...
    def target_chunk(self) -> int: ...
    def update_chunk(self, success: bool, nb_items: int, duration: float) -> None: ...
    def current_report(self) -> str: ...
    def is_done(self) -> bool: ...

class HackyCommitOperationAdd(CommitOperationAdd):
    def __post_init__(self) -> None: ...
