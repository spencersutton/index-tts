import torch
from typing import Any, Generic, TypeVar, overload
from torch._C._distributed_c10d import Store

_DEFAULT_INIT_METHOD: str
_DEFAULT_NUM_WORKER_THREADS: int
_UNSET_RPC_TIMEOUT: float
_DEFAULT_RPC_TIMEOUT_SEC: float
_T = TypeVar("_T")

class RpcBackendOptions:
    rpc_timeout: float
    init_method: str
    def __init__(self, rpc_timeout: float = ..., init_method: str = ...) -> None: ...

class WorkerInfo:
    def __init__(self, name: str, worker_id: int) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def id(self) -> int: ...
    def __eq__(self, other: object) -> bool: ...

class RpcAgent:
    def join(self, shutdown: bool = ..., timeout: float = ...): ...
    def sync(self): ...
    def shutdown(self): ...
    @overload
    def get_worker_info(self) -> WorkerInfo: ...
    @overload
    def get_worker_info(self, workerName: str) -> WorkerInfo: ...
    def get_worker_infos(self) -> list[WorkerInfo]: ...
    def get_debug_info(self) -> dict[str, str]: ...
    def get_metrics(self) -> dict[str, str]: ...

class PyRRef(Generic[_T]):
    def __init__(self, value: _T, type_hint: Any = ...) -> None: ...
    def is_owner(self) -> bool: ...
    def confirmed_by_owner(self) -> bool: ...
    def owner(self) -> WorkerInfo: ...
    def owner_name(self) -> str: ...
    def to_here(self, timeout: float = ...) -> _T: ...
    def local_value(self) -> Any: ...
    def rpc_sync(self, timeout: float = ...) -> Any: ...
    def rpc_async(self, timeout: float = ...) -> Any: ...
    def remote(self, timeout: float = ...) -> Any: ...

class _TensorPipeRpcBackendOptionsBase(RpcBackendOptions):
    num_worker_threads: int
    device_maps: dict[str, dict[torch.device, torch.device]]
    devices: list[torch.device]
    def __init__(
        self,
        num_worker_threads: int,
        _transports: list | None,
        _channels: list | None,
        rpc_timeout: float = ...,
        init_method: str = ...,
        device_maps: dict[str, dict[torch.device, torch.device]] = ...,
        devices: list[torch.device] = ...,
    ) -> None: ...

class TensorPipeAgent(RpcAgent):
    def __init__(
        self,
        store: Store,
        name: str,
        worker_id: int,
        world_size: int | None,
        opts: _TensorPipeRpcBackendOptionsBase,
        reverse_device_maps: dict[str, dict[torch.device, torch.device]],
        devices: list[torch.device],
    ) -> None: ...
    def join(self, shutdown: bool = ..., timeout: float = ...): ...
    def shutdown(self): ...
    @overload
    def get_worker_info(self) -> WorkerInfo: ...
    @overload
    def get_worker_info(self, workerName: str) -> WorkerInfo: ...
    @overload
    def get_worker_info(self, id: int) -> WorkerInfo: ...
    def get_worker_infos(self) -> list[WorkerInfo]: ...
    @property
    def is_static_group(self) -> bool: ...
    @property
    def store(self) -> Store: ...

def get_rpc_timeout() -> float: ...
def enable_gil_profiling(flag: bool): ...

class RemoteProfilerManager:
    @staticmethod
    def set_current_profiling_key(key: str): ...
