import torch
from collections.abc import Sequence
from typing import Any, Callable, Optional, TextIO, Union
from torch._dynamo.symbolic_convert import InstructionTranslatorBase
from torch._dynamo.variables.base import VariableTracker
from torch._subclasses.fake_tensor import FakeTensor

"""
This module provides the public comptime interface to TorchDynamo, enabling users to execute
arbitrary Python code during symbolic evaluation of their programs.

The comptime interface allows inspection and modification of TorchDynamo's compilation
process while it is running. This can be useful for:

- Debugging compilation issues
- Inspecting intermediate state
- Adding custom guards or graph breaks
- Analyzing symbolic shapes and values

Example usage:

    import torch
    from torch._dynamo.comptime import comptime

    def my_model(x):
        # Print the compile-time known information about x
        comptime.print(x)

        # Print the current FX graph being constructed
        comptime.print_graph()

        # Force a value to be treated as static
        if comptime(lambda ctx: ctx.get_local("x").is_dynamic()):
            comptime.force_static(x)

        # Add a manual graph break
        comptime.graph_break()

Note: While this API provides significant flexibility, it intentionally avoids
exposing internal implementation details of TorchDynamo to maintain compatibility
across versions.
"""

class ComptimeVar:
    def __init__(self, v: VariableTracker) -> None: ...
    def as_proxy(self) -> Union[VariableTracker, Sequence[VariableTracker]]: ...
    def is_proxy(self) -> bool: ...
    def as_fake(self) -> Union[FakeTensor, torch.SymInt]: ...
    def size(self, dim: Optional[int] = ...) -> Union[int, torch.SymInt]: ...
    def python_type(self) -> type: ...
    def as_python_constant(self) -> Any: ...
    def is_python_constant(self) -> bool: ...
    def is_dynamic(self) -> bool: ...
    def force_static(self) -> None: ...

class ComptimeContext:
    def __init__(self, tx: InstructionTranslatorBase) -> None: ...
    def get_local(self, name: str, *, stacklevel: int = ...) -> ComptimeVar: ...
    def graph_break(self, msg: str = ...) -> None: ...
    def graph(self) -> torch.fx.Graph: ...
    def assert_static(self, val: ComptimeVar) -> None: ...
    def print_graph(self, *, verbose: bool = ..., file: Optional[TextIO] = ...) -> None: ...
    def parent(self) -> ComptimeContext: ...
    def print(self, val: Any, *, file: Optional[TextIO] = ...) -> None: ...
    def print_disas(self, *, file: Optional[TextIO] = ..., stacklevel: int = ...) -> None: ...
    def print_value_stack(self, *, file: Optional[TextIO] = ..., stacklevel: int = ...) -> None: ...
    def print_locals(self, *, file: Optional[TextIO] = ..., stacklevel: int = ...) -> None: ...
    def print_bt(self, *, file: Optional[TextIO] = ..., stacklevel: int = ...) -> None: ...
    def print_guards(self, *, file: Optional[TextIO] = ...) -> None: ...
    def sleep(self, sec: float) -> None: ...

class _Comptime:
    @staticmethod
    def __call__(fn: Callable[[ComptimeContext], Any], fallback_fn: Callable[[], Any] = ...) -> Any: ...
    @staticmethod
    def graph_break() -> None: ...
    @staticmethod
    def print(e: Any) -> None: ...
    @staticmethod
    def print_graph() -> None: ...
    @staticmethod
    def print_disas(*, stacklevel: int = ...) -> None: ...
    @staticmethod
    def print_value_stack(*, stacklevel: int = ...) -> None: ...
    @staticmethod
    def print_value_stack_and_return(e: Any, *, stacklevel: int = ...) -> Any: ...
    @staticmethod
    def print_locals(*, stacklevel: int = ...) -> None: ...
    @staticmethod
    def print_bt(*, stacklevel: int = ...) -> None: ...
    @staticmethod
    def print_guards() -> None: ...
    @staticmethod
    def assert_static(val: Any) -> None: ...
    @staticmethod
    def force_static(val: Any) -> None: ...
    @staticmethod
    def breakpoint() -> None: ...
    @staticmethod
    def sleep(sec: float) -> None: ...

comptime = ...
