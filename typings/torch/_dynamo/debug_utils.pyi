import torch
from typing import Any, Optional, TYPE_CHECKING, TypeVar
from collections.abc import Callable
from torch import Tensor
from collections.abc import Sequence
from torch.hub import tqdm
from torch.storage import UntypedStorage

"""
Debug utilities for TorchDynamo compilation and execution.

This module provides various debugging tools and utilities for TorchDynamo, including:

- Minification support for reducing test cases while preserving bugs
- Input/output handling via InputReader and InputWriter for reproducible testing
- Accuracy checking between original and compiled models
- Neural network module string conversion via NNModuleToString
- Profiling tools and system information collection
- Buck build system integration for Meta-internal testing

Key classes:
- InputReader/InputWriter: Handle serialization of model inputs/outputs
- NNModuleToString: Converts nn.Modules to string representations
- BuckTargetWriter: Manages Buck build system integration
"""
if TYPE_CHECKING: ...
log = ...
T = TypeVar("T")
inductor_config = ...
use_buck = ...
if use_buck: ...
extra_deps = ...
extra_imports = ...
cur_target = ...
if use_buck:
    extra_deps = ...
    cur_target = ...
    extra_imports = ...
BUCK_CMD_PREFIX = ...

class BuckTargetWriter:
    def __init__(self, filename: str) -> None: ...
    def build(self) -> str: ...
    def write(self, print_msg: bool = ...) -> list[str]: ...

def minifier_dir() -> str: ...

MAX_CONSTANT_NUMEL_INLINE = ...

class NNModuleToString:
    safe_reprs = ...
    @staticmethod
    def can_convert_to_string(gm: torch.fx.GraphModule) -> bool: ...
    @staticmethod
    def convert(gm: torch.fx.GraphModule) -> str: ...

def generate_env_vars_string(*, stable_output: bool = ...) -> str: ...
def generate_config_string(*, stable_output: bool = ...) -> str: ...
def get_minifier_repro_path() -> str: ...
def helper_for_dump_minify(contents: str) -> None: ...

class AccuracyError(Exception): ...

def clone_inputs_retaining_gradness(example_inputs: Sequence[Any]) -> list[Any]: ...
def run_fwd_maybe_bwd(
    gm: torch.fx.GraphModule, args: Sequence[Any], only_fwd: bool = ..., disable_clone: bool = ...
) -> Any: ...
def same_two_models(
    gm: torch.fx.GraphModule,
    opt_gm: torch.fx.GraphModule,
    example_inputs: Sequence[Any],
    only_fwd: bool = ...,
    *,
    require_fp64: bool = ...,
    ignore_non_fp: bool = ...,
) -> bool: ...
def cast_dtype_args_to_fp64(model: torch.fx.GraphModule) -> torch.fx.GraphModule: ...
def cast_to(
    dtype: torch.dtype, model: torch.fx.GraphModule, inputs: list[Any]
) -> tuple[torch.fx.GraphModule, list[Any]]: ...
def cast_to_fp64(model: torch.fx.GraphModule, inputs: list[Any]) -> tuple[torch.fx.GraphModule, list[Any]]: ...
def backend_accuracy_fails(
    gm: torch.fx.GraphModule,
    example_inputs: Sequence[Any],
    compiler_fn: Callable[[torch.fx.GraphModule, list[Any]], torch.fx.GraphModule],
    only_fwd: bool = ...,
    *,
    require_fp64: bool = ...,
    ignore_non_fp: bool = ...,
) -> bool: ...

_dtype_or_default = ...
_device_or_default = ...
_storage_offset_or_default = ...
_requires_grad_or_default = ...
_is_leaf_or_default = ...

class NopInputReader:
    def __init__(self) -> None: ...
    def storage(
        self,
        storage_hash: str | None,
        nbytes: int,
        *,
        device: torch._prims_common.DeviceLikeType | None = ...,
        dtype_hint: torch.dtype | None = ...,
    ) -> None: ...
    def tensor(self, *args: Any, **kwargs: Any) -> torch.Tensor | None: ...
    def symint(self, *args: Any, **kwargs: Any) -> int | None: ...

class InputReader:
    def __init__(self, save_dir: str | None = ..., *, pbar: tqdm | None = ...) -> None: ...
    def storage(
        self,
        storage_hash: str | None,
        nbytes: int,
        *,
        device: torch._prims_common.DeviceLikeType | None = ...,
        dtype_hint: torch.dtype | None = ...,
    ) -> UntypedStorage: ...
    def tensor(
        self,
        storage: UntypedStorage,
        shape: torch._prims_common.ShapeType,
        stride: torch._prims_common.StrideType | None = ...,
        *,
        storage_offset: int | None = ...,
        dtype: torch.dtype | None = ...,
        requires_grad: bool | None = ...,
        is_leaf: bool | None = ...,
        **metadata: Any,
    ) -> torch.Tensor: ...
    def symint(self, val: Any) -> Any: ...

class InputWriter:
    def __init__(self, save_dir: str | None, *, stable_hash: bool = ...) -> None: ...
    def lines(self) -> list[str]: ...
    def storage(
        self,
        untyped_storage: UntypedStorage,
        *,
        device_hint: torch._prims_common.DeviceLikeType | None = ...,
        dtype_hint: torch.dtype | None = ...,
    ) -> str: ...
    def tensor(self, name: str, t: torch.Tensor) -> None: ...
    def unsupported(self, name: str, arg: Any) -> None: ...
    def const(self, name: str) -> None: ...
    def symint(self, name: str, val: Any) -> None: ...

def aot_graph_input_parser(
    func: Callable[[list[Tensor]], list[Tensor]],
    device: str = ...,
    sym_shapes: dict[str, int] | None = ...,
    default_sym_shape: int | None = ...,
) -> dict[str, Any]: ...
def profile_to_file(filename: str) -> Callable[[T], T]: ...
