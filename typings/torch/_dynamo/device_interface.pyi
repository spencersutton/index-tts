import torch
from collections.abc import Iterable
from dataclasses import dataclass
from typing import Any, Callable, Literal, Optional, Union
from torch._C import (
    _cuda_getCurrentRawStream as get_cuda_stream,
    _mtia_getCurrentRawStream as get_mtia_stream,
    _xpu_getCurrentRawStream as get_xpu_stream,
)

"""
Device abstraction layer for TorchDynamo and Inductor backends.

This module provides a unified interface for different hardware backends (CUDA, XPU,
CPU, MPS, MTIA) through a common device interface. Key components include:

- DeviceInterface: Base class defining the common API for all device types
- Device-specific implementations: CudaInterface, XpuInterface, CpuInterface, MpsInterface, MtiaInterface
- Device registration system for managing available backends
- Worker APIs for multi-processing scenarios
- Stream and event management across different devices
- Device property caching for worker processes

The abstraction layer enables device-agnostic code in TorchDynamo while allowing
specialized implementations for each hardware backend's unique features.
"""
get_cuda_stream: Optional[Callable[[int], int]]
if torch.cuda._is_compiled(): ...
else:
    get_cuda_stream = ...
caching_worker_device_properties: dict[str, Any] = ...
caching_worker_current_devices: dict[str, int] = ...

class DeviceInterface:
    class device:
        def __new__(cls, device: torch.types.Device) -> Any: ...

    class Event:
        def __new__(cls, *args: Any, **kwargs: Any) -> Any: ...

    class Stream:
        def __new__(cls, *args: Any, **kwargs: Any) -> Any: ...

    class Worker:
        @staticmethod
        def set_device(device: int) -> None: ...
        @staticmethod
        def current_device() -> int: ...
        @staticmethod
        def get_device_properties(device: torch.types.Device = ...) -> Any: ...

    @staticmethod
    def current_device() -> int: ...
    @staticmethod
    def set_device(device: torch.types.Device) -> None: ...
    @staticmethod
    def maybe_exchange_device(device: int) -> int: ...
    @staticmethod
    def exchange_device(device: int) -> int: ...
    @staticmethod
    def device_count() -> int: ...
    @staticmethod
    def is_available() -> bool: ...
    @staticmethod
    def stream(stream: torch.Stream) -> Any: ...
    @staticmethod
    def current_stream() -> torch.Stream: ...
    @staticmethod
    def set_stream(stream: torch.Stream) -> None: ...
    @staticmethod
    def get_raw_stream(device_idx: int) -> int: ...
    @staticmethod
    def synchronize(device: torch.types.Device = ...) -> None: ...
    @classmethod
    def get_device_properties(cls, device: torch.types.Device = ...) -> Any: ...
    @staticmethod
    def get_compute_capability(device: torch.types.Device = ...) -> Any: ...
    @staticmethod
    def is_bf16_supported(including_emulation: bool = ...) -> bool: ...
    @classmethod
    def is_dtype_supported(cls, dtype: torch.dtype, including_emulation: bool = ...) -> bool: ...
    @staticmethod
    def memory_allocated(device: torch.types.Device = ...) -> int: ...
    @staticmethod
    def is_triton_capable(device: torch.types.Device = ...) -> bool: ...
    @classmethod
    def raise_if_triton_unavailable(cls, device: torch.types.Device = ...) -> None: ...

class DeviceGuard:
    def __init__(self, device_interface: type[DeviceInterface], index: Optional[int]) -> None: ...
    def __enter__(self) -> None: ...
    def __exit__(self, type: Any, value: Any, traceback: Any) -> Literal[False]: ...

class CudaInterface(DeviceInterface):
    device = ...
    Event = torch.cuda.Event
    Stream = torch.cuda.Stream
    class Worker:
        @staticmethod
        def set_device(device: int) -> None: ...
        @staticmethod
        def current_device() -> int: ...
        @staticmethod
        def get_device_properties(device: torch.types.Device = ...) -> Any: ...

    current_device = ...
    set_device = ...
    device_count = ...
    stream = ...
    current_stream = ...
    set_stream = ...
    _set_stream_by_id = ...
    synchronize = ...
    get_device_properties = ...
    get_raw_stream = ...
    exchange_device = ...
    maybe_exchange_device = ...
    memory_allocated = ...
    is_bf16_supported = ...
    @staticmethod
    def is_available() -> bool: ...
    @staticmethod
    def get_compute_capability(device: torch.types.Device = ...) -> Union[int, str]: ...
    @staticmethod
    def is_triton_capable(device: torch.types.Device = ...) -> bool: ...
    @staticmethod
    def raise_if_triton_unavailable(device: torch.types.Device = ...) -> None: ...

get_mtia_stream: Optional[Callable[[int], int]]
if torch.mtia._is_compiled(): ...
else:
    get_mtia_stream = ...

class MtiaInterface(DeviceInterface):
    device = ...
    Event = ...
    Stream = ...
    class Worker:
        @staticmethod
        def set_device(device: int) -> None: ...
        @staticmethod
        def current_device() -> int: ...
        @staticmethod
        def get_device_properties(device: torch.types.Device = ...) -> Any: ...

    current_device = ...
    set_device = ...
    device_count = ...
    stream = ...
    current_stream = ...
    set_stream = ...
    _set_stream_by_id = ...
    synchronize = ...
    get_device_properties = ...
    get_raw_stream = ...
    exchange_device = ...
    maybe_exchange_device = ...
    memory_allocated = ...
    is_bf16_supported = ...
    @staticmethod
    def is_available() -> bool: ...
    @staticmethod
    def get_compute_capability(device: torch.types.Device = ...) -> Any: ...
    @staticmethod
    def is_triton_capable(device: torch.types.Device = ...) -> bool: ...
    @staticmethod
    def raise_if_triton_unavailable(evice: torch.types.Device = ...) -> None: ...

get_xpu_stream: Optional[Callable[[int], int]]
if torch.xpu._is_compiled(): ...
else:
    get_xpu_stream = ...

class XpuInterface(DeviceInterface):
    device = ...
    Event = torch.xpu.Event
    Stream = torch.xpu.Stream
    class Worker:
        @staticmethod
        def set_device(device: int) -> None: ...
        @staticmethod
        def current_device() -> int: ...
        @staticmethod
        def get_device_properties(device: torch.types.Device = ...) -> Any: ...

    current_device = ...
    set_device = ...
    device_count = ...
    stream = ...
    current_stream = ...
    set_stream = ...
    _set_stream_by_id = ...
    synchronize = ...
    get_device_properties = ...
    get_raw_stream = ...
    exchange_device = ...
    maybe_exchange_device = ...
    memory_allocated = ...
    @staticmethod
    def is_available() -> bool: ...
    @staticmethod
    def get_compute_capability(device: torch.types.Device = ...) -> Any: ...
    @staticmethod
    def is_bf16_supported(including_emulation: bool = ...) -> bool: ...
    @staticmethod
    def is_triton_capable(device: torch.types.Device = ...) -> bool: ...
    @staticmethod
    def raise_if_triton_unavailable(device: torch.types.Device = ...) -> None: ...

@dataclass
class CpuDeviceProperties:
    multi_processor_count: int

class CpuInterface(DeviceInterface):
    class Event(torch.Event):
        def __init__(self, enable_timing: bool = ...) -> None: ...
        def elapsed_time(self, end_event: Any) -> float: ...
        def record(self, stream: Any = ...) -> None: ...

    class Worker:
        @staticmethod
        def get_device_properties(device: torch.types.Device = ...) -> CpuDeviceProperties: ...

    @staticmethod
    def is_available() -> bool: ...
    @staticmethod
    def is_bf16_supported(including_emulation: bool = ...) -> bool: ...
    @staticmethod
    def get_compute_capability(device: torch.types.Device = ...) -> str: ...
    @staticmethod
    def get_raw_stream(device_idx: Any) -> int: ...
    @staticmethod
    def current_device() -> int: ...
    @staticmethod
    def synchronize(device: torch.types.Device = ...) -> None: ...
    @staticmethod
    def is_triton_capable(device: torch.types.Device = ...) -> bool: ...
    @staticmethod
    def raise_if_triton_unavailable(device: torch.types.Device = ...) -> None: ...

class MpsInterface(DeviceInterface):
    @staticmethod
    def is_bf16_supported(including_emulation: bool = ...) -> bool: ...
    @classmethod
    def is_dtype_supported(cls, dtype: torch.dtype, including_emulation: bool = ...) -> bool: ...
    @staticmethod
    def is_available() -> bool: ...
    @staticmethod
    def current_device() -> int: ...
    @staticmethod
    def get_compute_capability(device: torch.types.Device = ...) -> str: ...
    @staticmethod
    def synchronize(device: torch.types.Device = ...) -> None: ...

    class Worker:
        @staticmethod
        def get_device_properties(device: torch.types.Device = ...) -> Any: ...
        @staticmethod
        def current_device() -> int: ...

device_interfaces: dict[str, type[DeviceInterface]] = ...
_device_initialized = ...

def register_interface_for_device(
    device: Union[str, torch.device], device_interface: type[DeviceInterface]
) -> None: ...
def get_interface_for_device(device: Union[str, torch.device]) -> type[DeviceInterface]: ...
def get_registered_device_interfaces() -> Iterable[tuple[str, type[DeviceInterface]]]: ...
def init_device_reg() -> None: ...
