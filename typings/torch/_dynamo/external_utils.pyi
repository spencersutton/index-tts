from collections.abc import Callable
from typing import TYPE_CHECKING, Any, ParamSpec, TypeVar
from warnings import deprecated

import torch

_P = ParamSpec("_P")
_R = TypeVar("_R")
if TYPE_CHECKING:
    @deprecated(
        "`torch._dynamo.external_utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.",
        category=FutureWarning,
    )
    def is_compiling() -> bool: ...

def wrap_inline[**P, R](fn: Callable[_P, _R]) -> Callable[_P, _R]: ...
def call_hook(hook: Callable[..., torch.Tensor | None], *args: Any, **kwargs: Any) -> torch.Tensor: ...
def wrap_numpy[**P, R](f: Callable[_P, _R]) -> Callable[_P, _R]: ...

class FakeBackwardCFunction:
    def __init__(self, real: torch.autograd.function.BackwardCFunction, saved_tensors: list[torch.Tensor]) -> None: ...
    def __getattr__(self, name: str) -> Any: ...

def call_backward(
    backward_c_function: torch.autograd.function.BackwardCFunction, saved_tensors: list[torch.Tensor], *args: Any
) -> torch.Tensor | tuple[torch.Tensor, ...]: ...
def normalize_as_list(x: Any) -> list[Any]: ...
def untyped_storage_size(x: torch.Tensor) -> int: ...

class FakeCompiledAutogradEngine:
    @staticmethod
    def queue_callback(final_callbacks: list[Callable[[], None]], cb: Callable[[], None]) -> None: ...
    @staticmethod
    def exec_final_callbacks(final_callbacks: list[Callable[[], None]]) -> None: ...

def call_hook_from_backward_state(*args: Any, bw_state: Any, hook_name: str, **kwargs: Any) -> Any: ...
def call_module_hooks_from_backward_state(
    _: Any, result: Any, *args: Any, bw_state: Any, hooks_name: str, module_name: str
) -> Any: ...
def get_nonrecursive_disable_wrapper[**P, R](fn: Callable[_P, _R]) -> Callable[_P, _R]: ...
def wrap_dunder_call_ctx_manager[**P, R](self: Any, func: Callable[_P, _R]) -> Callable[_P, _R]: ...
def unwrap_maybe_dynamic_int(x: torch.Tensor | int) -> int: ...
def call_accumulate_grad(variable: torch.Tensor, grad: torch.Tensor, has_post_hooks: bool) -> None: ...
def wrap_inline_with_error_on_graph_break[**P, R](
    fn: Callable[_P, _R], error_on_graph_break: bool
) -> Callable[_P, _R]: ...
def filter_out_const_values(tup: tuple[Any, ...], masks: list[bool]) -> tuple[Any, ...]: ...
def insert_const_values_with_mask(
    tup: tuple[Any, ...], masks: list[bool], values: tuple[Any, ...]
) -> tuple[Any, ...]: ...
