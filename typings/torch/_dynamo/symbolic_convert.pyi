import contextlib
import dataclasses
import functools
import sys
import traceback
import types
from traceback import StackSummary
from typing import Any, Optional, TYPE_CHECKING, Union
from collections.abc import Callable
from typing import TypeAlias
from torch._dynamo.exc import ObservedException
from torch.utils._functools import cache_method
from . import trace_rules, variables
from .bytecode_transformation import Instruction
from .output_graph import GraphCompileReason, OutputGraph
from .replay_record import ExecutionRecorder
from .resume_execution import ReenterWith
from .source import GlobalSource, Source
from .variables.base import VariableTracker
from .variables.builder import FrameStateSizeEntry
from .variables.constant import ConstantVariable
from .variables.ctx_manager import ContextWrappingVariable, GenericContextWrappingVariable
from .variables.functions import BaseUserFunctionVariable
from .variables.misc import ExceptionVariable
from .variables.torch_function import SymbolicTorchFunctionState
from .variables.user_defined import UserDefinedExceptionClassVariable, UserDefinedExceptionObjectVariable
from collections.abc import Generator, Sequence
from torch._subclasses.fake_tensor import FakeTensorMode
from .package import CompilePackage

"""
Core module responsible for converting Python bytecode into TorchDynamo's symbolic execution format.

This module implements the bytecode-level tracing system that allows TorchDynamo to analyze
and transform Python code. It converts Python bytecode instructions into a symbolic format
that tracks the flow of tensors and other values through the program.

Key components:
- InstructionTranslatorBase: Base class for converting bytecode to symbolic execution
- InstructionTranslator: Main translator for function bytecode
- InliningInstructionTranslator: Handles inlining of called functions
- SpeculationLog: Manages state for speculative execution and rollback

The symbolic conversion process handles:
- Control flow (loops, conditionals, etc.)
- Function inlining and call stack management
- Tracking of program values and side effects
- Graph breaks and resumption points
- Exception handling and stack frame management

This is a core part of TorchDynamo's tracing system that enables ahead-of-time
optimization of PyTorch programs.
"""
if TYPE_CHECKING: ...
log = ...
graph_break_log = ...
trace_call_log = ...
trace_source_log = ...
trace_bytecode_log = ...
tls = ...
compare_op_handlers: dict[str, Any] = ...
handle_contains = ...
handle_not = ...
PT2_ISSUE_TRACKER_URL = ...
type ExceptionVals = (
    variables.ExceptionVariable | UserDefinedExceptionClassVariable | UserDefinedExceptionObjectVariable
)

@dataclasses.dataclass
class SpeculationEntry:
    filename: str
    lineno: int
    instruction_pointer: int
    inst: Instruction
    _failed: bool = ...
    error_on_graph_break: bool | None = ...
    reason: GraphCompileReason | None = ...
    def fail_and_restart_analysis(self, error_on_graph_break: bool) -> None: ...
    def failed(self, tx: InstructionTranslatorBase) -> bool: ...

@dataclasses.dataclass
class SpeculationLog:
    entries: list[SpeculationEntry] = ...
    index: int = ...
    def restart(self) -> None: ...
    def clear(self) -> None: ...
    def next(self, filename: str, lineno: int, instruction_pointer: int, inst: Instruction) -> SpeculationEntry: ...

@dataclasses.dataclass
class LocalState:
    automatic_dynamic: dict[str, FrameStateSizeEntry] = ...
    def render(self) -> str: ...

@dataclasses.dataclass
class DistributedState:
    compile_pg: Any
    local_state: LocalState
    all_states: list[LocalState] | None = ...

class TensorifyState:
    force_specializations: set[str] = ...
    @classmethod
    def specialize(cls, index: str) -> None: ...
    @classmethod
    def should_specialize(cls, index: str) -> bool: ...
    @classmethod
    def clear(cls) -> None: ...
    @classmethod
    def empty(cls) -> bool: ...

@contextlib.contextmanager
def save_and_restart_speculation_log(tx: InstructionTranslatorBase) -> Generator[None]: ...
@contextlib.contextmanager
def temporarely_allow_writes_to_output_graph(tx: InstructionTranslatorBase) -> Generator[None]: ...

@dataclasses.dataclass
class BlockStackEntry:
    inst: Instruction
    target: Instruction
    stack_index: int
    with_context: ContextWrappingVariable | GenericContextWrappingVariable | None = ...
    def can_restore(self) -> bool: ...
    def resume_fn(self) -> ReenterWith: ...
    def exit(self, tx: InstructionTranslatorBase, is_graph_break: bool) -> None: ...

class SpeculationLogDivergence(AssertionError): ...
class ReturnValueOp(Exception): ...
class YieldValueOp(Exception): ...

def stack_op(fn: Callable[..., object]) -> Callable[..., Any]: ...
def is_stdlib(mod: object) -> bool: ...

explain = ...

def log_graph_break(
    code_options: dict[str, Any], reason: str = ..., exc_info: bool = ..., user_stack: StackSummary | None = ...
) -> None: ...
def generic_jump(
    truth_fn: Callable[[object], bool], push: bool
) -> Callable[[InstructionTranslatorBase, Instruction], None]: ...
def break_graph_if_unsupported(
    *, push: int
) -> Callable[[Callable[..., None]], Callable[[InstructionTranslatorBase, Instruction], None]]: ...

class BytecodeDistpatchTableMeta(type):
    def __init__(cls: type, name: str, bases: Any, dct: Any) -> None: ...

@dataclasses.dataclass
class ExceptionStack:
    _exc_stack: list[ExceptionVals] = ...
    _current_exception: ExceptionVals | None = ...
    def clear_current_exception(self) -> None: ...
    def set_current_exception(self, val: ExceptionVals) -> None: ...
    def move_current_exception_to_stack(self) -> None: ...
    def get_current_exception(self) -> ExceptionVals: ...
    def pop(self) -> ExceptionVals: ...
    def append(self, val: ExceptionVals) -> None: ...
    def __len__(self) -> int: ...
    def __getitem__(self, index: int) -> ExceptionVals: ...

    __repr__ = ...

class InstructionTranslatorBase(metaclass=BytecodeDistpatchTableMeta):
    output: OutputGraph
    symbolic_locals: dict[str, VariableTracker]
    symbolic_globals: dict[str, VariableTracker]
    symbolic_torch_function_state: SymbolicTorchFunctionState
    post_prune_cell_and_freevars: dict[str, VariableTracker] | None
    stack: list[VariableTracker]
    instruction_pointer: int | None
    current_instruction: Instruction
    block_stack: list[BlockStackEntry]
    lineno: int
    kw_names: ConstantVariable | None
    accept_prefix_inst: bool
    prefix_insts: list[Instruction]
    inline_depth: int
    inconsistent_side_effects: bool
    current_speculation: SpeculationEntry | None
    dispatch_table: list[Any]
    exn_vt_stack: ExceptionStack
    exec_recorder: ExecutionRecorder | None
    strict_checks_fn: Callable[[VariableTracker], bool] | None
    start_point: int | None
    is_leaf_tracer: bool
    parent: InstructionTranslatorBase | None
    debug_locals: list[tuple[VariableTracker, list[VariableTracker]]]
    package: CompilePackage | None
    def mark_inconsistent_side_effects(self) -> None: ...
    def maybe_has_backedge(self) -> bool: ...
    def cellvars(self) -> list[str]: ...
    def freevars(self) -> list[str]: ...
    def cell_and_freevars(self) -> list[str]: ...
    def prune_dead_locals(self) -> None: ...
    def call_function(
        self, fn: VariableTracker, args: list[VariableTracker], kwargs: dict[str, VariableTracker]
    ) -> None: ...
    def inline_generator_function(self, fn: VariableTracker, args: Sequence[Any], kwargs: dict[str, Any]) -> Any: ...
    def inline_user_function_return(self, fn: VariableTracker, args: Sequence[Any], kwargs: dict[str, Any]) -> Any: ...
    def get_line_of_code_header(self, lineno: int | None = ...) -> str: ...
    def get_log_starts_line_log_str(self) -> str: ...
    def starts_line(self, lineno: int) -> None: ...
    def step(self) -> bool: ...

    if sys.version_info >= (3, 11):
        def update_block_stack(self, inst: Instruction) -> None: ...

    else: ...
    @property
    def next_instruction(self) -> Instruction: ...
    def step_graph_break(self, continue_inst: Instruction) -> None: ...
    def run_ctx_mgr(self) -> Any: ...
    def run(self) -> None: ...
    def push(self, val: VariableTracker | None) -> None: ...
    def push_many(self, vals: list[VariableTracker]) -> None: ...
    def pop(self) -> VariableTracker: ...
    def popn(self, n: int) -> list[VariableTracker]: ...
    def LOAD_FAST(self, inst: Instruction) -> None: ...
    def LOAD_DEREF(self, inst: Instruction) -> None: ...
    def STORE_FAST(self, inst: Instruction) -> None: ...
    def DELETE_FAST(self, inst: Instruction) -> None: ...
    def STORE_DEREF(self, inst: Instruction) -> None: ...

    LOAD_CLOSURE = ...
    def LOAD_CONST(self, inst: Instruction) -> None: ...
    @functools.cached_property
    def nn_modules_globals_vt(self) -> VariableTracker: ...
    def LOAD_GLOBAL(self, inst: Instruction) -> None: ...
    def STORE_GLOBAL(self, inst: Instruction) -> None: ...
    @cache_method
    def import_source(self, module_name: str) -> GlobalSource: ...
    def resolve_name(self, name: str, package: str, level: int) -> str: ...
    def calc_package(self) -> str: ...
    def IMPORT_NAME(self, inst: Instruction) -> None: ...

    EAGER_IMPORT_NAME = ...
    def IMPORT_FROM(self, inst: Instruction) -> None: ...
    @cache_method
    def load_builtin_from_argval(self, argval: Any) -> VariableTracker: ...
    def load_builtin(self, inst: Instruction) -> None: ...
    def jump(self, inst: Instruction) -> None: ...

    JUMP_FORWARD = ...
    JUMP_ABSOLUTE = ...
    POP_JUMP_IF_FALSE = ...
    POP_JUMP_IF_TRUE = ...
    JUMP_IF_FALSE_OR_POP = ...
    JUMP_IF_TRUE_OR_POP = ...
    def SETUP_LOOP(self, inst: Instruction) -> None: ...
    def SETUP_EXCEPT(self, inst: Instruction) -> None: ...
    def POP_BLOCK(self, inst: Instruction) -> None: ...
    def SETUP_WITH(self, inst: Instruction) -> None: ...
    def SETUP_FINALLY(self, inst: Instruction) -> None: ...
    def BEGIN_FINALLY(self, inst: Instruction) -> None: ...
    def WITH_CLEANUP_START(self, inst: Instruction) -> None: ...
    def WITH_CLEANUP_FINISH(self, inst: Instruction) -> None: ...
    def FOR_ITER(self, inst: Instruction) -> None: ...
    def RAISE_VARARGS(self, inst: Instruction) -> None: ...
    def CLEANUP_THROW(self, inst: Instruction) -> None: ...
    def RERAISE(self, inst: Instruction) -> None: ...
    def WITH_EXCEPT_START(self, inst: Instruction) -> None: ...
    def exception_handler(self, raised_exception: ObservedException) -> None: ...
    def PUSH_EXC_INFO(self, inst: Instruction) -> None: ...
    def POP_EXCEPT(self, inst: Instruction) -> None: ...
    def check_if_exc_matches(self) -> bool: ...
    def CHECK_EXC_MATCH(self, inst: Instruction) -> None: ...
    def JUMP_IF_NOT_EXC_MATCH(self, inst: Instruction) -> None: ...
    def COMPARE_OP(self, inst: Instruction) -> None: ...
    def GET_ITER(self, inst: Instruction) -> None: ...
    @break_graph_if_unsupported(push=1)
    def CALL_FUNCTION(self, inst: Instruction) -> None: ...
    @break_graph_if_unsupported(push=1)
    def CALL_FUNCTION_EX(self, inst: Instruction) -> None: ...
    @break_graph_if_unsupported(push=1)
    def CALL_FUNCTION_KW(self, inst: Instruction) -> None: ...
    def LOAD_METHOD_SUPER(self, inst: Instruction) -> None: ...
    def LOAD_ATTR_SUPER(self, inst: Instruction) -> None: ...
    def LOAD_METHOD(self, inst: Instruction) -> None: ...
    def CALL_METHOD(self, inst: Instruction) -> None: ...
    def LOAD_ATTR(self, inst: Instruction) -> None: ...
    def STORE_ATTR(self, inst: Instruction) -> None: ...
    def store_attr_graph_break(self, inst: Instruction) -> None: ...
    def DELETE_ATTR(self, inst: Instruction) -> None: ...
    def create_call_resume_at(
        self, inst: Instruction, all_stack_locals_metadata: Any, disable_current_frame_resume: bool
    ) -> list[Instruction]: ...
    def should_compile_partial_graph(self) -> bool: ...
    @break_graph_if_unsupported(push=0)
    def STORE_SUBSCR(self, inst: Instruction) -> None: ...
    def DELETE_SUBSCR(self, inst: Instruction) -> None: ...
    def BUILD_TUPLE(self, inst: Instruction) -> None: ...
    def BUILD_SLICE(self, inst: Instruction) -> None: ...
    def BUILD_LIST(self, inst: Instruction) -> None: ...
    def BUILD_SET(self, inst: Instruction) -> None: ...
    def BUILD_LIST_UNPACK(self, inst: Instruction, cls: type = ...) -> None: ...
    def BUILD_TUPLE_UNPACK(self, inst: Instruction) -> None: ...

    BUILD_TUPLE_UNPACK_WITH_CALL = ...
    def BUILD_MAP(self, inst: Instruction) -> None: ...
    def BUILD_MAP_UNPACK(self, inst: Instruction) -> None: ...

    BUILD_MAP_UNPACK_WITH_CALL = ...
    def BUILD_CONST_KEY_MAP(self, inst: Instruction) -> None: ...
    def MAP_ADD(self, inst: Instruction) -> None: ...
    def SET_ADD(self, inst: Instruction) -> None: ...
    def SET_UPDATE(self, inst: Instruction) -> None: ...
    def LIST_APPEND(self, inst: Instruction) -> None: ...
    def MAKE_FUNCTION(self, inst: Instruction) -> None: ...
    def UNPACK_SEQUENCE(self, inst: Instruction) -> None: ...
    def UNPACK_EX(self, inst: Instruction) -> None: ...
    @break_graph_if_unsupported(push=0)
    def graph_break_on_leaf_function(self, inst: Instruction) -> None: ...
    def NOP(self, inst: Instruction) -> None: ...
    def POP_TOP(self, inst: Instruction) -> None: ...
    def ROT_TWO(self, inst: Instruction) -> None: ...
    def ROT_THREE(self, inst: Instruction) -> None: ...
    def ROT_FOUR(self, inst: Instruction) -> None: ...
    def DUP_TOP(self, inst: Instruction) -> None: ...
    def DUP_TOP_TWO(self, inst: Instruction) -> None: ...
    def FORMAT_VALUE(self, inst: Instruction) -> None: ...
    def BUILD_STRING(self, inst: Instruction) -> None: ...
    def IS_OP(self, inst: Instruction) -> None: ...
    def CONTAINS_OP(self, inst: Instruction) -> None: ...
    def LIST_EXTEND(self, inst: Instruction) -> None: ...
    def LIST_TO_TUPLE(self, inst: Instruction) -> None: ...
    def STOPITERATION_ERROR(self, inst: Instruction) -> None: ...
    def DICT_MERGE(self, inst: Instruction) -> None: ...

    DICT_UPDATE = ...
    def GEN_START(self, inst: Instruction) -> None: ...
    def GET_LEN(self, inst: Instruction) -> None: ...
    def MATCH_MAPPING(self, inst: Instruction) -> None: ...
    def MATCH_SEQUENCE(self, inst: Instruction) -> None: ...
    def MATCH_KEYS(self, inst: Instruction) -> None: ...
    def LOAD_ASSERTION_ERROR(self, inst: Instruction) -> None: ...
    def LOAD_BUILD_CLASS(self, inst: Instruction) -> None: ...

    UNARY_POSITIVE = ...
    UNARY_NEGATIVE = ...
    UNARY_NOT = ...
    UNARY_INVERT = ...
    BINARY_POWER = ...
    BINARY_MULTIPLY = ...
    BINARY_MATRIX_MULTIPLY = ...
    BINARY_FLOOR_DIVIDE = ...
    BINARY_TRUE_DIVIDE = ...
    BINARY_MODULO = ...
    BINARY_REMAINDER = ...
    BINARY_ADD = ...
    BINARY_SUBTRACT = ...
    BINARY_SUBSCR = ...
    BINARY_LSHIFT = ...
    BINARY_RSHIFT = ...
    BINARY_AND = ...
    BINARY_OR = ...
    BINARY_XOR = ...
    INPLACE_POWER = ...
    INPLACE_MULTIPLY = ...
    INPLACE_MATRIX_MULTIPLY = ...
    INPLACE_FLOOR_DIVIDE = ...
    INPLACE_TRUE_DIVIDE = ...
    INPLACE_MODULO = ...
    INPLACE_REMAINDER = ...
    INPLACE_ADD = ...
    INPLACE_SUBTRACT = ...
    INPLACE_LSHIFT = ...
    INPLACE_RSHIFT = ...
    INPLACE_AND = ...
    INPLACE_XOR = ...
    INPLACE_OR = ...
    def RESUME(self, inst: Instruction) -> None: ...

    if sys.version_info >= (3, 11):
        def BINARY_OP(self, inst: Instruction) -> None: ...

    def PRECALL(self, inst: Instruction) -> None: ...
    def KW_NAMES(self, inst: Instruction) -> None: ...
    def PUSH_NULL(self, inst: Instruction) -> None: ...
    @break_graph_if_unsupported(push=1)
    def CALL(self, inst: Instruction) -> None: ...
    def COPY(self, inst: Instruction) -> None: ...
    def SWAP(self, inst: Instruction) -> None: ...

    JUMP_BACKWARD = ...
    JUMP_BACKWARD_NO_INTERRUPT = ...
    POP_JUMP_FORWARD_IF_TRUE = ...
    POP_JUMP_BACKWARD_IF_TRUE = ...
    POP_JUMP_FORWARD_IF_FALSE = ...
    POP_JUMP_BACKWARD_IF_FALSE = ...
    def CACHE(self, inst: Instruction) -> None: ...
    def BEFORE_WITH(self, inst: Instruction) -> None: ...
    def setup_or_before_with(self, inst: Instruction) -> None: ...
    def append_prefix_inst(self, inst: Instruction) -> None: ...
    def MAKE_CELL(self, inst: Instruction) -> None: ...
    def COPY_FREE_VARS(self, inst: Instruction) -> None: ...
    def RETURN_GENERATOR(self, inst: Instruction) -> None: ...
    def END_FOR(self, inst: Instruction) -> None: ...
    def LOAD_FAST_CHECK(self, inst: Instruction) -> None: ...
    def LOAD_FAST_AND_CLEAR(self, inst: Instruction) -> None: ...
    def LOAD_SUPER_ATTR(self, inst: Instruction) -> None: ...
    def CALL_INTRINSIC_1(self, inst: Instruction) -> None: ...
    def END_SEND(self, inst: Instruction) -> None: ...
    @break_graph_if_unsupported(push=1)
    def CALL_KW(self, inst: Instruction) -> None: ...
    def TO_BOOL(self, inst: Instruction) -> None: ...
    def SET_FUNCTION_ATTRIBUTE(self, inst: Instruction) -> None: ...
    def CONVERT_VALUE(self, inst: Instruction) -> None: ...
    def FORMAT_SIMPLE(self, inst: Instruction) -> None: ...
    def FORMAT_WITH_SPEC(self, inst: Instruction) -> None: ...
    def is_non_empty_graph(self) -> bool: ...
    def format_frame_summary(self, additional_stack_frames: list[Any] | None = ...) -> str: ...
    def frame_summary(self) -> traceback.FrameSummary: ...
    def is_co_filename_from_nn_modules(self) -> bool: ...
    def store_global_weakref_by_id(self, prefix: str, value: Any) -> str: ...
    @property
    def fake_mode(self) -> FakeTensorMode | None: ...
    @contextlib.contextmanager
    def strict_translation_mode(self, check_fn: Callable[[VariableTracker], bool]) -> Any: ...
    def speculate(self) -> SpeculationEntry: ...
    def __init__(
        self,
        output: OutputGraph,
        instructions: list[Instruction],
        f_locals: dict[str, Any],
        f_globals: dict[str, Any],
        f_builtins: dict[str, Any],
        code_options: dict[str, Any],
        symbolic_locals: dict[str, VariableTracker],
        symbolic_globals: dict[str, VariableTracker],
        symbolic_torch_function_state: SymbolicTorchFunctionState,
        f_code: types.CodeType,
        export: bool,
        inline_depth: int,
        speculation_log: SpeculationLog,
        exn_vt_stack: ExceptionStack,
        distributed_state: DistributedState | None,
        closure: tuple[types.CellType] | None = ...,
        package: CompilePackage | None = ...,
    ) -> None: ...

class InstructionTranslator(InstructionTranslatorBase):
    @staticmethod
    def current_tx() -> InstructionTranslator: ...
    @contextlib.contextmanager
    def set_current_tx(self) -> Any: ...
    def __init__(
        self,
        instructions: list[Instruction],
        f_code: types.CodeType,
        f_locals: dict[str, Any],
        f_globals: dict[str, Any],
        f_builtins: dict[str, Any],
        closure: tuple[Any, ...] | None,
        torch_function_mode_stack: Any,
        code_options: dict[str, Any],
        compiler_fn: Any,
        one_graph: bool,
        export: bool,
        export_constraints: Any,
        frame_state: Any,
        speculation_log: SpeculationLog,
        exn_vt_stack: ExceptionStack,
        distributed_state: DistributedState | None,
        package: CompilePackage | None,
    ) -> None: ...
    def get_example_value(self, source: Source) -> Any: ...
    def symbolic_locals_contain_module_class(self) -> bool: ...
    def replace_tos_if_return_is_generator(self) -> None: ...
    def RETURN_VALUE(self, inst: Instruction) -> None: ...
    def RETURN_CONST(self, inst: Instruction) -> None: ...

if sys.version_info >= (3, 11):
    _binary_op_lookup = ...

class InliningInstructionTranslator(InstructionTranslatorBase):
    symbolic_result: VariableTracker | None
    parent: InstructionTranslatorBase
    @classmethod
    def inline_call(cls, parent: Any, func: Any, args: Any, kwargs: Any) -> Any: ...
    @staticmethod
    def check_inlineable(func: Any) -> trace_rules.SkipResult: ...
    @staticmethod
    def build_inline_tracer(
        parent: Any, func: VariableTracker, args: list[VariableTracker], kwargs: Any
    ) -> InliningInstructionTranslator: ...
    def inline_call_(self) -> VariableTracker: ...
    def __init__(
        self,
        parent: InstructionTranslatorBase,
        code: types.CodeType,
        symbolic_locals: dict[str, VariableTracker],
        symbolic_globals: dict[str, VariableTracker],
        symbolic_torch_function_state: SymbolicTorchFunctionState,
        funcvar: BaseUserFunctionVariable,
    ) -> None: ...
    @property
    def fake_mode(self) -> FakeTensorMode | None: ...
    def run_ctx_mgr(self) -> Any: ...
    def should_compile_partial_graph(self) -> bool: ...
    def create_call_resume_at(
        self, inst: Instruction, all_stack_locals_metadata: Any, disable_current_frame_resume: bool
    ) -> list[Instruction]: ...
    def RETURN_VALUE(self, inst: Instruction) -> None: ...
    def RETURN_CONST(self, inst: Instruction) -> None: ...
    def get_globals_source_and_value(self, name: str) -> tuple[Any, VariableTracker, Source]: ...
    def STORE_GLOBAL(self, inst: Instruction) -> None: ...

class InliningGeneratorInstructionTranslator(InliningInstructionTranslator):
    generated_items: list[VariableTracker]
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def YIELD_VALUE(self, inst: Instruction) -> None: ...
    def GET_YIELD_FROM_ITER(self, inst: Instruction) -> None: ...
    def RETURN_VALUE(self, inst: Instruction) -> None: ...
    def RETURN_CONST(self, inst: Instruction) -> None: ...
    def YIELD_FROM(self, inst: Instruction) -> None: ...
    def SEND(self, inst: Instruction) -> None: ...
