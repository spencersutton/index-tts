import types
import torch
import numpy as np
from collections.abc import Sequence
from typing import Any, Optional, TypeVar, Union, overload
from collections.abc import Callable
from typing import ParamSpec
from torch import fx
from .types import ConvertFrameReturn, DynamoFrameType

"""Testing utilities and infrastructure for Dynamo.

This module provides a comprehensive set of testing utilities including:
- Test result collection and validation
- Graph manipulation and comparison tools
- Test case management and execution helpers
- Specialized test decorators for different Python versions and features
- RNG state management
- Compilation counting and monitoring
- Debug utilities for bytecode transformation

The utilities in this module are used across Dynamo's test suite to ensure
consistent testing patterns and proper test isolation.
"""
np: types.ModuleType | None = ...
unsupported = ...
three = ...
log = ...
_P = ParamSpec("_P")

def clone_me(x: torch.Tensor | None) -> torch.Tensor | None: ...
def remove_optimized_module_prefix(name: str) -> str: ...
def extract_graph_and_tracker(fn, *args, **kwargs):  # -> tuple[Any, None]:
    ...
def collect_results(model: torch.nn.Module, prediction: Any, loss: Any, example_inputs: Any) -> list[Any]: ...
def requires_bwd_pass(out: Any) -> bool: ...
@overload
def reduce_to_scalar_loss(out: torch.Tensor) -> torch.Tensor: ...
@overload
def reduce_to_scalar_loss(out: list[Any] | tuple[Any, ...] | dict[Any, Any]) -> float: ...
def reduce_to_scalar_loss(out: Any) -> torch.Tensor | float: ...
def debug_dir() -> str: ...
def debug_dump(name: str, code: types.CodeType, extra: str = ...) -> None: ...
def debug_insert_nops(
    frame: DynamoFrameType, cache_size: int, hooks: Any, _: Any, *, skip: int = ...
) -> ConvertFrameReturn: ...

class CompileCounter:
    def __init__(self) -> None: ...
    def __call__(self, gm: torch.fx.GraphModule, example_inputs: list[torch.Tensor]) -> Callable[..., Any]: ...
    def clear(self) -> None: ...

class CompileCounterWithBackend:
    def __init__(self, backend: str) -> None: ...
    def __call__(self, gm: torch.fx.GraphModule, example_inputs: list[torch.Tensor]) -> Callable[..., Any]: ...
    def clear(self) -> None: ...

class EagerAndRecordGraphs:
    def __init__(self) -> None: ...
    def __call__(self, gm: torch.fx.GraphModule, example_inputs: list[torch.Tensor]) -> Callable[..., Any]: ...

class AotEagerAndRecordGraphs:
    def __init__(self) -> None: ...
    def __call__(self, gm: torch.fx.GraphModule, example_inputs: list[torch.Tensor]) -> Callable[..., Any]: ...

class InductorAndRecordGraphs:
    def __init__(self) -> None: ...
    def __call__(
        self, gm, example_inputs
    ):  # -> Callable[[list[object]], Sequence[Tensor]] | str | list[str] | Weights:
        ...

def strip_comment(code: str) -> str: ...
def remove_trailing_space(code: str) -> str: ...
def normalize_gm(gm_str: str) -> str: ...
def empty_line_normalizer(code: str) -> str: ...
def standard_test(
    self: Any,
    fn: Callable[..., Any],
    nargs: int,
    expected_ops: int | None = ...,
    expected_ops_dynamic: int | None = ...,
    expected_frame_count: int = ...,
) -> None: ...
def dummy_fx_compile(gm: fx.GraphModule, example_inputs: list[torch.Tensor]) -> Callable[..., Any]: ...
def format_speedup(speedup: float, pvalue: float, is_correct: bool = ..., pvalue_threshold: float = ...) -> str: ...
def rand_strided(
    size: Sequence[int],
    stride: Sequence[int],
    dtype: torch.dtype = ...,
    device: str | torch.device = ...,
    extra_size: int = ...,
) -> torch.Tensor: ...

_T = TypeVar("_T")

def check_dynamic_shape_capture() -> bool: ...
def make_test_cls_with_patches(
    cls: type,
    cls_prefix: str,
    fn_suffix: str,
    *patches: Any,
    xfail_prop: str | None = ...,
    decorator: Callable[[Callable[..., Any]], Callable[..., Any]] = ...,
) -> type: ...
def skipIfNotPy311[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def skipIfNotPy312[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def xfailIfPy312[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def skipIfPy312[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def requiresPy310[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def expectedFailureDynamic[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def expectedFailureCodegenDynamic[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def expectedFailureDynamicWrapper[**P, T](fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
def reset_rng_state(use_xla: bool = ...) -> None: ...
