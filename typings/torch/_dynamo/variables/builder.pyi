import dataclasses
import re
import weakref
import torch
from typing import Any, NamedTuple, Optional, TYPE_CHECKING, Union
from torch import SymInt
from torch._subclasses.fake_tensor import FakeTensor
from torch.fx.experimental.symbolic_shapes import DimDynamic, SymIntSymbolicContext
from torch.utils.weak import TensorWeakRef
from ..pgo import FrameStateSizeEntry
from ..source import Source
from ..utils import odict_values, range_iterator, tuple_iterator
from .base import VariableTracker
from torch._dynamo.codegen import PyCodegen
from torch._dynamo.symbolic_convert import InstructionTranslator

"""
This module contains classes and utilities for building variable trackers in Dynamo.
Variable trackers are used to convert Python values into symbolic representations
that can be traced and transformed during graph capture.

The key classes are:

- VariableBuilder: Handles source-tracked objects that need guards and proper
  reconstruction in the output graph. Used for inputs, module attributes, etc.

- SourcelessBuilder: Handles ephemeral objects created during tracing that don't
  need source tracking or guards. Used for temporary lists, intermediate values, etc.

Variable trackers enable Dynamo to track the flow of values through the program,
maintain guards for dynamic properties, and reconstruct values in the output graph.
The builders in this module handle converting Python values into appropriate
VariableTracker instances based on their type and usage context.
"""
if TYPE_CHECKING: ...
log = ...
static_inputs_log = ...
DimList = list

def safe_has_grad(t):  # -> bool:
    ...

class _missing: ...

@dataclasses.dataclass
class GraphArg:
    source: Source
    _example: TensorWeakRef | torch.SymInt
    pass_arg_as_tensor: bool
    fake_tensor: torch._subclasses.fake_tensor.FakeTensor | None
    is_tensor: bool = ...
    example_strong_ref: torch.Tensor | None = ...
    @property
    def example(self):  # -> Tensor | SymInt:
        ...
    def __post_init__(self):  # -> None:
        ...
    def reconstruct(self, codegen: PyCodegen):  # -> None:
        ...
    def erase(self):  # -> None:
        ...
    def __eq__(self, other) -> bool: ...

class BackwardStateGraphArg(GraphArg):
    def __init__(self) -> None: ...
    def reconstruct(self, codegen: PyCodegen):  # -> None:
        ...

ITERTOOLS_TYPE_IDS: frozenset[int] = ...
ITERTOOLS_POLYFILLED_TYPE_IDS: set[int] = ...
og_module_named_buffers_fn_ptr = ...
og_module_named_parameters_fn_ptr = ...

class VariableBuilder:
    def __init__(self, tx, source: Source) -> None: ...
    def __call__(self, value): ...
    def get_source(self):  # -> Source | OptimizerSource | AttrSource | AttrProxySource:
        ...
    def install_guards(self, *guards):  # -> dict[Any, Any] | None:
        ...
    def wrap_regex_pattern(self, value: re.Pattern):  # -> RegexPatternVariable:
        ...
    def wrap_weakref(self, value: weakref.ReferenceType):  # -> WeakRefVariable:
        ...
    def wrap_removable_handle(self, value): ...
    def wrap_jit_function(self, value):  # -> WrapperUserFunctionVariable:
        ...
    def wrap_mapping_proxy(self, value): ...
    def wrap_user_defined(self, value: Any):  # -> UserDefinedObjectVariable:
        ...
    def wrap_listlike(
        self, value: Union[tuple, list, odict_values, NamedTuple]
    ):  # -> VariableTracker | TupleVariable | ListIteratorVariable | ListVariable | SizeVariable | DequeVariable | SliceVariable:
        ...
    def wrap_tuple_iterator(self, value: tuple_iterator): ...
    def wrap_range_iterator(self, value: range_iterator): ...
    def wrap_slice_range(self, value: slice | range):  # -> SliceVariable | RangeVariable:
        ...
    def mark_static_input(self, value: torch.Tensor, guard: bool):  # -> None:
        ...
    def wrap_module(
        self, value: torch.nn.Module
    ):  # -> DelayGraphBreakVariable | FSDPManagedNNModuleVariable | UnspecializedBuiltinNNModuleVariable | UnspecializedNNModuleVariable:
        ...
    def wrap_literal(self, value):  # -> VariableTracker | SymNodeVariable:
        ...
    def assert_not_wrapped_by_this_graph(self, value: torch.Tensor):  # -> None:
        ...
    def wrap_tensor(self, value: torch.Tensor):  # -> VariableTracker:
        ...
    def wrap_numpy_ndarray(self, value): ...
    def wrap_symint(
        self, value, dynamism: DimDynamic | None = ..., context: SymIntSymbolicContext | None = ...
    ):  # -> VariableTracker | SymNodeVariable:
        ...
    def wrap_symfloat(self, value):  # -> VariableTracker:
        ...
    def wrap_unspecialized_primitive(self, value):  # -> ConstantVariable:
        ...

def wrap_fx_proxy(tx, proxy, example_value=..., subclass_type=..., **options) -> VariableTracker: ...
def cache_real_value_when_export(tx, proxy, example_value):  # -> None:
    ...
def wrap_fx_proxy_cls(target_cls, tx, proxy, example_value=..., subclass_type=..., **options): ...
def handle_traced_output(example_value, tx, proxy, options, subclass_type, target_cls): ...
def infer_subclass_type(value):  # -> type[Any] | None:
    ...
def get_specialized_props(target_cls, tx, example_value, subclass_type): ...
def construct_tensor_variable(target_cls, tx, proxy, example_value, subclass_type, options): ...
def get_automatic_dynamic_shapes_mark_as():  # -> Literal[DimDynamic.DYNAMIC, DimDynamic.SIZE_LIKE_UNBACKED, DimDynamic.OBLIVIOUS_SIZE]:
    ...

_DYNAMIC_SOURCES: set[str] | None = ...
_DYNAMIC_SOURCES_CONFIG_HASH: int | None = ...

def get_dynamic_sources() -> set[str]: ...
def is_dynamic_source(source_name: str) -> bool: ...
def record_automatic_dynamic(tx: InstructionTranslator, name: str, e: torch.Tensor) -> FrameStateSizeEntry: ...

_UNBACKED_SOURCES: set[str] | None = ...
_UNBACKED_SOURCES_CONFIG_HASH: int | None = ...

def get_unbacked_sources() -> set[str]: ...
def is_unbacked_source(source_name: str) -> bool: ...
def wrap_to_fake_tensor_and_record(
    e, tx, *, source: Source | None, is_tensor: bool, parent_context=...
):  # -> Tensor | TensorWithFlatten | FakeTensor | Any:
    ...

class SourcelessBuilder:
    def __init__(self) -> None: ...
    @staticmethod
    def create(tx: InstructionTranslator, value) -> VariableTracker: ...
    @staticmethod
    def wrap_constant_literal(value):  # -> VariableTracker:
        ...
    @staticmethod
    def make_type_handlers():  # -> dict[Any, Any]:
        ...

class SourcelessUserDefinedObjectBuilder:
    def __init__(self) -> None: ...
    @staticmethod
    def create(tx: InstructionTranslator, value) -> VariableTracker: ...
