import torch
from inspect import Parameter
from typing import Any, Callable, Optional, TYPE_CHECKING, Union
from torch.export import ExportedProgram
from torch.export.graph_signature import ExportGraphSignature
from torch.utils._pytree import FlattenFunc, FromDumpableContextFn, KeyPath, ToDumpableContextFn, UnflattenFunc

if TYPE_CHECKING: ...
placeholder_prefixes = ...
_DISABLE_ATEN_TO_ASSERTION_PASS = ...

def get_keystr(key_path: KeyPath) -> str: ...
def register_dataclass_as_pytree_node(
    cls: type[Any],
    flatten_fn: Optional[FlattenFunc] = ...,
    unflatten_fn: Optional[UnflattenFunc] = ...,
    *,
    serialized_type_name: Optional[str] = ...,
    to_dumpable_context: Optional[ToDumpableContextFn] = ...,
    from_dumpable_context: Optional[FromDumpableContextFn] = ...,
    return_none_fields: bool = ...,
) -> None: ...
def is_param(program: ExportedProgram, node: torch.fx.Node) -> bool: ...
def get_param(program: ExportedProgram, node: torch.fx.Node) -> Optional[torch.nn.Parameter]: ...
def is_buffer(program: ExportedProgram, node: torch.fx.Node) -> bool: ...
def get_buffer(program: ExportedProgram, node: torch.fx.Node) -> Optional[torch.Tensor]: ...
def is_lifted_tensor_constant(program: ExportedProgram, node: torch.fx.Node) -> bool: ...
def get_lifted_tensor_constant(program: ExportedProgram, node: torch.fx.Node) -> Optional[torch.Tensor]: ...
def sequential_split(
    gm: torch.fx.GraphModule, node_call_back: Callable[[torch.fx.Node], Union[torch.fx.Node, bool]]
) -> torch.fx.GraphModule: ...
def nodes_filter(nodes: list[torch.fx.Node], node_call_back) -> list[torch.fx.Node]: ...
def apply_runtime_assertion_pass(gm: torch.fx.GraphModule, graph_signature):  # -> tuple[GraphModule, Any]:
    ...
def nodes_first(nodes: list[torch.fx.Node], node_call_back=...) -> Optional[torch.fx.Node]: ...
def nodes_count(nodes: list[torch.fx.Node], node_call_back) -> int: ...
def nodes_map(nodes: list[torch.fx.Node], node_call_back) -> list[torch.fx.Node]: ...
def node_replace_(old_node: torch.fx.Node, new_node: torch.fx.Node) -> None: ...
def node_inline_(call_mod_node: torch.fx.Node) -> Optional[torch.fx.GraphModule]: ...
def placeholder_naming_pass(
    gm: torch.fx.GraphModule,
    export_graph_signature: ExportGraphSignature,
    mod: torch.nn.Module,
    fake_args,
    fake_kwargs,
    fake_params_buffers,
    constants: dict[str, Any],
) -> None: ...
def remove_proxy_from_state_dict(state_dict: dict, in_place: bool) -> dict: ...
def register_module_as_pytree_input_node(cls: type[torch.nn.Module]) -> None: ...
def deregister_module_as_pytree_input_node(cls: type[torch.nn.Module]) -> None: ...
def sync_state(*wrapped_method_modules):  # -> None:

    ...

class _WrappedMethod(torch.nn.Module):
    def __init__(self, method) -> None: ...

def wrap_method(method):  # -> _WrappedMethod:

    ...
