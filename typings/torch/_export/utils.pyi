import torch
from inspect import Parameter
from typing import Any, Optional, TYPE_CHECKING, Union
from collections.abc import Callable
from torch.export import ExportedProgram
from torch.export.graph_signature import ExportGraphSignature
from torch.utils._pytree import FlattenFunc, FromDumpableContextFn, KeyPath, ToDumpableContextFn, UnflattenFunc

if TYPE_CHECKING: ...
placeholder_prefixes = ...
_DISABLE_ATEN_TO_ASSERTION_PASS = ...

def get_keystr(key_path: KeyPath) -> str: ...
def register_dataclass_as_pytree_node(
    cls: type[Any],
    flatten_fn: FlattenFunc | None = ...,
    unflatten_fn: UnflattenFunc | None = ...,
    *,
    serialized_type_name: str | None = ...,
    to_dumpable_context: ToDumpableContextFn | None = ...,
    from_dumpable_context: FromDumpableContextFn | None = ...,
    return_none_fields: bool = ...,
) -> None: ...
def is_param(program: ExportedProgram, node: torch.fx.Node) -> bool: ...
def get_param(program: ExportedProgram, node: torch.fx.Node) -> torch.nn.Parameter | None: ...
def is_buffer(program: ExportedProgram, node: torch.fx.Node) -> bool: ...
def get_buffer(program: ExportedProgram, node: torch.fx.Node) -> torch.Tensor | None: ...
def is_lifted_tensor_constant(program: ExportedProgram, node: torch.fx.Node) -> bool: ...
def get_lifted_tensor_constant(program: ExportedProgram, node: torch.fx.Node) -> torch.Tensor | None: ...
def sequential_split(
    gm: torch.fx.GraphModule, node_call_back: Callable[[torch.fx.Node], torch.fx.Node | bool]
) -> torch.fx.GraphModule: ...
def nodes_filter(nodes: list[torch.fx.Node], node_call_back) -> list[torch.fx.Node]: ...
def apply_runtime_assertion_pass(gm: torch.fx.GraphModule, graph_signature):  # -> tuple[GraphModule, Any]:
    ...
def nodes_first(nodes: list[torch.fx.Node], node_call_back=...) -> torch.fx.Node | None: ...
def nodes_count(nodes: list[torch.fx.Node], node_call_back) -> int: ...
def nodes_map(nodes: list[torch.fx.Node], node_call_back) -> list[torch.fx.Node]: ...
def node_replace_(old_node: torch.fx.Node, new_node: torch.fx.Node) -> None: ...
def node_inline_(call_mod_node: torch.fx.Node) -> torch.fx.GraphModule | None: ...
def placeholder_naming_pass(
    gm: torch.fx.GraphModule,
    export_graph_signature: ExportGraphSignature,
    mod: torch.nn.Module,
    fake_args,
    fake_kwargs,
    fake_params_buffers,
    constants: dict[str, Any],
) -> None: ...
def remove_proxy_from_state_dict(state_dict: dict, in_place: bool) -> dict: ...
def register_module_as_pytree_input_node(cls: type[torch.nn.Module]) -> None: ...
def deregister_module_as_pytree_input_node(cls: type[torch.nn.Module]) -> None: ...
def sync_state(*wrapped_method_modules):  # -> None:

    ...

class _WrappedMethod(torch.nn.Module):
    def __init__(self, method) -> None: ...

def wrap_method(method):  # -> _WrappedMethod:

    ...
