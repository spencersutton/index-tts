import dataclasses
from collections.abc import Iterable
from typing import Any

import torch

@dataclasses.dataclass
class SubclassCreationMeta:
    """SubclassCreationMeta(start_idx: int, num_tensors: int, class_type: Any, attrs: dict[str, 'SubclassCreationMeta'], metadata: Any, outer_size: collections.abc.Iterable[typing.Union[NoneType, int, torch.SymInt]], outer_stride: collections.abc.Iterable[typing.Union[NoneType, int, torch.SymInt]])"""

    start_idx: int
    num_tensors: int
    class_type: Any
    attrs: dict[str, SubclassCreationMeta]
    metadata: Any
    outer_size: Iterable[None | int | torch.SymInt]
    outer_stride: Iterable[None | int | torch.SymInt]

class UnwrapTensorSubclass(torch.nn.Module):
    def forward(self, *tensors) -> torch.Tensor: ...
    def right_inverse(self, tensor: torch.Tensor) -> list[torch.Tensor]: ...

def unwrap_tensor_subclass_parameters(module: torch.nn.Module) -> torch.nn.Module:
    """
    Model transformation that replaces all the parameters that are subclasses to plain tensors.
    This reduces runtime overhead of flattening/unflattening the parameters.

    This transformation adds parametrization with `torch.nn.utils.parametrize`.
    The FQNs of the subclass parameters will be changed and state_dict will become incompatible with the original model.
    E.g.
    Original model state_dict: {"p1": torch.testing._internal.TwoTensor}
    becomes: {"parametrizations.p2.original0": torch.Tensor, "parametrizations.p2.original1": torch.Tensor}
    """
