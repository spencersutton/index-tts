import contextlib
from collections.abc import Callable
from typing import Any

import torch
from torch._functorch.utils import argnums_t, exposed_in

from .vmap import doesnt_support_saved_tensors_hooks

def lazy_dynamo_disallow(func): ...
@contextlib.contextmanager
def enable_inplace_requires_grad(enabled): ...
@exposed_in("torch.func")
def vjp(func: Callable, *primals, has_aux: bool = ...): ...
@contextlib.contextmanager
def grad_increment_nesting(): ...
def enter_jvp_nesting(): ...
def exit_jvp_nesting(): ...
@contextlib.contextmanager
def jvp_increment_nesting(): ...
def error_if_complex(func_name, args, is_input): ...
@exposed_in("torch.func")
def jacrev(
    func: Callable,
    argnums: int | tuple[int] = ...,
    *,
    has_aux=...,
    chunk_size: int | None = ...,
    _preallocate_and_copy=...,
): ...

JVP_NESTING = ...

def assert_flat_tuple_of_tensors(elts: Any, api: str, argname: str) -> None: ...
def assert_non_empty_tensor_output(output: list[Any], api: str) -> None: ...
def assert_output_is_tensor_or_tensors(output: Any, api: str) -> None: ...
def assert_non_empty_list_of_tensors(output: list[torch.Tensor], api: str, argname: str) -> None: ...

jvp_str = ...

def safe_unpack_dual(dual, strict): ...
@exposed_in("torch.func")
def jvp(func: Callable, primals: Any, tangents: Any, *, strict: bool = ..., has_aux: bool = ...): ...
def safe_unflatten(tensor, dim, shape): ...
@exposed_in("torch.func")
def jacfwd(func: Callable, argnums: argnums_t = ..., has_aux: bool = ..., *, randomness: str = ...): ...
@exposed_in("torch.func")
def hessian(func, argnums=...): ...
@doesnt_support_saved_tensors_hooks
def grad_and_value_impl(func, argnums, has_aux, args, kwargs) -> Callable: ...
def grad_impl(func: Callable, argnums: argnums_t, has_aux: bool, args, kwargs): ...
@exposed_in("torch.func")
def functionalize(func: Callable, *, remove: str = ...) -> Callable: ...
@exposed_in("torch.func")
def linearize(func: Callable, *primals) -> tuple[Any, Callable]: ...
@exposed_in("torch.func")
def debug_unwrap(tensor: torch.Tensor, *, recurse=...) -> torch.Tensor: ...
