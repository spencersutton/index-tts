import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch._C import DispatchKey
from torch._higher_order_ops.utils import FunctionalizeCtxWrapper, register_fake
from torch._ops import HigherOrderOperator
from torch.fx.experimental.proxy_tensor import ProxyTorchDispatchMode
from torch.fx.graph_module import GraphModule

invoke_subgraph_counter = ...

@dataclass
class OutputMetadata:
    num_fw_outs: int | None = ...
    indexes_with_symint: set[int] = ...
    indexes_with_no_grad: set[int] = ...

class InvokeSubgraphHOP(HigherOrderOperator):
    def __init__(self) -> None: ...
    def __call__(
        self, subgraph: GraphModule | FunctionalizeCtxWrapper, identifier: str | None, *operands
    ):  # -> Any | None:
        ...
    def gen_schema(self, subgraph, identifier, *operands):  # -> FunctionSchema:
        ...

invoke_subgraph = ...

def invoke_subgraph_placeholder(func, *args, **kwargs): ...
def mark_compile_region(fn=...):  # -> Callable[..., Any] | Callable[..., Callable[..., Any]]:

    ...
def get_invoke_subgraph_cache():  # -> None:
    ...
def trace_joint_graph(fn, fw_inputs, fw_outputs):  # -> GraphModule:

    ...
def create_fw_bw_graph(subgraph, operands, grad_outputs=...):  # -> tuple[GraphModule, GraphModule, OutputMetadata]:
    ...
def get_output_metadata(subgraph, *operands):  # -> OutputMetadata:
    ...
def trace_joint_graph_as_bwd(
    subgraph, num_primals, joint_operands, include_key_set, exclude_key_set
):  # -> GraphModule:

    ...

class InvokeSubgraphAutogradOp(torch.autograd.Function):
    @staticmethod
    def forward(ctx, subgraph, identifier, output_metadata, *operands):  # -> Any | None:
        ...
    @staticmethod
    def backward(ctx, *grad_outs):  # -> tuple[None, None, None, *tuple[Any, ...]]:
        ...

@invoke_subgraph.py_autograd_impl
def _(subgraph, identifier, *operands):  # -> Any | None:
    ...
@invoke_subgraph.py_impl(DispatchKey.CompositeExplicitAutograd)
def _(subgraph, identifier, *operands): ...
@invoke_subgraph.py_functionalize_impl
def _(ctx, subgraph, identifier, *operands):  # -> Any:
    ...
@register_fake(invoke_subgraph)
def _(subgraph, identifier, *operands): ...
@invoke_subgraph.py_impl(ProxyTorchDispatchMode)
def _(proxy_mode: ProxyTorchDispatchMode, subgraph, identifier, *operands):  # -> Any | None:
    ...
