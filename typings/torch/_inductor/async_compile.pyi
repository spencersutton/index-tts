import contextlib
import functools
from collections.abc import Callable
from concurrent.futures import Future, ThreadPoolExecutor
from typing import TYPE_CHECKING, Any, Optional

from torch._inductor.codecache import CodeCacheFuture
from torch._inductor.compile_worker.subproc_pool import AnyPool
from torch._inductor.runtime.hints import HalideMeta
from torch._inductor.utils import clear_on_fresh_cache

if TYPE_CHECKING: ...
_cumulative_compile_time = ...
_t0: float | None = ...
kernel_code_log = ...
log = ...
_triton_kernel_metrics: dict[str, dict[str, Any]] | None = ...
size_hints_regex = ...

def pre_fork_setup():  # -> None:

    ...
def caching_device_properties():  # -> None:
    ...

_IS_WINDOWS = ...
log = ...
_pool_set = ...

def shutdown_compile_workers() -> None: ...
def after_fork():  # -> None:

    ...
def get_compile_threads() -> int: ...

@clear_on_fresh_cache
class CompiledTritonKernels:
    _cache: dict[str, CodeCacheFuture] = ...
    @staticmethod
    def key(kernel_src: str):  # -> str:

        ...
    @staticmethod
    def save(kernel_src: str, future: CodeCacheFuture):  # -> None:

        ...
    @staticmethod
    def get(kernel_src: str) -> CodeCacheFuture | None: ...
    @staticmethod
    def cache_clear():  # -> None:
        ...
    @staticmethod
    def remove_future(kernel_src: str) -> None: ...

@contextlib.contextmanager
def async_compile_pool_manager():  # -> Generator[None, Any, None]:

    ...

class AsyncCompile:
    _ready_future: Future[Any] | None = ...
    def __init__(self) -> None: ...
    @staticmethod
    @functools.lru_cache(1)
    def pool() -> ThreadPoolExecutor: ...
    @staticmethod
    @functools.lru_cache(1)
    def process_pool() -> AnyPool: ...
    @classmethod
    def warm_pool(cls) -> None: ...
    @classmethod
    def wait_pool_ready(cls, timeout=...) -> None: ...
    @classmethod
    def submit(cls, task: Callable[..., Any]) -> Any: ...
    @classmethod
    def use_process_pool(cls):  # -> bool:
        ...
    @classmethod
    def quiesce(cls) -> None: ...
    @classmethod
    def wakeup(cls) -> None: ...
    def triton(
        self, kernel_name: str, source_code: str, device_str: str = ...
    ):  # -> Any | StaticAutotunerFuture | CachingAutotuner | LambdaFuture:

        ...
    def multi_kernel(self, *args, **kwargs) -> Any: ...
    def cpp(self, source_code: str):  # -> Any | LambdaFuture:
        ...
    def cpp_pybinding(self, argtypes: list[str], source_code: str):  # -> Any | LambdaFuture:
        ...
    def cuda(self, source_code, dst_file_ext, aot_compile=...):  # -> Any:
        ...
    def rocm(self, source_code, dst_file_ext, aot_compile=...):  # -> Any:
        ...
    def halide(self, meta: HalideMeta, source_code: str):  # -> Any | LambdaFuture:
        ...
    def cutedsl(self, kernel_name: str, source_code: str):  # -> CuteDSLKernelWrapper | LambdaFuture:

        ...
    def wait(self, scope: dict[str, Any]) -> None: ...

def maybe_warm_pool() -> None: ...
