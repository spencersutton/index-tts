import functools
import sympy
import torch
import torch._ops
from typing import Any, Callable, Optional, Protocol, TYPE_CHECKING, Union, TypeAlias
from torch.utils._ordered_set import OrderedSet
from .. import ir
from ..utils import DeferredLineBase, LineContext
from .common import IndentedBuffer
from .wrapper import PythonWrapperCodegen
from collections.abc import Sequence

if TYPE_CHECKING:
    _OUTPUT_ARGS_TYPE: TypeAlias = list[Union[Optional[str], list[Optional[str]]]]

class HasWriteLine(Protocol):
    def writeline(self, line: Union[LineContext, DeferredLineBase, str]) -> None: ...

class CppWrapperCpu(PythonWrapperCodegen):
    def __init__(self) -> None: ...
    @staticmethod
    def create(
        is_subgraph: bool,
        subgraph_name: Optional[str],
        parent_wrapper: Optional[PythonWrapperCodegen],
        partition_signatures: Optional[ir.GraphPartitionSignature] = ...,
    ):  # -> CppWrapperCpu:
        ...
    def write_constant(self, name, hashed):  # -> None:
        ...
    @staticmethod
    def get_device_include_path(device: str) -> str: ...
    def add_device_include(self, device: str) -> None: ...
    def write_header(self):  # -> None:
        ...
    def mark_output_type(self):  # -> None:
        ...
    def write_prefix(self):  # -> None:
        ...
    def write_input_output_info(self, info_kind: str, idx: int, name: str):  # -> None:
        ...
    def codegen_input_symbol_assignment(
        self, name: str, value: ir.TensorBox, bound_vars: OrderedSet[sympy.Symbol]
    ):  # -> None:
        ...
    def generate_input_output_runtime_checks(self):  # -> None:

        ...
    def write_wrapper_decl(self):  # -> None:
        ...
    def codegen_tensor_dtype_var_decl(self, code: IndentedBuffer, name):  # -> None:
        ...
    def codegen_input_size_var_decl(self, code: IndentedBuffer, name):  # -> None:
        ...
    def codegen_input_stride_var_decl(self, code: IndentedBuffer, name):  # -> None:
        ...
    def codegen_input_device_type_var_decl(self, code: IndentedBuffer, name):  # -> None:
        ...
    def codegen_additional_funcs(self):  # -> None:
        ...
    def codegen_model_kernels(self):  # -> None:
        ...

    MSVC_C2026_MAX_STRING_LENGTH = ...
    def codegen_write_arg_with_large_length_string(
        self, arg_name: str, arg_str_val: str, max_truncate_length: int = ...
    ):  # -> None:
        ...
    def codegen_model_constructor(self):  # -> None:

        ...
    def codegen_const_run_driver(self):  # -> None:

        ...
    def generate(self, is_inference):  # -> tuple[ValueWithLineMap, ValueWithLineMap]:
        ...
    def finalize_prefix(self):  # -> None:
        ...
    def codegen_scalar_to_tensor(self, output: str):  # -> str:
        ...
    def codegen_tensor_item(self, dtype: torch.dtype, tensor: str, scalar: str, indented_buffer=...):  # -> None:
        ...
    def generate_return(self, output_refs: list[str]):  # -> None:
        ...
    def generate_before_suffix(self, result):  # -> None:
        ...
    def generate_end(self, result):  # -> None:

        ...
    @staticmethod
    def get_c_shim_func_name(kernel: str, device: str) -> str: ...
    def generate_c_shim_extern_kernel_call(
        self,
        kernel: str,
        args: list[str],
        device: str,
        *,
        debug_args: Optional[list[str]] = ...,
        debug_handle: Optional[int] = ...,
    ) -> None: ...
    def generate_c_shim_extern_kernel_alloc(self, extern_kernel: ir.ExternKernelAlloc, args: list[str]) -> None: ...
    def generate_c_shim_fallback_kernel(self, fallback_kernel: ir.FallbackKernel, args: list[str]) -> None: ...
    def generate_scatter_fallback(
        self, output, inputs, cpp_kernel_name, python_kernel_name, src_is_tensor, reduce, kwargs
    ):  # -> None:
        ...
    def generate_index_put_fallback(self, kernel, x, indices, values, accumulate):  # -> None:
        ...
    def add_benchmark_harness(self, output):  # -> None:
        ...
    def codegen_cpp_sizevar(self, x: sympy.Expr, *, simplify: bool = ...) -> str: ...
    def codegen_sizevar(self, x: sympy.Expr) -> str: ...
    def codegen_tuple_access(self, basename: str, name: str, index: str) -> str: ...
    def codegen_shape_tuple(self, shape: Sequence[sympy.Expr]) -> str: ...
    def ensure_size_computed(self, sym: sympy.Symbol):  # -> None:
        ...
    def codegen_dynamic_scalar(self, node):  # -> None:
        ...
    def codegen_dynamic_select_index(self, node):  # -> None:
        ...
    def make_buffer_free(self, buffer):  # -> str:
        ...
    def make_free_by_names(self, names_to_del: list[str]):  # -> str:
        ...
    def codegen_exact_buffer_reuse(self, old_name: str, new_name: str, del_line: str):  # -> str:
        ...
    def generate_profiler_mark_wrapper_call(self, stack):  # -> None:
        ...
    def generate_start_graph(self):  # -> None:
        ...
    def generate_end_graph(self):  # -> None:
        ...
    def generate_inf_and_nan_checker(self, nodes):  # -> None:
        ...
    def codegen_device(self, device):  # -> str:
        ...
    def codegen_dtype(self, dtype):  # -> str:
        ...
    def codegen_layout(self, layout):  # -> str:
        ...
    def codegen_memory_format(self, memory_format):  # -> str:
        ...
    @functools.cache
    def codegen_int_array_var(
        self, int_array: str, writeline: Callable[..., None], known_statically=..., graph=...
    ):  # -> str:
        ...
    def make_buffer_allocation(self, buffer):  # -> str:
        ...
    def make_allocation(self, name, device, dtype, shape, stride, allocation_shape=..., is_pinned=...):  # -> str:
        ...
    def codegen_alloc_from_pool(self, name, offset, dtype, shape, stride) -> tuple[str, list[str]]: ...
    def codegen_reinterpret_view(
        self, data, size, stride, offset, writeline: Callable[..., None], dtype=...
    ) -> str: ...
    def codegen_device_copy(self, src, dst, non_blocking: Union[bool, str]):  # -> None:

        ...
    def codegen_multi_output(self, node: ir.MultiOutput):  # -> None:
        ...
    def codegen_subgraph_prefix(self, subgraph, outer_inputs, outer_outputs):  # -> None:
        ...
    def codegen_subgraph_suffix(self, subgraph, outer_inputs, outer_outputs):  # -> None:
        ...
    def codegen_invoke_subgraph(self, invoke_subgraph): ...
    def codegen_conditional(self, conditional):  # -> None:
        ...
    def codegen_subgraph(self, subgraph, outer_inputs, outer_outputs):  # -> None:
        ...
    def codegen_while_loop(self, while_loop, stack_output=...):  # -> None:
        ...
    def generate_extern_kernel_args_decl_if_needed(
        self,
        op_overload: Union[torch._ops.OpOverload, torch._ops.HigherOrderOperator],
        raw_args: Sequence[Any],
        output_args: _OUTPUT_ARGS_TYPE,
        raw_outputs: Sequence[ir.Buffer],
    ):  # -> tuple[list[Any], list[Any]]:

        ...
    def generate_fallback_kernel_with_runtime_lookup(
        self,
        buf_name: str,
        python_kernel_name: str,
        get_args: Callable[[], Sequence[str]],
        op_overload: Union[torch._ops.OpOverload, torch._ops.HigherOrderOperator],
        raw_args: Sequence[Any],
        outputs: Sequence[ir.Buffer],
    ) -> None: ...
    def generate_scoped_gil_acquire(
        self, declarations_before_scope, lines_in_scope
    ):  # -> list[DeferredLineBase | LineContext | str]:
        ...
    def load_custom_op_wrapper(self):  # -> None:
        ...
    def generate_float_value(self, val):  # -> str:
        ...
    def generate_py_arg(self, py_args_var, idx, raw_arg, arg_type):  # -> LiteralString:
        ...
    def generate_fallback_kernel_with_runtime_lookup_nopython(
        self,
        get_args: Callable[[], Sequence[str]],
        op_overload: torch._ops.OpOverload,
        output_args: Sequence[Optional[str]],
        raw_outputs: Sequence[ir.Buffer],
    ) -> None: ...
    def generate_fallback_kernel_with_runtime_lookup_python(
        self,
        buf_name: str,
        python_kernel_name: str,
        op_overload: torch._ops.OpOverload,
        raw_args: Sequence[Any],
        output_args: Sequence[Optional[str]],
        raw_outputs: Sequence[ir.Buffer],
    ) -> None: ...
    def generate_fallback_kernel_with_runtime_lookup_aot(
        self,
        op_overload: Union[torch._ops.OpOverload, torch._ops.HigherOrderOperator],
        raw_args: Sequence[Any],
        output_args: _OUTPUT_ARGS_TYPE,
        raw_outputs: Sequence[ir.Buffer],
    ) -> None: ...
    def generate_reset_kernel_saved_flags(self):  # -> None:
        ...
    def generate_save_uncompiled_kernels(self):  # -> None:
        ...
    def c_type_for_prim_type(self, val, type_) -> str: ...
    def val_to_arg_str_for_prim_type(self, val, type_) -> str: ...
    def val_to_arg_str(self, val, type_=...) -> str: ...
    def create_tmp_raii_handle_var_if_needed(
        self, handle: str, writer: Optional[Union[HasWriteLine, list[str]]] = ...
    ) -> str: ...
