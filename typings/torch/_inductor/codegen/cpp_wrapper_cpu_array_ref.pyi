from collections.abc import Callable, Sequence
from typing import Any

import torch
import torch._ops

from .. import ir
from .cpp_wrapper_cpu import CppWrapperCpu
from .wrapper import BufferLike, PythonWrapperCodegen

BufferName = str
MAX_STACK_ALLOCATION_SIZE = ...

class CppWrapperCpuArrayRef(CppWrapperCpu):
    def __init__(self) -> None: ...
    @staticmethod
    def create(
        is_subgraph: bool,
        subgraph_name: str | None,
        parent_wrapper: PythonWrapperCodegen | None,
        partition_signatures: ir.GraphPartitionSignature | None = ...,
    ): ...
    @staticmethod
    def get_input_cpp_type(input): ...
    @staticmethod
    def get_device_include_path(device: str) -> str: ...
    def codegen_input_numel_asserts(self): ...
    def generate_extern_kernel_alloc(self, *args, **kwargs): ...
    def generate_extern_kernel_out(self, *args, **kwargs): ...
    def generate_fallback_kernel(self, node: ir.FallbackKernel) -> None: ...
    def write_wrapper_decl(self): ...
    def generate_return(self, output_refs: list[str]): ...
    def memory_plan(self): ...
    def memory_plan_reuse(self): ...
    def can_stack_allocate_buffer(self, buffer): ...
    def make_buffer_free(self, buffer): ...
    def make_buffer_allocation(self, buffer): ...
    def make_allocation(self, name, device, dtype, shape, stride, buffer_if_can_stack_allocate=..., is_pinned=...): ...
    def make_buffer_reuse(self, old: BufferLike, new: BufferLike, delete_old: bool): ...
    def is_safe_to_use_borrow_arrayref_tensor_as_tensor(self): ...
    def generate_c_shim_extern_kernel_call(self, kernel: str, args: list[str], device: str, **_) -> None: ...
    def generate_scatter_fallback(
        self, output, inputs, cpp_kernel_name, python_kernel_name, src_is_tensor, reduce, kwargs
    ): ...
    def generate_index_put_fallback(self, kernel, x, indices, values, accumulate): ...
    def generate_fallback_kernel_with_runtime_lookup(
        self,
        buf_name: str,
        python_kernel_name: str,
        get_args: Callable[[], Sequence[str]],
        op_overload: torch._ops.OpOverload | torch._ops.HigherOrderOperator,
        raw_args: Sequence[Any],
        outputs: Sequence[ir.Buffer],
    ) -> None: ...
    def codegen_device_copy(self, src, dst, non_blocking: bool | str): ...
    def codegen_reinterpret_view(
        self, data, size, stride, offset, writeline: Callable[..., None], dtype=...
    ) -> str: ...
    def val_to_arg_str(self, val, type_=...) -> str: ...
    def codegen_tensor_item(self, dtype: torch.dtype, tensor: str, scalar: str, indented_buffer=...): ...
