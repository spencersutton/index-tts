import contextlib
import dataclasses
import functools
from collections.abc import Callable, Iterator, Sequence
from typing import IO, Any, Optional, TypeAlias, Union

import torch
from torch import fx as fx
from torch.fx.graph_module import GraphModule
from torch.fx.passes.shape_prop import TensorMetadata
from torch.types import FileLike

from . import ir
from .ir import ExternKernel
from .scheduler import BaseSchedulerNode

log = ...
GRAPH_EXECUTION_ORDER: list[dict[str, object]] | None = ...
RECORD_GRAPH_EXECUTION: bool = ...
GRAPH_COMPILE_IDS: dict[int, str | None] | None = ...
ir_pre_fusion_log = ...
ir_post_fusion_log = ...
type SchedulerNodeList = list[Any]
BufMeta = ...
GRAPHVIZ_COMMAND_SCALABLE = ...

@functools.cache
def has_dot() -> bool: ...
def draw_buffers(nodes: list[BaseSchedulerNode], print_graph: bool = ..., fname: str | None = ...) -> None: ...
def create_fx_from_snodes(snodes: list[BaseSchedulerNode]) -> fx.Graph: ...
def update_orig_fx_node_name_to_buf_name(
    nodes: SchedulerNodeList | None,
    node_name_to_buf_name: dict[str, str],
    parent_buf_name: str | None = ...,
    n_origins: int = ...,
) -> None: ...
def get_node_name_to_buf_meta(node_name_to_buf_name: dict[str, str]) -> dict[str, BufMeta]: ...
def annotate_orig_fx_with_snodes(gm: torch.fx.GraphModule, snodes: SchedulerNodeList) -> None: ...
@contextlib.contextmanager
def enable_aot_logging() -> Iterator[None]: ...

_inductor_post_to_pre_grad_nodes: dict[str, dict[str, list[str]]] = ...
_inductor_triton_kernel_to_post_grad_node_info: dict[str, list[str]] = ...
_pre_grad_graph_id: int | None = ...
_inductor_pre_grad_node_stack_trace: dict[str, str] = ...
_inductor_kernel_stack_trace: dict[str, list[str]] = ...
_inductor_kernel_provenance_debug_handle: int = ...

def reset_inductor_kernel_provenance_debug_handle() -> None: ...
@contextlib.contextmanager
def reset_provenance_globals() -> Iterator[None]: ...

class DebugContext:
    _counter = ...
    @staticmethod
    def create_debug_dir(folder_name: str) -> str | None: ...
    def __init__(self) -> None: ...
    def copy(self, new_path: str) -> None: ...
    def fopen(self, filename: str, write_mode: str = ..., *args: Any, **kwargs: Any) -> IO[Any]: ...
    @contextlib.contextmanager
    def fopen_context(self, filename: str, write_mode: str = ..., *args: Any, **kwargs: Any) -> Iterator[IO[Any]]: ...
    def filename(self, suffix: str) -> str: ...
    def upload_tar(self) -> None: ...
    def __enter__(self) -> None: ...
    def __exit__(
        self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: Any | None
    ) -> None: ...
    def __getattr__(self, name: str) -> Callable[..., None] | None: ...

class DebugFormatter:
    def __init__(self, handler: DebugContext) -> None: ...
    def fx_graph(self, gm: torch.fx.GraphModule, inputs: list[torch.Tensor]) -> None: ...
    def fx_graph_transformed(self, gm: torch.fx.GraphModule, inputs: list[torch.Tensor]) -> None: ...
    def ir_pre_fusion(self, nodes: SchedulerNodeList) -> None: ...
    def ir_post_fusion(self, nodes: SchedulerNodeList) -> None: ...
    def graph_diagram(self, nodes: SchedulerNodeList) -> None: ...
    def draw_orig_fx_graph(self, gm: torch.fx.GraphModule, nodes: SchedulerNodeList) -> None: ...
    def output_code(self, filename: str, extension: str = ...) -> None: ...
    def log_autotuning_results(
        self,
        name: str,
        input_nodes: list[ir.IRNode],
        timings: dict[ChoiceCaller, float],
        elapse: float,
        precompile_elapse: float,
        prescreening_elapse: float | None,
    ) -> None: ...

def log_ir_pre_fusion(nodes: SchedulerNodeList) -> None: ...
def log_ir_post_fusion(nodes: SchedulerNodeList) -> None: ...
def log_collective_schedule(nodes: Sequence[BaseSchedulerNode]) -> None: ...
def log_runtime_and_tensor_meta(node_runtimes: Sequence[tuple[Any, float]]) -> None: ...
def log_graph_execution() -> None: ...
@contextlib.contextmanager
def record_and_log_graph_execution_order() -> Iterator[None]: ...

@dataclasses.dataclass
class TensorMetadataHolder:
    tensor_metadata: TensorMetadata
    device: torch.device

save_args_cnt = ...

def create_mapping_pre_post_grad_nodes(
    pre_grad_graph_id: int | None, post_to_pre_grad_nodes_json: dict[str, Any]
) -> dict[str, dict[str, list[str]]]: ...
def create_node_mapping_kernel_to_post_grad(
    triton_kernel_to_post_grad_json: dict[str, Any],
) -> dict[str, dict[str, Any]]: ...
def dump_inductor_provenance_info() -> dict[str, Any]: ...
def create_kernel_information_json() -> dict[str, dict[str, list[str]]]: ...
def set_kernel_post_grad_provenance_tracing(
    node_schedule: Sequence[BaseSchedulerNode] | ExternKernel, kernel_name: str, is_extern: bool = ...
) -> int | None: ...
def save_args_for_compile_fx_inner(*args: Any, **kwargs: Any) -> None: ...
def load_args_and_run_compile_fx_inner(path: str) -> Any: ...
def aot_inductor_minifier_wrapper(
    func: Callable[..., str],
    exported_program: torch.export.ExportedProgram,
    *,
    inductor_configs: dict[str, Any],
    package_path: FileLike | None = ...,
) -> str: ...
