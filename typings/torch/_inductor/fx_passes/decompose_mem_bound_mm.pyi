import torch
from torch import Tensor

from .. import config
from ..pattern_matcher import Arg, CallFunction, Match, register_graph_pattern
from .split_cat import construct_pattern_matcher_pass

aten = ...
log = ...
MIN_FIRST_DIMENSION_DECOMPOSITION = ...
MAX_OTHER_DIMENSION_DECOMPOSITION = ...
CPU_MAX_FIRST_DIMENSION_DECOMPOSITION = ...
CPU_MAX_OTHER_DIMENSION_DECOMPOSITION = ...
min_first_dimension_decomposition = ...
max_other_dimension_decomposition = ...
cpu_max_first_dimension_decomposition = ...
cpu_max_other_dimension_decomposition = ...
if "decompose_mm_pass" in config.post_grad_fusion_options:
    min_first_dimension_decomposition = ...
    max_other_dimension_decomposition = ...
    cpu_max_first_dimension_decomposition = ...
    cpu_max_other_dimension_decomposition = ...

def check_device(a: Tensor, b: Tensor, device=...) -> bool: ...
def realize_inputs(inputs: list[torch.fx.Node]): ...
def should_decompose_bmm(mat1, mat2) -> bool: ...
def should_decompose_mm(mat1, mat2) -> bool:
    """
    Determines whether matrix multiplication (mm) should be decomposed into pointwise operations
    based on the input matrices' metadata, shapes, device placement, and configuration options.
    Args:
        mat1: The first matrix operand. Expected to be an object with a `.meta` attribute containing
              a "val" key, or a tensor-like object with a `.shape` attribute.
        mat2: The second matrix operand. Same requirements as `mat1`.
    Returns:
        bool: True if the matrix multiplication should be decomposed according to the following logic:
            - Both inputs must have valid node metadata.
            - Both matrices must be 2-dimensional.
            - If the configuration option `skip_dynamic_shape_dim_check` is False:
                - Decomposition is only considered for statically-shaped matrices.
                - For CUDA devices: `mat1.shape[0]` must be at least `min_first_dimension_decomposition`,
                  and both dimensions of `mat2` must be less than `max_other_dimension_decomposition`.
                - For CPU devices: All relevant dimensions must be less than or equal to their respective
                  CPU decomposition thresholds.
            - If `skip_dynamic_shape_dim_check` is True:
                - Decomposition is considered for dynamic shapes as well, using a combination of
                  `statically_known_true` and `statically_known_false` checks to handle uncertainty.
                - The same dimension and device checks apply, but allow for dynamic/static uncertainty.
            - Returns False if any of the above conditions are not met.
    Notes:
        - Relies on helper functions such as `is_node_meta_valid`, `check_device`, `statically_known_true`,
          and `statically_known_false`, as well as configuration values like
          `min_first_dimension_decomposition`, `max_other_dimension_decomposition`, etc.
        - Designed for use in graph optimization or fusion passes where decomposing large or dynamic
          matrix multiplications can improve performance or memory usage.
    """

def print_decompose_pattern(match: Match, inputs: list[torch.fx.Node]): ...
@register_graph_pattern(
    CallFunction(aten.bmm, Arg(), Arg()), pass_dict=construct_pattern_matcher_pass("decompose_mm_pass")
)
def decompose_bmm(match: Match, mat1: torch.fx.Node, mat2: torch.fx.Node): ...
@register_graph_pattern(
    CallFunction(aten.addmm, Arg(), Arg(), Arg()), pass_dict=construct_pattern_matcher_pass("decompose_mm_pass")
)
def decompose_addmm(match: Match, mat1: torch.fx.Node, mat2: torch.fx.Node, mat3: torch.fx.Node): ...
@register_graph_pattern(
    CallFunction(aten.mm, Arg(), Arg()), pass_dict=construct_pattern_matcher_pass("decompose_mm_pass")
)
def decompose_mm(match: Match, mat1: torch.fx.Node, mat2: torch.fx.Node): ...
