import functools
import torch
from ..pattern_matcher import CallFunction, Ignored, KeywordArg, Match, init_once_fakemode, register_graph_pattern

aten = ...
pass_patterns = ...
binary_folding_pass = ...

def freezing_passes(gm: torch.fx.GraphModule, aot_example_inputs):  # -> None:

    ...
@init_once_fakemode
def lazy_init():  # -> None:
    ...
def register_freezing_graph_pattern(
    pattern, extra_check=..., pass_number=...
):  # -> Callable[[Callable[..., Any]], Callable[..., Any]]:
    ...
def register_binary_folding_pattern(pattern, extra_check=...):  # -> Callable[[Callable[..., Any]], Callable[..., Any]]:
    ...
@functools.cache
def addmm_patterns_init():  # -> None:

    ...
def same_dtype(match): ...
@register_graph_pattern(
    CallFunction(torch.ops.prims.convert_element_type.default, Ignored(), KeywordArg("dtype")),
    pass_dict=pass_patterns[0],
    extra_check=same_dtype,
)
def unnecessary_dtype_convert(match: Match, **kwargs):  # -> None:

    ...
