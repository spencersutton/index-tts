import functools
from typing import Any, Optional
from ..codegen.subgraph import SubgraphChoiceCaller, SubgraphTemplate
from ..ir import Buffer, Layout
from ..lowering import register_lowering

triton_version = ...
has_triton = ...
log = ...
aten = ...
prims = ...
mm_template = ...
persistent_tma_mm_template = ...
load_scales = ...
apply_scaling = ...
device_tma = ...
scaled_mm_device_tma_template = ...

@functools.cache
def lazy_register_extern_choice(fn):  # -> ExternKernelChoice:
    ...

aten_mm = ...
aten_addmm = ...
aten__int_mm = ...
aten__sparse_semi_structured_mm = ...
aten__fp8_mm = ...

def bias_addmm(inp, mat1, mat2, *, out=..., alpha=..., beta=...):  # -> Tensor:

    ...
def check_supported_striding(mat_a, mat_b) -> None: ...

aten_bias_addmm = ...

def decomposeK(a, b, k_splits):  # -> Tensor:
    ...

class DecomposeKSugraphTemplate(SubgraphTemplate):
    def __init__(self) -> None: ...
    def generate(self, input_nodes: list[Buffer], layout: Layout, k_split: int) -> SubgraphChoiceCaller: ...

decompose_k_subgraph_template = ...

class ContiguousTemplate(SubgraphTemplate):
    def __init__(self, name: str, description: str, fn: Any) -> None: ...
    def generate(self, input_nodes: list[Buffer], layout: Layout) -> SubgraphChoiceCaller: ...

def contiguous_mm(a, b):  # -> Tensor:
    ...
def contiguous_addmm(inp, a, b):  # -> Tensor:
    ...

mm_contiguous_subgraph_template = ...
addmm_contiguous_subgraph_template = ...

@register_lowering(aten.mm, type_promotion_kind=None)
def tuned_mm(mat1, mat2, *, layout=...):  # -> TensorBox | ShapeAsConstantBuffer:

    ...
@register_lowering(aten._int_mm, type_promotion_kind=None)
def tuned_int_mm(mat1, mat2, *, layout=...):  # -> TensorBox | ShapeAsConstantBuffer:
    ...
@register_lowering(aten.addmm, type_promotion_kind=None)
def tuned_addmm(inp, mat1, mat2, *, alpha=..., beta=..., layout=...):  # -> TensorBox | ShapeAsConstantBuffer:

    ...
@register_lowering(aten._sparse_semi_structured_mm, type_promotion_kind=None)
def tuned_sparse_semi_structured_mm(
    mat1, mat1_meta, mat2, *, out_dtype=..., layout=...
):  # -> TensorBox | ShapeAsConstantBuffer:
    ...
@register_lowering(aten._scaled_mm.default, type_promotion_kind=None)
def tuned_scaled_mm(
    mat_a, mat_b, scale_a, scale_b, bias=..., scale_result=..., out_dtype=..., use_fast_accum=..., layout=...
):  # -> TensorBox | ShapeAsConstantBuffer:

    ...
def dims_are_int(dims):  # -> bool:
    ...
def mm_autoheuristic(
    mat1, mat2, m, n, k, choices, name, input_nodes, ops, precondition, top_k: int | None = ..., always_included=...
):  # -> list[ChoiceCaller] | ChoiceCaller | None:
    ...
def get_size_hints(mat1, mat2, m, n, k):  # -> tuple[int, int, int]:
    ...
def get_size_hints_strides(mat1, mat2):  # -> tuple[Any, Any]:
    ...
