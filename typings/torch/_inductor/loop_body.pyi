import collections
from collections.abc import Callable
from enum import Enum
from typing import Any, NamedTuple, TypeVar

import sympy
import torch.fx
from torch.fx.proxy import TracerBase

from .ops_handler import DefaultHandler, OpsHandler, WrapperHandler
from .utils import cache_on_self

T = TypeVar("T")

class InterpreterShim(torch.fx.Interpreter):
    def __init__(self, graph, submodules) -> None: ...
    def run_node(self, n: torch.fx.Node) -> Any: ...
    def run(self, *args, **kwargs): ...

class LightTracer(TracerBase):
    def __init__(self) -> None: ...

class MemoryEntry(NamedTuple):
    index_name: str
    buffer_name: str | None
    mode: str | None

class MemoryUsageType(Enum):
    LOAD = ...
    LOAD_SEED = ...
    STORE = ...
    STORE_REDUCTION = ...
    INDEX_EXPR = ...
    CHECK_BOUNDS = ...
    BUCKETIZE = ...

class LoopBody:
    indexing_exprs: dict[str, sympy.Expr]
    indexing_exprs_name: dict[sympy.Expr, str]
    submodules: dict[str, Any]
    subblocks: dict[str, LoopBodyBlock]
    indirect_vars: list[sympy.Symbol]
    indirect_var_ranges: dict[sympy.Symbol, sympy.Expr]
    root_block: LoopBodyBlock
    memory_usage: dict[MemoryUsageType, list[MemoryEntry]]
    op_counts: collections.Counter[str]
    def __init__(self, fn, args, var_ranges, iter_vars, reduce_vars) -> None: ...
    def has_op(self, name: str): ...
    def merge_loops(self) -> LoopBody: ...
    def expand_dimension_for_pointwise_node(self, dimension: int, new_range: int) -> LoopBody: ...
    def reorder_iter_loops(self, new_order) -> LoopBody: ...
    @property
    def vars(self): ...
    @cache_on_self
    def get_nodes(self): ...
    @cache_on_self
    def bounds(self): ...
    def get_read_expr(self, buffer_name): ...
    def get_write_expr(self, buffer_name): ...
    def get_read_exprs(self): ...
    def get_all_read_expr(self, buffer_name): ...
    def get_write_exprs(self): ...
    def get_all_write_expr(self, buffer_name): ...
    def debug_str(self): ...
    def is_memory_copy(self) -> bool: ...

    __repr__ = ...
    def add_index_expr(
        self, expr: sympy.Expr, mtype: MemoryUsageType, buffer_name: str | None = ..., mode: str | None = ...
    ): ...
    def add_submodule(self, block, prefix): ...
    def add_indirect(self, size): ...
    def replace_indirect(self, old, new): ...
    def get_index(self, name): ...
    def indexing_from_args(self, indices): ...
    def __call__(self, *indices): ...
    def bind_set_indirect_shim(self, var, size, check, wrap_neg): ...
    def bind_scan_shim(self, combine_fn): ...
    def bind_masked_shim(self, name): ...

class LoopBodyBlock:
    def __init__(self, body: LoopBody, fn: Callable[..., Any], args: list[Any]) -> None: ...
    def __call__(self): ...
    def debug_str(self, name=...): ...
    def contains_only_ops(self, allowed_ops) -> bool: ...
    def clone(self, body: LoopBody): ...

class CountOps(DefaultHandler):
    def __init__(self, inner: OpsHandler[Any], counts: collections.Counter[str]) -> None: ...

class CaptureIndexing(WrapperHandler):
    name = ...
    def __init__(self, inner: OpsHandler[Any], body: LoopBody, tracer: LightTracer) -> None: ...
    def load(self, name: str, index: sympy.Expr): ...
    def load_seed(self, name: str, index: int): ...
    def store(self, name, index, value, mode=...): ...
    def store_reduction(self, name, index, value): ...
    def reduction(self, dtype, src_dtype, reduction_type, value): ...
    def index_expr(self, index, dtype): ...
    def check_bounds(self, index, size, lower, upper): ...
    def bucketize(
        self,
        values: T,
        boundaries: tuple[str, sympy.Expr, sympy.Expr, sympy.Expr],
        boundary_indices: T,
        indexing_dtype: torch.dtype,
        right: bool,
        sorter: tuple[str, sympy.Expr] | None = ...,
        sorter_indices: T | None = ...,
    ) -> T: ...
    def masked(self, mask_proxy, masked_body: Callable[..., Any], other_proxy): ...
    def scan(
        self, dtype_proxy, combine_fn: Callable[[tuple[Any, ...], tuple[Any, ...]], tuple[Any, ...]], value_proxy
    ): ...
    def sort(self, dtypes, values, stable, descending): ...
    def frexp(self, value_proxy): ...
    def indirect_indexing(self, index_proxy, size, check=..., wrap_neg=...): ...
    def output(self, *result): ...
