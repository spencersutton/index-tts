import functools
import sympy
import torch
from collections.abc import Sequence
from typing import Callable, Optional, Protocol, Union, TypeAlias
from .virtualized import OpsValue

BlockShapeType: TypeAlias = Optional[Sequence[Union[int, str]]]

class ShapeVar(Protocol):
    @property
    def shape(self) -> BlockShapeType: ...

ShapeArg: TypeAlias = Union[ShapeVar, torch.types.Number, str, OpsValue, torch.dtype]

@functools.lru_cache(None)
def get_broadcasted_shape(a: BlockShapeType, b: BlockShapeType) -> BlockShapeType: ...
def broadcast_shapes_for_args(args: Sequence[ShapeArg]) -> BlockShapeType: ...

class ShapePropagationOpsHandler:
    @staticmethod
    def constant(value: torch.types.Number, dtype: torch.dtype) -> BlockShapeType: ...
    @staticmethod
    def store_reduction(name: str, index: int, value: ShapeArg) -> None: ...
    @staticmethod
    def reduction(
        dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: str, value: Union[ShapeArg, tuple[ShapeArg, ...]]
    ) -> Union[BlockShapeType, tuple[BlockShapeType, ...]]: ...
    @staticmethod
    def store(name: str, index: int, value: ShapeArg, mode: Optional[str] = ...) -> None: ...
    @staticmethod
    def to_dtype(
        value: ShapeVar, dtype: torch.dtype, src_dtype: Optional[torch.dtype] = ..., use_compute_types: bool = ...
    ) -> BlockShapeType: ...
    @staticmethod
    def index_expr(expr: sympy.Expr, dtype: torch.dtype) -> BlockShapeType: ...
    @staticmethod
    def load_seed(name: str, offset: int) -> BlockShapeType: ...
    @staticmethod
    def indirect_indexing(
        var: ShapeArg, size: Union[sympy.Expr, int], check: bool = ..., wrap_neg: bool = ...
    ) -> None: ...
    def __getattr__(self, name: str) -> Callable[..., BlockShapeType]: ...
    @staticmethod
    def device_assert_async(cond: ShapeArg, msg: str) -> None: ...
