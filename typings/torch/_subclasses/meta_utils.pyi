import torch
from abc import abstractmethod
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Callable, ClassVar, Generic, NewType, Optional, Protocol, TYPE_CHECKING, TypeVar, Union
from typing_extensions import TypeGuard, TypedDict, Unpack, override
from torch._C._autograd import CreationMeta
from torch._C._functorch import CInterpreter, is_batchedtensor, is_gradtrackingtensor, is_legacy_batchedtensor
from torch.utils._python_dispatch import is_traceable_wrapper_subclass
from collections.abc import Generator
from torch._guards import Source
from torch._subclasses.fake_tensor import FakeTensor, FakeTensorMode
from torch.fx.experimental.symbolic_shapes import ShapeEnv, SymbolicContext

if TYPE_CHECKING: ...
DimList = list
_TensorLikeT = TypeVar("_TensorLikeT", MetaTensorDesc, torch.Tensor)
_T = TypeVar("_T")
_TensorT = TypeVar("_TensorT", bound=torch.Tensor)
_TensorT_cov = TypeVar("_TensorT_cov", bound=torch.Tensor, covariant=True)

def safe_is_leaf(t: Union[MetaTensorDesc, torch.Tensor]) -> bool: ...
def safe_grad(t: _TensorLikeT) -> Optional[_TensorLikeT]: ...
def assert_eq(a: _T, b: _T) -> None: ...

tls = ...

@contextmanager
def disable_inference_mode_for_fake_prop() -> Generator[None, None, None]: ...
def assert_metadata_eq(
    assert_eq: Callable[[object, object], None],
    m1: Union[MetaTensorDesc, torch.Tensor],
    m2: torch.Tensor,
    *,
    skip_symbolic: bool = ...,
    skip_leaf: bool = ...,
) -> None: ...
def is_sparse_coo(t: object) -> TypeGuard[torch.Tensor]: ...
def is_sparse_compressed_layout(layout: torch.layout) -> bool: ...
def is_sparse_compressed(t: object) -> TypeGuard[torch.Tensor]: ...
def is_sparse_any(t: object) -> TypeGuard[torch.Tensor]: ...

MetaStorageId = NewType("MetaStorageId", int)
MetaTensorId = NewType("MetaTensorId", int)
_DescriberId = NewType("_DescriberId", int)
DESCRIBER_NEXT_ID = ...

class MetaTensorDescriber:
    def __init__(self, *, copy_data: bool = ...) -> None: ...
    def get_tensor_id(self, t: torch.Tensor) -> MetaTensorId: ...
    def get_storage_id(self, s: torch.UntypedStorage) -> MetaStorageId: ...
    def describe_storage(self, s: torch.UntypedStorage, *, trace: bool = ...) -> MetaStorageDesc: ...
    def describe_tensor(self, t: torch.Tensor, *, recurse: bool = ..., trace: bool = ...) -> MetaTensorDesc: ...

@dataclass(frozen=True)
class MetaStorageDesc:
    id: MetaStorageId
    size: int
    data: Optional[torch.UntypedStorage]
    def as_json(self, describer_id: _DescriberId) -> dict[str, object]: ...

@dataclass(frozen=True)
class ViewFunc(Generic[_TensorT]):
    @abstractmethod
    def apply(
        self,
        t: _TensorT,
        new_base: _TensorT,
        symint_visitor_fn: Optional[Callable[[int], int]] = ...,
        tensor_visitor_fn: Optional[Callable[[torch.Tensor], _TensorT]] = ...,
    ) -> _TensorT: ...
    @staticmethod
    def from_tensor(t: torch.Tensor) -> ViewFunc: ...

@dataclass(frozen=True)
class _FakeTensorViewFunc(ViewFunc["FakeTensor"]):
    @override
    def apply(
        self,
        t: torch.Tensor,
        new_base: torch.Tensor,
        symint_visitor_fn: Optional[Callable[[int], int]] = ...,
        tensor_visitor_fn: Optional[Callable[[torch.Tensor], FakeTensor]] = ...,
    ) -> FakeTensor: ...

@dataclass(frozen=True)
class _CustomViewFunc(ViewFunc[_TensorT], Generic[_TensorT]):
    func: Callable[
        [torch.Tensor, Optional[Callable[[int], int]], Optional[Callable[[torch.Tensor], _TensorT]]],
        _TensorT,
    ]
    @override
    def apply(
        self,
        t: torch.Tensor,
        new_base: torch.Tensor,
        symint_visitor_fn: Optional[Callable[[int], int]] = ...,
        tensor_visitor_fn: Optional[Callable[[torch.Tensor], _TensorT]] = ...,
    ) -> _TensorT: ...

class _MetaTensorCallback(Protocol, Generic[_TensorT_cov]):
    def __call__(self, arg: Callable[[], torch.Tensor], /, *, device: Union[torch.device, str]) -> _TensorT_cov: ...

class _MetaTensorCallbackKwargs(TypedDict, total=False):
    device: Union[torch.device, str]

class _MetaTensorCallbackOptDevice(Protocol, Generic[_TensorT_cov]):
    def __call__(
        self, arg: Callable[[], torch.Tensor], /, **kwargs: Unpack[_MetaTensorCallbackKwargs]
    ) -> _TensorT_cov: ...

@dataclass(frozen=True)
class MetaTensorDesc(Generic[_TensorT]):
    id: MetaTensorId
    ndim: int
    dtype: torch.dtype
    device: torch.device
    size: tuple[int, ...]
    dynamo_dynamic_indices: list[int]
    dynamo_hint_overrides: dict[int, int]
    layout: torch.layout = ...
    is_inference: bool = ...
    is_leaf: bool = ...
    requires_grad: bool = ...
    is_sparse: bool = ...
    is_mkldnn: bool = ...
    is_functorch_wrapped: bool = ...
    is_batchedtensor: bool = ...
    is_legacy_batchedtensor: bool = ...
    is_gradtrackingtensor: bool = ...
    is_view: bool = ...
    is_nested: bool = ...
    nested_int: Optional[int] = ...
    is_traceable_wrapper_subclass: bool = ...
    is_functional: bool = ...
    is_conj: bool = ...
    is_neg: bool = ...
    is_parameter: bool = ...
    stride: Optional[tuple[int, ...]] = ...
    storage_offset: int = ...
    storage: Optional[MetaStorageDesc] = ...
    sparse_dim: Optional[int] = ...
    dense_dim: Optional[int] = ...
    is_coalesced: Optional[bool] = ...
    crow_indices: Optional[MetaTensorDesc] = ...
    col_indices: Optional[MetaTensorDesc] = ...
    ccol_indices: Optional[MetaTensorDesc] = ...
    row_indices: Optional[MetaTensorDesc] = ...
    values: Optional[MetaTensorDesc] = ...
    unwrapped: Optional[MetaTensorDesc] = ...
    bdim: Optional[int] = ...
    base: Optional[MetaTensorDesc] = ...
    attrs: Optional[dict[str, MetaTensorDesc]] = ...
    creation_meta: Optional[CreationMeta] = ...
    grad: Optional[MetaTensorDesc] = ...
    _UNSERIALIZABLE: ClassVar[set[str]] = ...
    ctx: Optional[object] = ...
    type: Optional[type] = ...
    fake_mode: Optional[FakeTensorMode] = ...
    view_func: Optional[ViewFunc] = ...
    level: Optional[int] = ...
    current_level: Optional[int] = ...
    functorch_stack: Optional[list[CInterpreter]] = ...
    autograd_meta_from: Optional[torch.Tensor] = ...
    data: Optional[torch.Tensor] = ...
    def as_json(self, describer_id: _DescriberId) -> dict[str, object]: ...
    @property
    def shape(self) -> tuple[int, ...]: ...

class MetaConverter(Generic[_TensorT]):
    def __init__(self, *, copy_data: bool = ...) -> None: ...
    def successful(self) -> bool: ...
    def get_tensor_memo(self, t: MetaTensorDesc) -> Optional[torch.Tensor]: ...
    def set_tensor_memo(self, t: MetaTensorDesc, v: _TensorT) -> None: ...
    def get_storage_memo(self, s: MetaStorageDesc) -> Optional[torch.UntypedStorage]: ...
    def set_storage_memo(self, s: MetaStorageDesc, v: torch.UntypedStorage) -> None: ...
    def meta_storage(
        self, s: MetaStorageDesc, callback: Callable[[Callable[[], torch.Tensor]], _TensorT]
    ) -> torch.UntypedStorage: ...
    def meta_tensor(
        self,
        t: MetaTensorDesc,
        shape_env: Optional[ShapeEnv],
        callback_: _MetaTensorCallback[_TensorT],
        source: Optional[Source],
        symbolic_context: Optional[SymbolicContext],
    ) -> _TensorT: ...
    def __call__(
        self,
        t: torch.Tensor,
        shape_env: Optional[ShapeEnv] = ...,
        *,
        callback: Optional[_MetaTensorCallback[_TensorT]] = ...,
        source: Optional[Source] = ...,
        symbolic_context: Optional[SymbolicContext] = ...,
        trace: bool = ...,
    ) -> _TensorT: ...
