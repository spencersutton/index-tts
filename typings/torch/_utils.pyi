import torch
from types import ModuleType
from typing import Callable, Generic, Optional, TYPE_CHECKING
from typing_extensions import ParamSpec, deprecated

def get_tensor_metadata(tensor): ...
def set_tensor_metadata(tensor, metadata):  # -> None:
    ...

_sparse_tensors_to_validate: list[torch.Tensor] = ...
_rebuild_xla_tensor = ...

def annotate(ret, **kwargs):  # -> Callable[..., Any]:
    ...
def render_call(fn, args, kwargs):  # -> str:
    ...

class KeyErrorMessage(str):
    __slots__ = ...
    def __repr__(self):  # -> Self:
        ...

class ExceptionWrapper:
    def __init__(self, exc_info=..., where=...) -> None: ...
    def reraise(self): ...

def get_current_device_index() -> int: ...

class _ClassPropertyDescriptor:
    def __init__(self, fget, fset=...) -> None: ...
    def __get__(self, instance, owner=...): ...

def classproperty(func):  # -> _ClassPropertyDescriptor:
    ...

if TYPE_CHECKING:
    @deprecated(
        "`torch._utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.", category=FutureWarning
    )
    def is_compiling() -> bool: ...

else: ...

class _LazySeedTracker:
    def __init__(self) -> None: ...
    def queue_seed_all(self, cb, traceback):  # -> None:
        ...
    def queue_seed(self, cb, traceback):  # -> None:
        ...
    def get_calls(self) -> list: ...

logger = ...
P = ParamSpec("P")

class CallbackRegistry(Generic[P]):
    def __init__(self, name: str) -> None: ...
    def add_callback(self, cb: Callable[P, None]) -> None: ...
    def fire_callbacks(self, *args: P.args, **kwargs: P.kwargs) -> None: ...

def try_import(module_name: str) -> Optional[ModuleType]: ...

IMPORT_MAPPING = ...
NAME_MAPPING = ...
