from collections import UserString
from collections.abc import Callable
from types import ModuleType
from typing import ParamSpec
from warnings import deprecated

import torch

def get_tensor_metadata(tensor): ...
def set_tensor_metadata(tensor, metadata): ...

_sparse_tensors_to_validate: list[torch.Tensor] = ...
_rebuild_xla_tensor = ...

def annotate(ret, **kwargs): ...
def render_call(fn, args, kwargs): ...

class KeyErrorMessage(UserString):
    """str subclass that returns itself in repr"""

    __slots__ = ...

class ExceptionWrapper:
    """Wraps an exception plus traceback to communicate across threads"""
    def __init__(self, exc_info=..., where=...) -> None: ...
    def reraise(self):
        """Reraises the wrapped exception in the current thread"""

def get_current_device_index() -> int:
    """
    Checks if there are CUDA devices available and
    returns the device index of the current default CUDA device.
    Returns -1 in case there are no CUDA devices available.
    Arguments: ``None``
    """

class _ClassPropertyDescriptor:
    def __init__(self, fget, fset=...) -> None: ...
    def __get__(self, instance, owner=...): ...

def classproperty(func): ...
@deprecated(
    "`torch._utils.is_compiling` is deprecated. Use `torch.compiler.is_compiling` instead.", category=FutureWarning
)
def is_compiling() -> bool:
    """Indicates whether we are tracing/compiling with torch.compile() or torch.export()."""

class _LazySeedTracker:
    def __init__(self) -> None: ...
    def queue_seed_all(self, cb, traceback): ...
    def queue_seed(self, cb, traceback): ...
    def get_calls(self) -> list: ...

logger = ...
P = ParamSpec("P")

class CallbackRegistry[P]:
    def __init__(self, name: str) -> None: ...
    def add_callback(self, cb: Callable[P, None]) -> None: ...
    def fire_callbacks(self, *args: P.args, **kwargs: P.kwargs) -> None: ...

def try_import(module_name: str) -> ModuleType | None: ...

IMPORT_MAPPING = ...
NAME_MAPPING = ...
