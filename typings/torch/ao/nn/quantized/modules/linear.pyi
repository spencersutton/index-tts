import torch
from .utils import WeightedQuantizedModule

__all__ = ["Linear", "LinearPackedParams"]

class LinearPackedParams(torch.nn.Module):
    _version = ...
    def __init__(self, dtype=...) -> None: ...
    @torch.jit.export
    def set_weight_bias(self, weight: torch.Tensor, bias: torch.Tensor | None) -> None: ...
    def forward(self, x): ...

class Linear(WeightedQuantizedModule):
    _version = ...
    _FLOAT_MODULE = ...
    def __init__(self, in_features, out_features, bias_=..., dtype=...) -> None: ...
    def extra_repr(self) -> str: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...
    def weight(self) -> Any: ...
    def bias(self) -> Any: ...
    def set_weight_bias(self, w: torch.Tensor, b: torch.Tensor | None) -> None: ...
    @classmethod
    def from_float(cls, mod, use_precomputed_fake_quant=...) -> Self: ...
    @classmethod
    def from_reference(cls, ref_qlinear, output_scale, output_zero_point) -> Self: ...
