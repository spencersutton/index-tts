import torch
from collections.abc import Callable
from typing import Any, Concatenate, ParamSpec, TypeVar
from warnings import deprecated
from torch import _C

__all__ = [
    "BackwardCFunction",
    "Function",
    "FunctionCtx",
    "FunctionMeta",
    "InplaceFunction",
    "NestedIOFunction",
    "once_differentiable",
]
AUTOGRAD_FUNCTION_COUNTER = ...
_T = TypeVar("_T")
_R = TypeVar("_R")
_P = ParamSpec("_P")

class FunctionCtx:
    def save_for_backward(self, *tensors: torch.Tensor) -> None: ...
    def save_for_forward(self, *tensors: torch.Tensor) -> None: ...
    def mark_dirty(self, *args: torch.Tensor) -> None: ...
    @deprecated(
        "`mark_shared_storage` is deprecated. Tensors with shared storages are automatically tracked. Note that calls to `set_()` are not tracked",
        category=FutureWarning,
    )
    def mark_shared_storage(self, *pairs) -> None: ...
    def mark_non_differentiable(self, *args: torch.Tensor) -> None: ...
    def set_materialize_grads(self, value: bool) -> None: ...

_ContextMethodMixin = FunctionCtx

class _HookMixin: ...

class BackwardCFunction(_C._FunctionBase, FunctionCtx, _HookMixin):
    def apply(self, *args): ...
    def apply_jvp(self, *args): ...

class FunctionMeta(type):
    def __init__(cls, name, bases, attrs) -> None: ...

class _SingleLevelFunction(_C._FunctionBase, FunctionCtx, _HookMixin, metaclass=FunctionMeta):
    @staticmethod
    def forward(*args: Any, **kwargs: Any) -> Any: ...
    @staticmethod
    def setup_context(ctx: Any, inputs: tuple[Any, ...], output: Any) -> Any: ...
    @staticmethod
    def backward(ctx: Any, *grad_outputs: Any) -> Any: ...

    vjp = ...
    @staticmethod
    def jvp(ctx: Any, *grad_inputs: Any) -> Any: ...

class Function(_SingleLevelFunction):
    def __init__(self, *args, **kwargs) -> None: ...
    def __call__(self, *args, **kwargs): ...

    generate_vmap_rule = ...
    @staticmethod
    def vmap(info, in_dims, *args): ...
    @classmethod
    def apply(cls, *args, **kwargs) -> Any | None: ...

def once_differentiable[T, **P, R](fn: Callable[Concatenate[_T, _P], _R]) -> Callable[Concatenate[_T, _P], _R]: ...

class InplaceFunction(Function):
    def __init__(self, inplace=...) -> None: ...

_iter_jit_values = ...
_iter_tensors = ...
_iter_tensors_permissive = ...
_iter_None_tensors = ...
_map_tensor_data = ...

class NestedIOFunction(Function):
    def backward(self, *gradients: Any) -> Any: ...

    __call__ = ...
    def forward(self, *args: Any) -> Any: ...
    def save_for_backward(self, *args: Any) -> None: ...
    @property
    def saved_tensors(self) -> list[Any] | tuple[Any, ...]: ...
    def mark_dirty(self, *args: Any, **kwargs: Any) -> None: ...
    def mark_non_differentiable(self, *args: Any, **kwargs: Any) -> None: ...
    def forward_extended(self, *input: Any) -> None: ...
    def backward_extended(self, *grad_output: Any) -> None: ...
