from contextlib import contextmanager
from functools import lru_cache as _lru_cache
from typing import Any

from torch.backends import PropModule

@_lru_cache
def is_available() -> bool: ...
def get_opt_einsum() -> Any: ...
def set_flags(_enabled=..., _strategy=...) -> tuple[ContextProp | bool, ContextProp | str | None]: ...
@contextmanager
def flags(enabled=..., strategy=...) -> Generator[None, Any, None]: ...

class OptEinsumModule(PropModule):
    def __init__(self, m, name) -> None: ...

    enabled = ...
    strategy = ...
    if is_available():
        strategy = ...

enabled = ...
strategy = ...
