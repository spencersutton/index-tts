from collections.abc import Callable
from typing import Concatenate, ParamSpec, Protocol, TypeVar

from torch import nn
from torch.distributed._composable_state import _State

_T = TypeVar("_T", covariant=True)
_P = ParamSpec("_P")

def generate_state_key(string=...): ...

STATE_KEY = ...
REGISTRY_KEY = ...

class RegistryItem: ...

_TState = TypeVar("_TState", bound=_State, covariant=True)
_M = TypeVar("_M", nn.Module, list[nn.Module])

class _ContractFn[P, T, TState: _State](Protocol):
    def __call__(self, *args: _P.args, **kwargs: _P.kwargs) -> _T: ...
    def state(self, module: nn.Module) -> _TState: ...

def contract[TState: _State](
    state_cls: type[_TState] = ...,
) -> Callable[[Callable[Concatenate[_M, _P], _M]], _ContractFn[Concatenate[_M, _P], _M, _TState]]:
    """
    Decorate a function as a composable distributed API, where the first
    argument of the function must be an :class:`nn.Module` instance or sequence
    of :class:`nn.Module` instances.

    The decorator verifies that the decorated function does not modify
    fully-qualified names (FQNs) for parameters, buffers, or modules. The
    decorated function can return different module instances than the input
    modules; the FQN invariant will be enforced following the input order.

    When a function ``func`` is decorated by ``@contract()``, a
    ``.state(module: nn.Module)`` method will be installed to the decorated
    function. Then you can retrieve and modify the state on a module by calling
    ``func.state(module)``.

    Example::
        >>> # xdoctest: +SKIP
        >>> import torch.nn as nn
        >>>
        >>> class MyModel(nn.Module):
        >>>     def __init__(self) -> None:
        >>>         super().__init__()
        >>>         self.l1 = nn.Linear(10, 10)
        >>>         self.l2 = nn.Linear(10, 10)
        >>>
        >>>     def forward(self, x):
        >>>         return self.l2(self.l1(x))
        >>>
        >>> @contract()
        >>> def my_feature(module: nn.Module) -> nn.Module:
        >>>     my_feature.state(module).some_state = "any value"
        >>>     return module
        >>>
        >>> model = MyModel()
        >>> my_feature(model.l1)
        >>> assert my_feature.state(model.l1).some_state == "any value"
        >>> my_feature(model.l2)
        >>> model(torch.randn(2, 10)).sum().backward()
    """
