from torch.distributed._shard.metadata import ShardMetadata

def validate_non_overlapping_shards_metadata(shards: list[ShardMetadata]): ...
def check_tensor(shards_metadata, tensor_dims) -> None: ...
def get_split_size(dim_size, chunks): ...
def get_chunked_dim_size(dim_size, split_size, idx): ...
def get_chunk_sharding_params(sharding_dim_size, world_size, spec, rank): ...
