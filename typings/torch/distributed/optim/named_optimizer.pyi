from collections.abc import Callable, Collection, Mapping
from typing import Any, overload

import torch
import torch.nn as nn
from torch import optim
from torch.distributed._shard.sharded_tensor import ShardedTensor

__all__: list[str] = ...
logger = ...

class _NamedOptimizer(optim.Optimizer):
    def __init__(
        self,
        named_parameters: Mapping[str, torch.Tensor | ShardedTensor],
        optimizer_class: optim.Optimizer,
        param_groups: Collection[Mapping[str, Any]] | None = ...,
        module: nn.Module | None = ...,
        *args: tuple[Any, ...],
        **kwargs: dict[str, Any],
    ) -> None: ...
    def state_dict(self) -> dict[str, Any]: ...
    @overload
    def step(self, closure: None = ...) -> None: ...
    @overload
    def step(self, closure: Callable[[], float]) -> float: ...
    def step(self, closure: Callable[[], float] | None = ...) -> float | None: ...
    @property
    def state(self) -> Mapping[torch.Tensor, Any]: ...
    def load_state_dict(self, state_dict: dict[str, Any]) -> None: ...
    def add_param_group(self, param_group: Mapping[str, Any]) -> None: ...
    def init_state(self) -> None: ...
