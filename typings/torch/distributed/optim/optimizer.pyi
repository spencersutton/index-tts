from torch import jit, nn

__all__ = ["DistributedOptimizer"]
logger = ...

@jit.interface
class _ScriptLocalOptimizerInterface:
    def step(self, autograd_ctx_id: int) -> None: ...

class _ScriptLocalOptimizer(nn.Module):
    compile_lock = ...
    def __init__(self, optim_cls, local_params_rref, *args, **kwargs) -> None: ...
    @jit.export
    def step(self, autograd_ctx_id: int) -> None: ...

class _LocalOptimizer:
    global_lock = ...
    def __init__(self, optim_cls, local_params_rref, *args, **kwargs) -> None: ...
    def step(self, autograd_ctx_id) -> None: ...

class DistributedOptimizer:
    def __init__(self, optimizer_class, params_rref, *args, **kwargs) -> None: ...
    def step(self, context_id) -> None: ...
