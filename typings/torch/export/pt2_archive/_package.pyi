import logging
import torch
from dataclasses import dataclass
from typing import Any, Optional, TYPE_CHECKING, Union, Self
from typing_extensions import TypeAlias
from torch.export import ExportedProgram
from torch.export.pt2_archive._package_weights import Weights
from torch.types import FileLike

if TYPE_CHECKING: ...
DEFAULT_PICKLE_PROTOCOL = ...
AOTI_FILES: TypeAlias = Union[list[Union[str, Weights]], dict[str, list[Union[str, Weights]]]]
logger: logging.Logger = ...

def is_pt2_package(serialized_model: Union[bytes, str]) -> bool: ...

class PT2ArchiveWriter:
    def __init__(self, archive_path_or_buffer: FileLike) -> None: ...
    def __enter__(self) -> Self: ...
    def __exit__(self, *args: object) -> None: ...
    def has_record(self, name: str) -> bool: ...
    def count_prefix(self, prefix: str) -> int: ...
    def write_bytes(self, name: str, data: bytes) -> None: ...
    def write_string(self, name: str, data: str) -> None: ...
    def write_file(self, name: str, file_path: str) -> None: ...
    def write_folder(self, archive_dir: str, folder_dir: str) -> None: ...
    def close(self) -> None: ...

class PT2ArchiveReader:
    def __init__(self, archive_path_or_buffer: FileLike) -> None: ...
    def __enter__(self) -> Self: ...
    def __exit__(self, *args: object) -> None: ...
    def read_bytes(self, name: str) -> bytes: ...
    def read_string(self, name: str) -> str: ...
    def archive_version(self) -> int: ...
    def get_file_names(self) -> list[str]: ...

def package_pt2(
    f: FileLike,
    *,
    exported_programs: Optional[Union[ExportedProgram, dict[str, ExportedProgram]]] = ...,
    aoti_files: Optional[AOTI_FILES] = ...,
    extra_files: Optional[dict[str, Any]] = ...,
    opset_version: Optional[dict[str, int]] = ...,
    pickle_protocol: int = ...,
) -> FileLike: ...

class AOTICompiledModel:
    def __init__(self, loader: torch._C._aoti.AOTIModelPackageLoader) -> None: ...
    def __call__(self, *args, **kwargs):  # -> PyTree:
        ...
    def get_metadata(self) -> dict[str, str]: ...
    def load_constants(
        self, constants_map: dict[str, torch.Tensor], *, check_full_update: bool, user_managed: bool = ...
    ) -> None: ...
    def get_constant_fqns(self) -> list[str]: ...
    def __deepcopy__(self, memo: Optional[dict[Any, Any]]) -> AOTICompiledModel: ...

@dataclass
class PT2ArchiveContents:
    exported_programs: dict[str, ExportedProgram]
    aoti_runners: dict[str, AOTICompiledModel]
    extra_files: dict[str, Any]

def load_pt2(
    f: FileLike,
    *,
    expected_opset_version: Optional[dict[str, int]] = ...,
    run_single_threaded: bool = ...,
    num_runners: int = ...,
    device_index: int = ...,
    load_weights_from_disk: bool = ...,
) -> PT2ArchiveContents: ...
def load_weights_to_pt2_contents(pt2_contents: PT2ArchiveContents, weights_map: dict[str, Any]) -> None: ...
