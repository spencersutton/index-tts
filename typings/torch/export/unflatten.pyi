import abc
from dataclasses import dataclass
from enum import Enum
from typing import Any

import torch
import torch.utils._pytree as pytree
from torch.export import ExportedProgram
from torch.export.exported_program import ModuleCallSignature

log = ...
__all__ = [
    "FlatArgsAdapter",
    "InterpreterModule",
    "InterpreterModuleDispatcher",
    "UnflattenedModule",
    "unflatten",
]

class _AttrKind(Enum):
    PARAMETER = ...
    BUFFER = ...
    CONSTANT = ...
    MODULE = ...

@dataclass(frozen=True)
class _TensorID:
    untyped_storage: torch.UntypedStorage
    stride: tuple
    size: tuple
    storage_offset: int

RUN_WITH_INTERPRETER = ...

class _SubmoduleBase:
    _ty: str | None
    def type_name(self) -> str | None: ...

class InterpreterModule(_SubmoduleBase, torch.nn.Module):
    graph_module: torch.fx.GraphModule | None
    def __init__(self, graph: torch.fx.Graph, ty: str | None = ...) -> None: ...
    def forward(self, *args, **kwargs) -> Any: ...
    def finalize(self) -> None: ...
    def print_readable(
        self,
        print_output=...,
        include_stride=...,
        include_device=...,
        colored=...,
    ): ...

class InterpreterModuleDispatcher(_SubmoduleBase, torch.nn.Module):
    def __init__(self, attrs: set[str], call_modules: list[InterpreterModule]) -> None: ...
    def forward(self, *args, **kwargs) -> Any: ...
    def call_modules(self) -> list[InterpreterModule]: ...
    def print_readable(
        self,
        print_output=...,
        include_stride=...,
        include_device=...,
        colored=...,
    ) -> LiteralString: ...

class FlatArgsAdapter(abc.ABC):
    @abc.abstractmethod
    def adapt(
        self,
        target_spec: pytree.TreeSpec,
        input_spec: pytree.TreeSpec,
        input_args: list[Any],
        metadata: dict[str, Any] | None = ...,
        obj: Any | None = ...,
    ) -> list[Any]: ...
    def get_flat_arg_paths(self) -> list[str]: ...

class UnflattenedModule(torch.nn.Module):
    def __init__(
        self,
        export_module: ExportedProgram,
        flat_args_adapter: FlatArgsAdapter | None = ...,
    ) -> None: ...
    def process_forward_inputs(self, *args, **kwargs) -> list[Any]: ...
    def forward(self, *args, **kwargs) -> Any | tuple[Any, ...]: ...
    def finalize(self) -> None: ...
    def print_readable(
        self,
        print_output=...,
        include_stride=...,
        include_device=...,
        colored=...,
    ): ...

def unflatten(module: ExportedProgram, flat_args_adapter: FlatArgsAdapter | None = ...) -> UnflattenedModule: ...

class _ModuleFrame:
    def __init__(
        self,
        flat_graph: torch.fx.Graph,
        nodes: tuple[torch.fx.Node, ...],
        seen_nodes,
        seen_modules,
        seen_attrs,
        created_modules,
        parent,
        module_stack: list[tuple[str, str | None, int]],
        module_id,
        module_call_graph: dict[str, ModuleCallSignature],
        module: torch.fx.GraphModule | UnflattenedModule | None = ...,
    ) -> None: ...
    def add_placeholder(self, x) -> None: ...
    def copy_sym_call_function(self, x) -> Node: ...
    def remap_input(self, x) -> Node | Any: ...
    def finalize_outputs(self) -> None: ...
    def copy_node(self, node) -> None: ...
    def run_outer(self) -> None: ...
    def print(self, *args, **kwargs) -> None: ...
    def run_from(self, node_idx) -> None: ...

@dataclass
class _SubmoduleEntry:
    parent_fqn: str
    parent_module: torch.nn.Module
    parent_call_module: torch.fx.Node
    fqn: str
    call_idx: int
    module: torch.nn.Module

class _IVals:
    def __init__(self) -> None: ...
    def read(self, mf, node): ...
    def update(self, partitions) -> None: ...
