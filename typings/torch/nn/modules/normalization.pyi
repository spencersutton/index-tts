import torch
from torch import Size, Tensor, nn

from indextts.util import patch_call

from .module import Module

__all__ = ["CrossMapLRN2d", "GroupNorm", "LayerNorm", "LocalResponseNorm", "RMSNorm"]

class LocalResponseNorm(Module):
    __constants__ = ...
    size: int
    alpha: float
    beta: float
    k: float
    def __init__(self, size: int, alpha: float = ..., beta: float = ..., k: float = ...) -> None: ...
    def forward(self, input: Tensor) -> Tensor: ...
    def extra_repr(self) -> str: ...

class CrossMapLRN2d(Module):
    size: int
    alpha: float
    beta: float
    k: float
    def __init__(self, size: int, alpha: float = ..., beta: float = ..., k: float = ...) -> None: ...
    def forward(self, input: Tensor) -> Tensor: ...
    def extra_repr(self) -> str: ...

type _shape_t = int | list[int] | Size

class LayerNorm(Module):
    __constants__ = ...
    normalized_shape: tuple[int, ...]
    eps: float
    elementwise_affine: bool
    def __init__(
        self,
        normalized_shape: _shape_t,
        eps: float = ...,
        elementwise_affine: bool = ...,
        bias: bool = ...,
        device=...,
        dtype=...,
    ) -> None: ...
    def reset_parameters(self) -> None: ...
    def forward(self, input: Tensor) -> Tensor: ...
    @patch_call(forward)
    def __call__(self) -> None: ...
    def extra_repr(self) -> str: ...
    weight: nn.Parameter

class GroupNorm(Module):
    __constants__ = ...
    num_groups: int
    num_channels: int
    eps: float
    affine: bool
    def __init__(
        self, num_groups: int, num_channels: int, eps: float = ..., affine: bool = ..., device=..., dtype=...
    ) -> None: ...
    def reset_parameters(self) -> None: ...
    def forward(self, input: Tensor) -> Tensor: ...
    def extra_repr(self) -> str: ...
    @patch_call(forward)
    def __call__(self) -> None: ...

class RMSNorm(Module):
    __constants__ = ...
    normalized_shape: tuple[int, ...]
    eps: float | None
    elementwise_affine: bool
    def __init__(
        self, normalized_shape: _shape_t, eps: float | None = ..., elementwise_affine: bool = ..., device=..., dtype=...
    ) -> None: ...
    def reset_parameters(self) -> None: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...
    def extra_repr(self) -> str: ...
