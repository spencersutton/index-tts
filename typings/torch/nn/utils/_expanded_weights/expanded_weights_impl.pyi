from collections.abc import Callable
from contextlib import contextmanager

import torch

HANDLED_FUNCTIONS: dict[Callable, torch.autograd.Function] = ...
aten = ...
expanded_weights_rnn_decomps = ...

@contextmanager
def batch_second(args, kwargs):  # -> Generator[None, Any, None]:
    ...
@contextmanager
def allow_smaller_batches(args, kwargs):  # -> Generator[None, Any, None]:
    ...
@contextmanager
def setup_rnn(use_input_variant, args, kwargs):  # -> Generator[None, Any, None]:
    ...
def implements_per_sample_grads(torch_function):  # -> _Wrapped[..., Any, ..., Any]:
    ...

class ExpandedWeight(torch.Tensor):
    def __init__(self, orig_weight, batch_size, loss_reduction) -> None: ...

    handled_functions = ...
    def __new__(cls, orig_weight, batch_size, loss_reduction):  # -> Self:
        ...
    @classmethod
    def __torch_function__(cls, func, _, args=..., kwargs=...):  # -> Any | None:
        ...
    @property
    def dtype(self): ...
    @property
    def data(self): ...
    @property
    def shape(self): ...
    @property
    def device(self): ...
    @property
    def is_cuda(self): ...
    def data_ptr(self): ...
    def get_device(self): ...
    def set_allow_smaller_batches(self, is_allow_smaller_batches):  # -> None:
        ...
    def set_batch_first(self, is_batch_first=...):  # -> None:
        ...
