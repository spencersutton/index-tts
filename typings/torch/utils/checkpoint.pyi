import contextlib
import enum
from typing import *
from weakref import ReferenceType

import torch
from torch.utils._python_dispatch import TorchDispatchMode

__all__ = [
    "SAC_IGNORED_OPS",
    "CheckpointError",
    "CheckpointFunction",
    "CheckpointPolicy",
    "DefaultDeviceType",
    "SelectiveCheckpointContext",
    "check_backward_validity",
    "checkpoint",
    "checkpoint_sequential",
    "create_selective_checkpoint_contexts",
    "detach_variable",
    "get_device_states",
    "noop_context_fn",
    "set_checkpoint_debug_enabled",
    "set_checkpoint_early_stop",
    "set_device_states",
]
_DEFAULT_DETERMINISM_MODE = ...
_checkpoint_debug_enabled: Optional[bool] = ...

@contextlib.contextmanager
def set_checkpoint_debug_enabled(
    enabled: Optional[bool],
) -> Generator[None, Any, None]: ...
def detach_variable(inputs: Tuple[Any, ...]) -> Tuple[torch.Tensor, ...]: ...
def check_backward_validity(inputs: Iterable[Any]) -> None: ...

class DefaultDeviceType:
    _default_device_type = ...
    @staticmethod
    def set_device_type(device: str = ...) -> None: ...
    @staticmethod
    def get_device_type() -> str: ...

def get_device_states(*args) -> Tuple[List[int], List[torch.Tensor]]: ...
def set_device_states(devices, states, *, device_type=...) -> None: ...

class CheckpointFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, run_function, preserve_rng_state, *args): ...
    @staticmethod
    def backward(ctx, *args) -> tuple[None, None, *tuple[Tensor | None, ...]]: ...

def noop_context_fn() -> tuple[nullcontext[None], nullcontext[None]]: ...
@torch._disable_dynamo
def checkpoint(
    function,
    *args,
    use_reentrant: Optional[bool] = ...,
    context_fn: Callable[[], Tuple[ContextManager, ContextManager]] = ...,
    determinism_check: str = ...,
    debug: bool = ...,
    early_stop: bool = ...,
    **kwargs,
) -> Any | None: ...
def checkpoint_sequential(functions, segments, input, use_reentrant=..., **kwargs): ...

_enable_checkpoint_early_stop: Optional[bool] = ...

@contextlib.contextmanager
def set_checkpoint_early_stop(enable: bool) -> Generator[None, Any, None]: ...

class _Handle: ...

class _Holder:
    def __init__(self) -> None: ...

class _NoopSaveInputs(torch.autograd.Function):
    @staticmethod
    def forward(*args) -> Tensor: ...
    @staticmethod
    def setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any) -> None: ...
    @staticmethod
    def backward(ctx, *grad_outputs): ...

class _CheckpointFrame:
    def __init__(self, recompute_fn, early_stop, unpack_error_cb, metadata_fn) -> None: ...
    def check_recomputed_tensors_match(self, gid) -> None: ...

_debug_tip_msg = ...
_checkpoint_error_template = ...

class CheckpointError(RuntimeError): ...

_allowed_determinism_checks_to_fns: Dict[str, Callable[[torch.Tensor], Any]] = ...

class _StopRecomputationError(Exception): ...

class _recomputation_hook(torch.autograd.graph.saved_tensors_hooks):
    def __init__(self, target_frame_ref: ReferenceType, gid: int) -> None: ...

class _checkpoint_hook(torch.autograd.graph.saved_tensors_hooks):
    def __init__(self, frame) -> None: ...

class _VersionWrapper:
    def __init__(self, val) -> None: ...
    def get_val(self, allow_cache_entry_mutation) -> Tensor | Any: ...

class SelectiveCheckpointContext:
    def __init__(self, *, is_recompute) -> None: ...

class CheckpointPolicy(enum.Enum):
    MUST_SAVE = ...
    PREFER_SAVE = ...
    MUST_RECOMPUTE = ...
    PREFER_RECOMPUTE = ...

SAC_IGNORED_OPS = ...

class _CachingTorchDispatchMode(TorchDispatchMode):
    def __init__(self, policy_fn, storage) -> None: ...
    def __torch_dispatch__(self, func, types, args=..., kwargs=...): ...

class _CachedTorchDispatchMode(TorchDispatchMode):
    def __init__(self, policy_fn, storage, allow_cache_entry_mutation) -> None: ...
    def __torch_dispatch__(self, func, types, args=..., kwargs=...) -> PyTree: ...

def create_selective_checkpoint_contexts(
    policy_fn_or_list, allow_cache_entry_mutation=...
) -> tuple[_CachingTorchDispatchMode, _CachedTorchDispatchMode]: ...
