TORCH_AVAILABLE = ...
SystemEnv = ...
COMMON_PATTERNS = ...
NVIDIA_PATTERNS = ...
ONEAPI_PATTERNS = ...
CONDA_PATTERNS = ...
PIP_PATTERNS = ...

def run(command) -> tuple[int | Any, str, str]:
    """Return (return-code, stdout, stderr)."""

def run_and_read_all(run_lambda, command) -> None:
    """Run command using run_lambda; reads and returns entire output if rc is 0."""

def run_and_parse_first_match(run_lambda, command, regex) -> None:
    """Run command using run_lambda, returns the first regex match if it exists."""

def run_and_return_first_line(run_lambda, command) -> None:
    """Run command using run_lambda and returns first line if output is not empty."""

def get_conda_packages(run_lambda, patterns=...) -> LiteralString | None: ...
def get_gcc_version(run_lambda) -> None: ...
def get_clang_version(run_lambda) -> None: ...
def get_cmake_version(run_lambda) -> None: ...
def get_nvidia_driver_version(run_lambda) -> None: ...
def get_gpu_info(run_lambda) -> str | None: ...
def get_running_cuda_version(run_lambda) -> None: ...
def get_cudnn_version(run_lambda) -> str | LiteralString | None:
    """Return a list of libcudnn.so; it's hard to tell which one is being used."""

def get_nvidia_smi() -> str: ...
def get_linux_pkg_version(run_lambda, pkg_name) -> str: ...
def get_intel_gpu_driver_version(run_lambda) -> LiteralString: ...
def get_intel_gpu_onboard(run_lambda) -> str: ...
def get_intel_gpu_detected(run_lambda) -> str: ...
def get_cpu_info(run_lambda) -> LiteralString | Literal[""]: ...
def get_platform() -> LiteralString | Literal[linux, win32, cygwin, darwin]: ...
def get_mac_version(run_lambda) -> None: ...
def get_windows_version(run_lambda) -> str: ...
def get_lsb_version(run_lambda) -> None: ...
def check_release_file(run_lambda) -> None: ...
def get_os(run_lambda) -> str | LiteralString | None: ...
def get_python_platform() -> str: ...
def get_libc_version() -> str: ...
def get_pip_packages(
    run_lambda, patterns=...
) -> tuple[Literal[pip3, pip], None] | tuple[Literal[pip3, pip], LiteralString]:
    """Return `pip list` output. Note: will also find conda-installed pytorch and numpy packages."""

def get_cachingallocator_config() -> str: ...
def get_cuda_module_loading_config() -> str: ...
def is_xnnpack_available() -> str: ...
def get_env_info() -> SystemEnv:
    """
    Collects environment information to aid in debugging.

    The returned environment information contains details on torch version, is debug build
    or not, cuda compiled version, gcc version, clang version, cmake version, operating
    system, libc version, python version, python platform, CUDA availability, CUDA
    runtime version, CUDA module loading config, GPU model and configuration, Nvidia
    driver version, cuDNN version, pip version and versions of relevant pip and
    conda packages, HIP runtime version, MIOpen runtime version,
    Caching allocator config, XNNPACK availability and CPU information.

    Returns:
        SystemEnv (namedtuple): A tuple containing various environment details
            and system information.
    """

env_info_fmt = ...

def pretty_str(envinfo) -> str: ...
def get_pretty_env_info() -> str:
    """
    Returns a pretty string of environment information.

    This function retrieves environment information by calling the `get_env_info` function
    and then formats the information into a human-readable string. The retrieved environment
    information is listed in the document of `get_env_info`.
    This function is used in `python collect_env.py` that should be executed when reporting a bug.

    Returns:
        str: A pretty string of the environment information.
    """

def main() -> None: ...

if __name__ == "__main__": ...
