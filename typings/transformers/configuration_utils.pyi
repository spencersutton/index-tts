import os
from typing import TYPE_CHECKING, Any, Self, TypeVar

import torch

from .utils import PushToHubMixin

"""Configuration base class and utilities."""
if TYPE_CHECKING: ...
logger = ...
SpecificPretrainedConfigType = TypeVar("SpecificPretrainedConfigType", bound=PretrainedConfig)

class PretrainedConfig(PushToHubMixin):
    model_type: str = ...
    base_config_key: str = ...
    sub_configs: dict[str, type[PretrainedConfig]] = ...
    has_no_defaults_at_init: bool = ...
    attribute_map: dict[str, str] = ...
    base_model_tp_plan: dict[str, Any] | None = ...
    base_model_pp_plan: dict[str, tuple[list[str]]] | None = ...
    _auto_class: str | None = ...
    def __setattr__(self, key, value) -> None:  # -> None:
        ...
    def __getattribute__(self, key):  # -> Any:
        ...
    def __init__(
        self,
        *,
        output_hidden_states: bool = ...,
        output_attentions: bool = ...,
        return_dict: bool = ...,
        torchscript: bool = ...,
        torch_dtype: str | torch.dtype | None = ...,
        pruned_heads: dict[int, list[int]] | None = ...,
        tie_word_embeddings: bool = ...,
        chunk_size_feed_forward: int = ...,
        is_encoder_decoder: bool = ...,
        is_decoder: bool = ...,
        cross_attention_hidden_size: int | None = ...,
        add_cross_attention: bool = ...,
        tie_encoder_decoder: bool = ...,
        architectures: list[str] | None = ...,
        finetuning_task: str | None = ...,
        id2label: dict[int, str] | None = ...,
        label2id: dict[str, int] | None = ...,
        num_labels: int | None = ...,
        task_specific_params: dict[str, Any] | None = ...,
        problem_type: str | None = ...,
        tokenizer_class: str | None = ...,
        prefix: str | None = ...,
        bos_token_id: int | None = ...,
        pad_token_id: int | None = ...,
        eos_token_id: int | None = ...,
        sep_token_id: int | None = ...,
        decoder_start_token_id: int | None = ...,
        **kwargs,
    ) -> None: ...
    @property
    def name_or_path(self) -> str | None: ...
    @name_or_path.setter
    def name_or_path(self, value):  # -> None:
        ...
    @property
    def output_attentions(self):  # -> bool:

        ...
    @output_attentions.setter
    def output_attentions(self, value: bool):  # -> None:
        ...
    @property
    def use_return_dict(self) -> bool: ...
    @property
    def num_labels(self) -> int: ...
    @num_labels.setter
    def num_labels(self, num_labels: int):  # -> None:
        ...
    def save_pretrained(self, save_directory: str | os.PathLike, push_to_hub: bool = ..., **kwargs):  # -> None:

        ...
    @classmethod
    def from_pretrained(
        cls,
        pretrained_model_name_or_path: str | os.PathLike,
        cache_dir: str | os.PathLike | None = ...,
        force_download: bool = ...,
        local_files_only: bool = ...,
        token: str | bool | None = ...,
        revision: str = ...,
        **kwargs,
    ) -> Self: ...
    @classmethod
    def get_config_dict(
        cls, pretrained_model_name_or_path: str | os.PathLike, **kwargs
    ) -> tuple[dict[str, Any], dict[str, Any]]: ...
    @classmethod
    def from_dict(cls, config_dict: dict[str, Any], **kwargs) -> Self: ...
    @classmethod
    def from_json_file(cls, json_file: str | os.PathLike) -> Self: ...
    def __eq__(self, other) -> bool: ...
    def __iter__(self):  # -> Generator[str, Any, None]:
        ...
    def to_diff_dict(self) -> dict[str, Any]: ...
    def to_dict(self) -> dict[str, Any]: ...
    def to_json_string(self, use_diff: bool = ...) -> str: ...
    def to_json_file(self, json_file_path: str | os.PathLike, use_diff: bool = ...):  # -> None:

        ...
    def update(self, config_dict: dict[str, Any]):  # -> None:

        ...
    def update_from_string(self, update_str: str):  # -> None:

        ...
    def dict_torch_dtype_to_str(self, d: dict[str, Any]) -> None: ...
    @classmethod
    def register_for_auto_class(cls, auto_class=...):  # -> None:

        ...
    def get_text_config(self, decoder=...) -> PretrainedConfig: ...
    @classmethod
    def from_text_vision_configs(cls, text_config, vision_config, **kwargs):  # -> Self:

        ...
    @classmethod
    def from_text_audio_configs(cls, text_config, audio_config, **kwargs):  # -> Self:

        ...

def get_configuration_file(configuration_files: list[str]) -> str: ...
def recursive_diff_dict(dict_a, dict_b, config_obj=...):  # -> dict[Any, Any]:

    ...

if PretrainedConfig.push_to_hub.__doc__ is not None: ...
ALLOWED_LAYER_TYPES = ...

def layer_type_validation(layer_types: list[str]):  # -> None:

    ...
