"""
This type stub file was generated by pyright.
"""

import os
import torch
from dataclasses import dataclass
from typing import Callable, Optional, TYPE_CHECKING, TypeAlias, Union
from ..cache_utils import Cache
from ..configuration_utils import PretrainedConfig
from ..utils import ModelOutput, is_accelerate_available
from .configuration_utils import GenerationConfig
from .continuous_batching import ContinuousMixin
from .logits_process import LogitsProcessorList
from .stopping_criteria import StoppingCriteriaList
from ..modeling_utils import PreTrainedModel
from ..tokenization_utils_base import PreTrainedTokenizerBase
from .streamers import BaseStreamer

if TYPE_CHECKING: ...
logger = ...
if is_accelerate_available(): ...
ALL_CACHE_NAMES = ...

@dataclass
class GenerateDecoderOnlyOutput(ModelOutput):
    sequences: torch.LongTensor
    scores: Optional[tuple[torch.FloatTensor]] = ...
    logits: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = ...

@dataclass
class GenerateEncoderDecoderOutput(ModelOutput):
    sequences: torch.LongTensor
    scores: Optional[tuple[torch.FloatTensor]] = ...
    logits: Optional[tuple[torch.FloatTensor]] = ...
    encoder_attentions: Optional[tuple[torch.FloatTensor]] = ...
    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    decoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    cross_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    decoder_hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = ...

@dataclass
class GenerateBeamDecoderOnlyOutput(ModelOutput):
    sequences: torch.LongTensor
    sequences_scores: Optional[torch.FloatTensor] = ...
    scores: Optional[tuple[torch.FloatTensor]] = ...
    logits: Optional[tuple[torch.FloatTensor]] = ...
    beam_indices: Optional[torch.LongTensor] = ...
    attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = ...

@dataclass
class GenerateBeamEncoderDecoderOutput(ModelOutput):
    sequences: torch.LongTensor
    sequences_scores: Optional[torch.FloatTensor] = ...
    scores: Optional[tuple[torch.FloatTensor]] = ...
    logits: Optional[tuple[torch.FloatTensor]] = ...
    beam_indices: Optional[torch.LongTensor] = ...
    encoder_attentions: Optional[tuple[torch.FloatTensor]] = ...
    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    decoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    cross_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    decoder_hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = ...

GreedySearchDecoderOnlyOutput = GenerateDecoderOnlyOutput
ContrastiveSearchDecoderOnlyOutput = GenerateDecoderOnlyOutput
SampleDecoderOnlyOutput = GenerateDecoderOnlyOutput
ContrastiveSearchEncoderDecoderOutput = GenerateEncoderDecoderOutput
GreedySearchEncoderDecoderOutput = GenerateEncoderDecoderOutput
SampleEncoderDecoderOutput = GenerateEncoderDecoderOutput
BeamSearchDecoderOnlyOutput = GenerateBeamDecoderOnlyOutput
BeamSampleDecoderOnlyOutput = GenerateBeamDecoderOnlyOutput
BeamSearchEncoderDecoderOutput = GenerateBeamEncoderDecoderOutput
BeamSampleEncoderDecoderOutput = GenerateBeamEncoderDecoderOutput
GreedySearchOutput: TypeAlias = Union[GreedySearchEncoderDecoderOutput, GreedySearchDecoderOnlyOutput]
SampleOutput: TypeAlias = Union[SampleEncoderDecoderOutput, SampleDecoderOnlyOutput]
BeamSearchOutput: TypeAlias = Union[BeamSearchEncoderDecoderOutput, BeamSearchDecoderOnlyOutput]
BeamSampleOutput: TypeAlias = Union[BeamSampleEncoderDecoderOutput, BeamSampleDecoderOnlyOutput]
ContrastiveSearchOutput: TypeAlias = Union[ContrastiveSearchEncoderDecoderOutput, ContrastiveSearchDecoderOnlyOutput]
GenerateNonBeamOutput: TypeAlias = Union[GenerateDecoderOnlyOutput, GenerateEncoderDecoderOutput]
GenerateBeamOutput: TypeAlias = Union[GenerateBeamDecoderOnlyOutput, GenerateBeamEncoderDecoderOutput]
GenerateOutput: TypeAlias = Union[GenerateNonBeamOutput, GenerateBeamOutput]

class GenerationMixin(ContinuousMixin):
    def load_custom_generate(
        self,
        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]] = ...,
        trust_remote_code: Optional[bool] = ...,
        **kwargs,
    ) -> Callable: ...
    def prepare_inputs_for_generation(
        self,
        input_ids: torch.LongTensor,
        past_key_values: Optional[Cache] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        cache_position: Optional[torch.LongTensor] = ...,
        **kwargs,
    ): ...
    def compute_transition_scores(
        self,
        sequences: torch.Tensor,
        scores: tuple[torch.Tensor],
        beam_indices: Optional[torch.Tensor] = ...,
        normalize_logits: bool = ...,
    ) -> torch.Tensor: ...
    @torch.no_grad()
    def generate(
        self,
        inputs: Optional[torch.Tensor] = ...,
        generation_config: Optional[GenerationConfig] = ...,
        logits_processor: Optional[LogitsProcessorList] = ...,
        stopping_criteria: Optional[StoppingCriteriaList] = ...,
        prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], list[int]]] = ...,
        synced_gpus: Optional[bool] = ...,
        assistant_model: Optional[PreTrainedModel] = ...,
        streamer: Optional[BaseStreamer] = ...,
        negative_prompt_ids: Optional[torch.Tensor] = ...,
        negative_prompt_attention_mask: Optional[torch.Tensor] = ...,
        use_model_defaults: Optional[bool] = ...,
        custom_generate: Optional[str] = ...,
        **kwargs,
    ) -> Union[GenerateOutput, torch.LongTensor]: ...
    def heal_tokens(
        self, input_ids: torch.LongTensor, tokenizer: Optional[PreTrainedTokenizerBase] = ...
    ) -> torch.LongTensor: ...

def stack_model_outputs(model_outputs: list[ModelOutput], config: PretrainedConfig) -> ModelOutput: ...
