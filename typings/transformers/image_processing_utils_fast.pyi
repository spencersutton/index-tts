"""
This type stub file was generated by pyright.
"""

import numpy as np
import torch
from collections.abc import Iterable
from functools import lru_cache
from typing import Any, Optional, TypedDict, Union
from .image_processing_utils import BaseImageProcessor, BatchFeature
from .image_utils import ChannelDimension, ImageInput, PILImageResampling, SizeDict, pil_torch_interpolation_mapping
from .processing_utils import Unpack
from .utils import TensorType, auto_docstring, is_torch_available, is_torchvision_available, is_vision_available

if is_vision_available(): ...
if is_torch_available(): ...
if is_torchvision_available(): ...
else:
    pil_torch_interpolation_mapping = ...
logger = ...

@lru_cache(maxsize=10)
def validate_fast_preprocess_arguments(
    do_rescale: Optional[bool] = ...,
    rescale_factor: Optional[float] = ...,
    do_normalize: Optional[bool] = ...,
    image_mean: Optional[Union[float, list[float]]] = ...,
    image_std: Optional[Union[float, list[float]]] = ...,
    do_pad: Optional[bool] = ...,
    size_divisibility: Optional[int] = ...,
    do_center_crop: Optional[bool] = ...,
    crop_size: Optional[SizeDict] = ...,
    do_resize: Optional[bool] = ...,
    size: Optional[SizeDict] = ...,
    resample: Optional[PILImageResampling] = ...,
    return_tensors: Optional[Union[str, TensorType]] = ...,
    data_format: Optional[ChannelDimension] = ...,
): ...
def safe_squeeze(tensor: torch.Tensor, axis: Optional[int] = ...) -> torch.Tensor: ...
def max_across_indices(values: Iterable[Any]) -> list[Any]: ...
def get_max_height_width(images: list[torch.Tensor]) -> tuple[int]: ...
def divide_to_patches(image: Union[np.array, torch.Tensor], patch_size: int) -> list[Union[np.array, torch.Tensor]]: ...

class DefaultFastImageProcessorKwargs(TypedDict, total=False):
    do_resize: Optional[bool]
    size: Optional[dict[str, int]]
    default_to_square: Optional[bool]
    resample: Optional[Union[PILImageResampling, F.InterpolationMode]]
    do_center_crop: Optional[bool]
    crop_size: Optional[dict[str, int]]
    do_rescale: Optional[bool]
    rescale_factor: Optional[Union[int, float]]
    do_normalize: Optional[bool]
    image_mean: Optional[Union[float, list[float]]]
    image_std: Optional[Union[float, list[float]]]
    do_convert_rgb: Optional[bool]
    return_tensors: Optional[Union[str, TensorType]]
    data_format: Optional[ChannelDimension]
    input_data_format: Optional[Union[str, ChannelDimension]]
    device: Optional[torch.device]
    disable_grouping: Optional[bool]
    ...

@auto_docstring
class BaseImageProcessorFast(BaseImageProcessor):
    resample = ...
    image_mean = ...
    image_std = ...
    size = ...
    default_to_square = ...
    crop_size = ...
    do_resize = ...
    do_center_crop = ...
    do_rescale = ...
    rescale_factor = ...
    do_normalize = ...
    do_convert_rgb = ...
    return_tensors = ...
    data_format = ...
    input_data_format = ...
    device = ...
    model_input_names = ...
    valid_kwargs = DefaultFastImageProcessorKwargs
    unused_kwargs = ...
    def __init__(self, **kwargs: Unpack[DefaultFastImageProcessorKwargs]) -> None: ...
    def resize(
        self,
        image: torch.Tensor,
        size: SizeDict,
        interpolation: F.InterpolationMode = ...,
        antialias: bool = ...,
        **kwargs,
    ) -> torch.Tensor: ...
    @staticmethod
    def compile_friendly_resize(
        image: torch.Tensor,
        new_size: tuple[int, int],
        interpolation: Optional[F.InterpolationMode] = ...,
        antialias: bool = ...,
    ) -> torch.Tensor: ...
    def rescale(self, image: torch.Tensor, scale: float, **kwargs) -> torch.Tensor: ...
    def normalize(
        self, image: torch.Tensor, mean: Union[float, Iterable[float]], std: Union[float, Iterable[float]], **kwargs
    ) -> torch.Tensor: ...
    def rescale_and_normalize(
        self,
        images: torch.Tensor,
        do_rescale: bool,
        rescale_factor: float,
        do_normalize: bool,
        image_mean: Union[float, list[float]],
        image_std: Union[float, list[float]],
    ) -> torch.Tensor: ...
    def center_crop(self, image: torch.Tensor, size: dict[str, int], **kwargs) -> torch.Tensor: ...
    def convert_to_rgb(self, image: ImageInput) -> ImageInput: ...
    def filter_out_unused_kwargs(self, kwargs: dict): ...
    def __call__(
        self, images: ImageInput, *args, **kwargs: Unpack[DefaultFastImageProcessorKwargs]
    ) -> BatchFeature: ...
    @auto_docstring
    def preprocess(
        self, images: ImageInput, *args, **kwargs: Unpack[DefaultFastImageProcessorKwargs]
    ) -> BatchFeature: ...
    def to_dict(self): ...
