"""
This type stub file was generated by pyright.
"""

import numpy as np
import torch
from collections.abc import Iterable
from functools import lru_cache
from typing import Any, Optional, TypedDict, Union
from .image_processing_utils import BaseImageProcessor, BatchFeature
from .image_utils import ChannelDimension, ImageInput, PILImageResampling, SizeDict, pil_torch_interpolation_mapping
from .processing_utils import Unpack
from .utils import TensorType, auto_docstring, is_torch_available, is_torchvision_available, is_vision_available

if is_vision_available(): ...
if is_torch_available(): ...
if is_torchvision_available(): ...
else:
    pil_torch_interpolation_mapping = ...
logger = ...

@lru_cache(maxsize=10)
def validate_fast_preprocess_arguments(
    do_rescale: bool | None = ...,
    rescale_factor: float | None = ...,
    do_normalize: bool | None = ...,
    image_mean: float | list[float] | None = ...,
    image_std: float | list[float] | None = ...,
    do_pad: bool | None = ...,
    size_divisibility: int | None = ...,
    do_center_crop: bool | None = ...,
    crop_size: SizeDict | None = ...,
    do_resize: bool | None = ...,
    size: SizeDict | None = ...,
    resample: PILImageResampling | None = ...,
    return_tensors: str | TensorType | None = ...,
    data_format: ChannelDimension | None = ...,
):  # -> None:
    """
    Checks validity of typically used arguments in an `ImageProcessorFast` `preprocess` method.
    Raises `ValueError` if arguments incompatibility is caught.
    """
    ...

def safe_squeeze(tensor: torch.Tensor, axis: int | None = ...) -> torch.Tensor:
    """
    Squeezes a tensor, but only if the axis specified has dim 1.
    """
    ...

def max_across_indices(values: Iterable[Any]) -> list[Any]:
    """
    Return the maximum value across all indices of an iterable of values.
    """
    ...

def get_max_height_width(images: list[torch.Tensor]) -> tuple[int]:
    """
    Get the maximum height and width across all images in a batch.
    """
    ...

def divide_to_patches(image: np.array | torch.Tensor, patch_size: int) -> list[np.array | torch.Tensor]:
    """
    Divides an image into patches of a specified size.

    Args:
        image (`Union[np.array, "torch.Tensor"]`):
            The input image.
        patch_size (`int`):
            The size of each patch.
    Returns:
        list: A list of Union[np.array, "torch.Tensor"] representing the patches.
    """
    ...

class DefaultFastImageProcessorKwargs(TypedDict, total=False):
    do_resize: bool | None
    size: dict[str, int] | None
    default_to_square: bool | None
    resample: PILImageResampling | F.InterpolationMode | None
    do_center_crop: bool | None
    crop_size: dict[str, int] | None
    do_rescale: bool | None
    rescale_factor: int | float | None
    do_normalize: bool | None
    image_mean: float | list[float] | None
    image_std: float | list[float] | None
    do_convert_rgb: bool | None
    return_tensors: str | TensorType | None
    data_format: ChannelDimension | None
    input_data_format: str | ChannelDimension | None
    device: torch.device | None
    disable_grouping: bool | None
    ...

@auto_docstring
class BaseImageProcessorFast(BaseImageProcessor):
    resample = ...
    image_mean = ...
    image_std = ...
    size = ...
    default_to_square = ...
    crop_size = ...
    do_resize = ...
    do_center_crop = ...
    do_rescale = ...
    rescale_factor = ...
    do_normalize = ...
    do_convert_rgb = ...
    return_tensors = ...
    data_format = ...
    input_data_format = ...
    device = ...
    model_input_names = ...
    valid_kwargs = DefaultFastImageProcessorKwargs
    unused_kwargs = ...
    def __init__(self, **kwargs: Unpack[DefaultFastImageProcessorKwargs]) -> None: ...
    def resize(
        self,
        image: torch.Tensor,
        size: SizeDict,
        interpolation: F.InterpolationMode = ...,
        antialias: bool = ...,
        **kwargs,
    ) -> torch.Tensor:
        """
        Resize an image to `(size["height"], size["width"])`.

        Args:
            image (`torch.Tensor`):
                Image to resize.
            size (`SizeDict`):
                Dictionary in the format `{"height": int, "width": int}` specifying the size of the output image.
            interpolation (`InterpolationMode`, *optional*, defaults to `InterpolationMode.BILINEAR`):
                `InterpolationMode` filter to use when resizing the image e.g. `InterpolationMode.BICUBIC`.

        Returns:
            `torch.Tensor`: The resized image.
        """
        ...

    @staticmethod
    def compile_friendly_resize(
        image: torch.Tensor,
        new_size: tuple[int, int],
        interpolation: F.InterpolationMode | None = ...,
        antialias: bool = ...,
    ) -> torch.Tensor:
        """
        A wrapper around `F.resize` so that it is compatible with torch.compile when the image is a uint8 tensor.
        """
        ...

    def rescale(self, image: torch.Tensor, scale: float, **kwargs) -> torch.Tensor:
        """
        Rescale an image by a scale factor. image = image * scale.

        Args:
            image (`torch.Tensor`):
                Image to rescale.
            scale (`float`):
                The scaling factor to rescale pixel values by.

        Returns:
            `torch.Tensor`: The rescaled image.
        """
        ...

    def normalize(
        self, image: torch.Tensor, mean: float | Iterable[float], std: float | Iterable[float], **kwargs
    ) -> torch.Tensor:
        """
        Normalize an image. image = (image - image_mean) / image_std.

        Args:
            image (`torch.Tensor`):
                Image to normalize.
            mean (`torch.Tensor`, `float` or `Iterable[float]`):
                Image mean to use for normalization.
            std (`torch.Tensor`, `float` or `Iterable[float]`):
                Image standard deviation to use for normalization.

        Returns:
            `torch.Tensor`: The normalized image.
        """
        ...

    def rescale_and_normalize(
        self,
        images: torch.Tensor,
        do_rescale: bool,
        rescale_factor: float,
        do_normalize: bool,
        image_mean: float | list[float],
        image_std: float | list[float],
    ) -> torch.Tensor:
        """
        Rescale and normalize images.
        """
        ...

    def center_crop(self, image: torch.Tensor, size: dict[str, int], **kwargs) -> torch.Tensor:
        """
        Center crop an image to `(size["height"], size["width"])`. If the input size is smaller than `crop_size` along
        any edge, the image is padded with 0's and then center cropped.

        Args:
            image (`"torch.Tensor"`):
                Image to center crop.
            size (`dict[str, int]`):
                Size of the output image.

        Returns:
            `torch.Tensor`: The center cropped image.
        """
        ...

    def convert_to_rgb(self, image: ImageInput) -> ImageInput:
        """
        Converts an image to RGB format. Only converts if the image is of type PIL.Image.Image, otherwise returns the image
        as is.
        Args:
            image (ImageInput):
                The image to convert.

        Returns:
            ImageInput: The converted image.
        """
        ...

    def filter_out_unused_kwargs(self, kwargs: dict):  # -> dict[Any, Any]:
        """
        Filter out the unused kwargs from the kwargs dictionary.
        """
        ...

    def __call__(
        self, images: ImageInput, *args, **kwargs: Unpack[DefaultFastImageProcessorKwargs]
    ) -> BatchFeature: ...
    @auto_docstring
    def preprocess(
        self, images: ImageInput, *args, **kwargs: Unpack[DefaultFastImageProcessorKwargs]
    ) -> BatchFeature: ...
    def to_dict(self):  # -> dict[str, Any]:
        ...
