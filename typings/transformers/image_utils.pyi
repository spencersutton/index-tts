"""
This type stub file was generated by pyright.
"""

import numpy as np
import PIL.Image
import torch
from collections.abc import Iterable
from dataclasses import dataclass
from typing import Optional, TypeAlias, Union
from .utils import ExplicitEnum, is_torch_available, is_vision_available

if is_vision_available(): ...
if is_torch_available(): ...
logger = ...
ImageInput: TypeAlias = Union[
    PIL.Image.Image, np.ndarray, torch.Tensor, list[PIL.Image.Image], list[np.ndarray], list[torch.Tensor]
]

class ChannelDimension(ExplicitEnum):
    FIRST = ...
    LAST = ...

class AnnotationFormat(ExplicitEnum):
    COCO_DETECTION = ...
    COCO_PANOPTIC = ...

class AnnotionFormat(ExplicitEnum):
    COCO_DETECTION = ...
    COCO_PANOPTIC = ...

AnnotationType: TypeAlias = dict[str, Union[int, str, list[dict]]]

def is_pil_image(img): ...

class ImageType(ExplicitEnum):
    PIL = ...
    TORCH = ...
    NUMPY = ...
    TENSORFLOW = ...
    JAX = ...

def get_image_type(image): ...
def is_valid_image(img): ...
def is_valid_list_of_images(images: list): ...
def concatenate_list(input_list): ...
def valid_images(imgs): ...
def is_batched(img): ...
def is_scaled_image(image: np.ndarray) -> bool: ...
def make_list_of_images(images, expected_ndims: int = ...) -> list[ImageInput]: ...
def make_flat_list_of_images(images: Union[list[ImageInput], ImageInput], expected_ndims: int = ...) -> ImageInput: ...
def make_nested_list_of_images(
    images: Union[list[ImageInput], ImageInput], expected_ndims: int = ...
) -> ImageInput: ...
def to_numpy_array(img) -> np.ndarray: ...
def infer_channel_dimension_format(
    image: np.ndarray, num_channels: Optional[Union[int, tuple[int, ...]]] = ...
) -> ChannelDimension: ...
def get_channel_dimension_axis(
    image: np.ndarray, input_data_format: Optional[Union[ChannelDimension, str]] = ...
) -> int: ...
def get_image_size(image: np.ndarray, channel_dim: ChannelDimension = ...) -> tuple[int, int]: ...
def get_image_size_for_max_height_width(
    image_size: tuple[int, int], max_height: int, max_width: int
) -> tuple[int, int]: ...
def is_valid_annotation_coco_detection(annotation: dict[str, Union[list, tuple]]) -> bool: ...
def is_valid_annotation_coco_panoptic(annotation: dict[str, Union[list, tuple]]) -> bool: ...
def valid_coco_detection_annotations(annotations: Iterable[dict[str, Union[list, tuple]]]) -> bool: ...
def valid_coco_panoptic_annotations(annotations: Iterable[dict[str, Union[list, tuple]]]) -> bool: ...
def load_image(image: Union[str, PIL.Image.Image], timeout: Optional[float] = ...) -> PIL.Image.Image: ...
def load_images(
    images: Union[list, tuple, str, PIL.Image.Image], timeout: Optional[float] = ...
) -> Union[PIL.Image.Image, list[PIL.Image.Image], list[list[PIL.Image.Image]]]: ...
def validate_preprocess_arguments(
    do_rescale: Optional[bool] = ...,
    rescale_factor: Optional[float] = ...,
    do_normalize: Optional[bool] = ...,
    image_mean: Optional[Union[float, list[float]]] = ...,
    image_std: Optional[Union[float, list[float]]] = ...,
    do_pad: Optional[bool] = ...,
    size_divisibility: Optional[int] = ...,
    do_center_crop: Optional[bool] = ...,
    crop_size: Optional[dict[str, int]] = ...,
    do_resize: Optional[bool] = ...,
    size: Optional[dict[str, int]] = ...,
    resample: Optional[PILImageResampling] = ...,
): ...

class ImageFeatureExtractionMixin:
    def to_pil_image(self, image, rescale=...): ...
    def convert_rgb(self, image): ...
    def rescale(self, image: np.ndarray, scale: float) -> np.ndarray: ...
    def to_numpy_array(self, image, rescale=..., channel_first=...): ...
    def expand_dims(self, image): ...
    def normalize(self, image, mean, std, rescale=...): ...
    def resize(self, image, size, resample=..., default_to_square=..., max_size=...): ...
    def center_crop(self, image, size): ...
    def flip_channel_order(self, image): ...
    def rotate(self, image, angle, resample=..., expand=..., center=..., translate=..., fillcolor=...): ...

def validate_annotations(
    annotation_format: AnnotationFormat,
    supported_annotation_formats: tuple[AnnotationFormat, ...],
    annotations: list[dict],
) -> None: ...
def validate_kwargs(valid_processor_keys: list[str], captured_kwargs: list[str]): ...

@dataclass(frozen=True)
class SizeDict:
    height: Optional[int] = ...
    width: Optional[int] = ...
    longest_edge: Optional[int] = ...
    shortest_edge: Optional[int] = ...
    max_height: Optional[int] = ...
    max_width: Optional[int] = ...
    def __getitem__(self, key): ...
