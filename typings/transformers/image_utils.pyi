from collections.abc import Iterable
from dataclasses import dataclass

import numpy as np
import PIL.Image
import torch

from .utils import ExplicitEnum, is_torch_available, is_vision_available

if is_vision_available(): ...
if is_torch_available(): ...
logger = ...
type ImageInput = (
    PIL.Image.Image | np.ndarray | torch.Tensor | list[PIL.Image.Image] | list[np.ndarray] | list[torch.Tensor]
)

class ChannelDimension(ExplicitEnum):
    FIRST = ...
    LAST = ...

class AnnotationFormat(ExplicitEnum):
    COCO_DETECTION = ...
    COCO_PANOPTIC = ...

class AnnotionFormat(ExplicitEnum):
    COCO_DETECTION = ...
    COCO_PANOPTIC = ...

type AnnotationType = dict[str, int | str | list[dict]]

def is_pil_image(img):  # -> bool:
    ...

class ImageType(ExplicitEnum):
    PIL = ...
    TORCH = ...
    NUMPY = ...
    TENSORFLOW = ...
    JAX = ...

def get_image_type(
    image,
):  # -> Literal[ImageType.PIL, ImageType.TORCH, ImageType.NUMPY, ImageType.TENSORFLOW, ImageType.JAX]:
    ...
def is_valid_image(img):  # -> bool:
    ...
def is_valid_list_of_images(images: list):  # -> list[Any] | bool:
    ...
def concatenate_list(input_list):  # -> list[Any] | NDArray[Any] | Tensor | None:
    ...
def valid_images(imgs):  # -> bool:
    ...
def is_batched(img):  # -> bool:
    ...
def is_scaled_image(image: np.ndarray) -> bool: ...
def make_list_of_images(images, expected_ndims: int = ...) -> list[ImageInput]: ...
def make_flat_list_of_images(images: list[ImageInput] | ImageInput, expected_ndims: int = ...) -> ImageInput: ...
def make_nested_list_of_images(images: list[ImageInput] | ImageInput, expected_ndims: int = ...) -> ImageInput: ...
def to_numpy_array(img) -> np.ndarray: ...
def infer_channel_dimension_format(
    image: np.ndarray, num_channels: int | tuple[int, ...] | None = ...
) -> ChannelDimension: ...
def get_channel_dimension_axis(image: np.ndarray, input_data_format: ChannelDimension | str | None = ...) -> int: ...
def get_image_size(image: np.ndarray, channel_dim: ChannelDimension = ...) -> tuple[int, int]: ...
def get_image_size_for_max_height_width(
    image_size: tuple[int, int], max_height: int, max_width: int
) -> tuple[int, int]: ...
def is_valid_annotation_coco_detection(annotation: dict[str, list | tuple]) -> bool: ...
def is_valid_annotation_coco_panoptic(annotation: dict[str, list | tuple]) -> bool: ...
def valid_coco_detection_annotations(annotations: Iterable[dict[str, list | tuple]]) -> bool: ...
def valid_coco_panoptic_annotations(annotations: Iterable[dict[str, list | tuple]]) -> bool: ...
def load_image(image: str | PIL.Image.Image, timeout: float | None = ...) -> PIL.Image.Image: ...
def load_images(
    images: list | tuple | str | PIL.Image.Image, timeout: float | None = ...
) -> PIL.Image.Image | list[PIL.Image.Image] | list[list[PIL.Image.Image]]: ...
def validate_preprocess_arguments(
    do_rescale: bool | None = ...,
    rescale_factor: float | None = ...,
    do_normalize: bool | None = ...,
    image_mean: float | list[float] | None = ...,
    image_std: float | list[float] | None = ...,
    do_pad: bool | None = ...,
    size_divisibility: int | None = ...,
    do_center_crop: bool | None = ...,
    crop_size: dict[str, int] | None = ...,
    do_resize: bool | None = ...,
    size: dict[str, int] | None = ...,
    resample: PILImageResampling | None = ...,
):  # -> None:

    ...

class ImageFeatureExtractionMixin:
    def to_pil_image(self, image, rescale=...):  # -> Image:

        ...
    def convert_rgb(self, image):  # -> Image:

        ...
    def rescale(self, image: np.ndarray, scale: float) -> np.ndarray: ...
    def to_numpy_array(self, image, rescale=..., channel_first=...):  # -> ndarray[_AnyShape, dtype[Any]]:

        ...
    def expand_dims(self, image):  # -> Image | NDArray[Any]:

        ...
    def normalize(self, image, mean, std, rescale=...):  # -> NDArray[float64]:

        ...
    def resize(self, image, size, resample=..., default_to_square=..., max_size=...):  # -> Image:

        ...
    def center_crop(self, image, size):  # -> Image | ndarray[_AnyShape, dtype[Any]] | ndarray[_AnyShape, Any]:

        ...
    def flip_channel_order(self, image):  # -> ndarray[_AnyShape, dtype[Any]]:

        ...
    def rotate(self, image, angle, resample=..., expand=..., center=..., translate=..., fillcolor=...):  # -> Image:

        ...

def validate_annotations(
    annotation_format: AnnotationFormat,
    supported_annotation_formats: tuple[AnnotationFormat, ...],
    annotations: list[dict],
) -> None: ...
def validate_kwargs(valid_processor_keys: list[str], captured_kwargs: list[str]):  # -> None:
    ...

@dataclass(frozen=True)
class SizeDict:
    height: int | None = ...
    width: int | None = ...
    longest_edge: int | None = ...
    shortest_edge: int | None = ...
    max_height: int | None = ...
    max_width: int | None = ...
    def __getitem__(self, key):  # -> Any:
        ...
