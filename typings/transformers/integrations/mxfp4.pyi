import torch
from torch import nn

from ..utils import is_accelerate_available, is_torch_available

if is_torch_available(): ...
if is_accelerate_available(): ...
logger = ...
FP4_VALUES = ...

def quantize_to_mxfp4(w):  # -> tuple[Any, Any]:
    ...
def swizzle_mxfp4(w, w_scale):  # -> tuple[Any, Any]:
    ...
def convert_moe_packed_tensors(
    blocks, scales, *, dtype: torch.dtype = ..., rows_per_chunk: int = ...
) -> torch.Tensor: ...

class Mxfp4GptOssExperts(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor, routing_data, gather_idx, scatter_idx) -> torch.Tensor: ...

def routing_torch_dist(logits, n_expts_act):  # -> tuple[Any, Any, Any]:
    ...
def mlp_forward(self, hidden_states):  # -> tuple[Any, Any]:
    ...
def should_convert_module(current_key_name, patterns):  # -> bool:
    ...
def dequantize(module, param_name, param_value, target_device, dq_param_name, **kwargs):  # -> None:
    ...
def load_and_swizzle_mxfp4(module, param_name, param_value, target_device, **kwargs):  # -> None:
    ...
def replace_with_mxfp4_linear(
    model, modules_to_not_convert=..., current_key_name=..., quantization_config=..., config=...
): ...
