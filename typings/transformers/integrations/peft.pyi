from typing import Any

import torch

from ..utils import is_accelerate_available, is_torch_available

if is_torch_available(): ...
if is_accelerate_available(): ...
MIN_PEFT_VERSION = ...
logger = ...
VLMS = ...

class PeftAdapterMixin:
    _hf_peft_config_loaded = ...
    def load_adapter(
        self,
        peft_model_id: str | None = ...,
        adapter_name: str | None = ...,
        revision: str | None = ...,
        token: str | None = ...,
        device_map: str | None = ...,
        max_memory: str | None = ...,
        offload_folder: str | None = ...,
        offload_index: int | None = ...,
        peft_config: dict[str, Any] | None = ...,
        adapter_state_dict: dict[str, torch.Tensor] | None = ...,
        low_cpu_mem_usage: bool = ...,
        is_trainable: bool = ...,
        adapter_kwargs: dict[str, Any] | None = ...,
    ) -> None: ...
    def add_adapter(self, adapter_config, adapter_name: str | None = ...) -> None: ...
    def set_adapter(self, adapter_name: list[str] | str) -> None: ...
    def disable_adapters(self) -> None: ...
    def enable_adapters(self) -> None: ...
    def active_adapters(self) -> list[str]: ...
    def active_adapter(self) -> str: ...
    def get_adapter_state_dict(self, adapter_name: str | None = ..., state_dict: dict | None = ...) -> dict: ...
    def delete_adapter(self, adapter_names: list[str] | str) -> None: ...
