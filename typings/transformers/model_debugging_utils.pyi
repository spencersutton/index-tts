"""
This type stub file was generated by pyright.
"""

from contextlib import contextmanager
from typing import Optional
from .utils.import_utils import is_torch_available, requires

if is_torch_available():
    _torch_distributed_available = ...
else:
    _torch_distributed_available = ...
logger = ...
MEMORY_ADDRESS_REGEX = ...

def prune_outputs_if_children(node):  # -> None:
    ...

LAYER_SUFFIX_RE = ...

def is_layer_block(node):  # -> bool:
    """
    Checks whether a node represents a layer block with submodules.

    Args:
        node (`dict`): A node from the call tree.

    Returns:
        `bool`: Whether the node is a layer block.
    """
    ...

def prune_intermediate_layers(node):  # -> None:
    """
    Recursively removes intermediate layers from the tree to improve readability.
    Keeps at least the first and last layers if many consecutive layers are present.

    Args:
        node (`dict`): The root or subnode to prune recursively.
    """
    ...

def log_model_debug_trace(debug_path, model):  # -> None:
    ...
@requires(backends=("torch",))
@contextmanager
def model_addition_debugger_context(
    model, debug_path: Optional[str] = ..., do_prune_layers: Optional[bool] = ..., use_repr: Optional[bool] = ...
):  # -> Generator[Any, Any, None]:
    """
    # Model addition debugger - context manager for model adders
    This context manager is a power user tool intended for model adders.

    It tracks all forward calls within a model forward and logs a slice of each input and output on a nested JSON file.
    If `use_repr=True` (the default), the JSON file will record a `repr()`-ized version of the tensors as a list of
    strings. If `use_repr=False`, the full tensors will be stored in spearate SafeTensors files and the JSON file will
    provide a relative path to that file.

    To note, this context manager enforces `torch.no_grad()`.

    ## Usage

    add the context manager to a model to debug

    ```python
    import torch

    from PIL import Image
    from transformers import LlavaProcessor, LlavaForConditionalGeneration, model_addition_debugger_context

    torch.random.manual_seed(673)

    # load pretrained model and processor
    model_id = "llava-hf/llava-1.5-7b-hf"
    processor = LlavaProcessor.from_pretrained(model_id)
    model = LlavaForConditionalGeneration.from_pretrained(model_id)

    # create random image input
    random_image = Image.fromarray(torch.randint(0, 256, (224, 224, 3), dtype=torch.uint8).numpy())

    # prompt
    prompt = "<image>Describe this image."

    # process inputs
    inputs = processor(text=prompt, images=random_image, return_tensors="pt")

    # call forward method (not .generate!)
    with model_addition_debugger_context(model, debug_path="Your_debug_path", do_prune_layers=False):
        output = model.forward(**inputs)
    ```

    """
    ...
