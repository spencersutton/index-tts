"""
This type stub file was generated by pyright.
"""

import os
import flax.linen as nn
import jax
import jax.numpy as jnp
from typing import Any, Optional, Union
from flax.core.frozen_dict import FrozenDict
from jax.random import PRNGKey
from .configuration_utils import PretrainedConfig
from .generation import FlaxGenerationMixin
from .utils import PushToHubMixin
from .utils.import_utils import is_safetensors_available

if is_safetensors_available(): ...
logger = ...

def quick_gelu(x): ...

ACT2FN = ...

def flax_shard_checkpoint(params, max_shard_size=...): ...

class FlaxPreTrainedModel(PushToHubMixin, FlaxGenerationMixin):
    config_class = ...
    base_model_prefix = ...
    main_input_name = ...
    _auto_class = ...
    _missing_keys = ...
    def __init__(
        self,
        config: PretrainedConfig,
        module: nn.Module,
        input_shape: tuple = ...,
        seed: int = ...,
        dtype: jnp.dtype = ...,
        _do_init: bool = ...,
    ) -> None: ...
    def init_weights(self, rng: jax.random.PRNGKey, input_shape: tuple, params: FrozenDict = ...) -> dict: ...
    def enable_gradient_checkpointing(self): ...
    @property
    def framework(self) -> str: ...
    @property
    def config(self) -> PretrainedConfig: ...
    @property
    def module(self) -> nn.Module: ...
    @property
    def params(self) -> Union[dict, FrozenDict]: ...
    @property
    def required_params(self) -> set: ...
    @property
    def params_shape_tree(self) -> dict: ...
    @params.setter
    def params(self, params: Union[dict, FrozenDict]): ...
    def to_bf16(self, params: Union[dict, FrozenDict], mask: Any = ...): ...
    def to_fp32(self, params: Union[dict, FrozenDict], mask: Any = ...): ...
    def to_fp16(self, params: Union[dict, FrozenDict], mask: Any = ...): ...
    @classmethod
    def load_flax_weights(cls, resolved_archive_file): ...
    @classmethod
    def load_flax_sharded_weights(cls, shard_files): ...
    @classmethod
    def can_generate(cls) -> bool: ...
    @classmethod
    def from_pretrained(
        cls,
        pretrained_model_name_or_path: Union[str, os.PathLike],
        dtype: jnp.dtype = ...,
        *model_args,
        config: Optional[Union[PretrainedConfig, str, os.PathLike]] = ...,
        cache_dir: Optional[Union[str, os.PathLike]] = ...,
        ignore_mismatched_sizes: bool = ...,
        force_download: bool = ...,
        local_files_only: bool = ...,
        token: Optional[Union[str, bool]] = ...,
        revision: str = ...,
        **kwargs,
    ): ...
    def save_pretrained(
        self,
        save_directory: Union[str, os.PathLike],
        params=...,
        push_to_hub=...,
        max_shard_size=...,
        token: Optional[Union[str, bool]] = ...,
        safe_serialization: bool = ...,
        **kwargs,
    ): ...
    @classmethod
    def register_for_auto_class(cls, auto_class=...): ...

if FlaxPreTrainedModel.push_to_hub.__doc__ is not None: ...

def overwrite_call_docstring(model_class, docstring): ...
def append_call_sample_docstring(
    model_class, checkpoint, output_type, config_class, mask=..., revision=..., real_checkpoint=...
): ...
def append_replace_return_docstrings(model_class, output_type, config_class): ...
