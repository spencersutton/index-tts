"""
This type stub file was generated by pyright.
"""

import torch
import torch.nn as nn
from typing import Optional
from .cache_utils import Cache
from .modeling_outputs import QuestionAnsweringModelOutput, SequenceClassifierOutputWithPast, TokenClassifierOutput
from .processing_utils import Unpack
from .utils import TransformersKwargs, auto_docstring, can_return_tuple

logger = ...

class GradientCheckpointingLayer(nn.Module):
    gradient_checkpointing = ...
    def __call__(self, *args, **kwargs): ...

@auto_docstring
class GenericForSequenceClassification:
    base_model_prefix = ...
    def __init__(self, config) -> None: ...
    @can_return_tuple
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        use_cache: Optional[bool] = ...,
        **kwargs: Unpack[TransformersKwargs],
    ) -> SequenceClassifierOutputWithPast: ...

@auto_docstring
class GenericForQuestionAnswering:
    base_model_prefix = ...
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    @can_return_tuple
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        start_positions: Optional[torch.LongTensor] = ...,
        end_positions: Optional[torch.LongTensor] = ...,
        **kwargs: Unpack[TransformersKwargs],
    ) -> QuestionAnsweringModelOutput: ...

@auto_docstring
class GenericForTokenClassification:
    base_model_prefix = ...
    def __init__(self, config) -> None: ...
    @can_return_tuple
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        use_cache: Optional[bool] = ...,
        **kwargs,
    ) -> TokenClassifierOutput: ...
