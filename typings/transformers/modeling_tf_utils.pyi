import functools
import os
from collections.abc import Callable
from typing import TYPE_CHECKING, Any

import numpy as np
import tensorflow as tf
import tf_keras as keras

from . import PreTrainedTokenizerBase
from .configuration_utils import PretrainedConfig
from .generation import TFGenerationMixin
from .utils import PushToHubMixin, is_safetensors_available

"""TF general model utils."""
if is_safetensors_available(): ...
if TYPE_CHECKING: ...
logger = ...
if "TF_USE_LEGACY_KERAS" not in os.environ: ...
tf_logger = ...
type TFModelInputType = (
    list[tf.Tensor] | list[np.ndarray] | dict[str, tf.Tensor] | dict[str, np.ndarray] | tf.Tensor | np.ndarray
)

def dummy_loss(y_true, y_pred): ...

class TFModelUtilsMixin:
    def num_parameters(self, only_trainable: bool = ...) -> int: ...

def keras_serializable(cls): ...

class TFCausalLanguageModelingLoss:
    def hf_compute_loss(self, labels, logits): ...

class TFQuestionAnsweringLoss:
    def hf_compute_loss(self, labels, logits): ...

class TFTokenClassificationLoss:
    def hf_compute_loss(self, labels, logits): ...

class TFSequenceClassificationLoss:
    def hf_compute_loss(self, labels, logits): ...

class TFMultipleChoiceLoss:
    def hf_compute_loss(self, labels, logits): ...

class TFMaskedLanguageModelingLoss(TFCausalLanguageModelingLoss): ...

class TFNextSentencePredictionLoss:
    def hf_compute_loss(self, labels, logits): ...

def booleans_processing(config, **kwargs):  # -> dict[Any, Any]:

    ...
def unpack_inputs(func):  # -> _Wrapped[..., Any, ..., Any]:

    ...
def input_processing(func, config, **kwargs): ...
def strip_model_name_and_prefix(name, _prefix=...):  # -> str:
    ...
def tf_shard_checkpoint(
    weights, max_shard_size=..., weights_name: str = ...
):  # -> tuple[dict[str, Any], None] | tuple[dict[Any, Any], dict[str, dict[str, Any | int]]]:

    ...
def load_tf_sharded_weights(
    model, shard_files, ignore_mismatched_sizes=..., strict=..., _prefix=...
):  # -> tuple[set[Any], set[Any], set[Any]]:

    ...
def load_tf_shard(
    model, model_layer_map, resolved_archive_file, ignore_mismatched_sizes=..., _prefix=...
):  # -> tuple[set[Any], set[Any], set[Any]]:

    ...
def load_tf_sharded_weights_from_safetensors(
    model, shard_files, ignore_mismatched_sizes=..., strict=..., _prefix=...
):  # -> tuple[set[Any], set[Any], set[Any]]:

    ...
def load_tf_weights(
    model, resolved_archive_file, ignore_mismatched_sizes=..., _prefix=...
):  # -> tuple[list[str | Any], list[Any], list[Any]]:

    ...
def load_tf_weights_from_h5(
    model, resolved_archive_file, ignore_mismatched_sizes=..., _prefix=...
):  # -> tuple[list[Any], list[Any], list[Any]]:
    ...
def load_tf_weights_from_safetensors(
    model, resolved_archive_file, ignore_mismatched_sizes=..., _prefix=...
):  # -> tuple[list[str | Any], list[Any], list[Any]]:
    ...
def init_copy_embeddings(old_embeddings, new_num_tokens):  # -> tuple[Any, Any]:

    ...

class TFPreTrainedModel(keras.Model, TFModelUtilsMixin, TFGenerationMixin, PushToHubMixin):
    config_class = ...
    base_model_prefix = ...
    main_input_name = ...
    _auto_class = ...
    _using_dummy_loss = ...
    _label_to_output_map = ...
    _keys_to_ignore_on_load_missing = ...
    _keys_to_ignore_on_load_unexpected = ...
    _requires_load_weight_prefix = ...
    @property
    def dummy_inputs(self) -> dict[str, tf.Tensor]: ...
    def build_in_name_scope(self):  # -> None:
        ...
    @property
    def framework(self) -> str: ...
    def build(self, input_shape=...):  # -> None:
        ...
    def __init__(self, config, *inputs, **kwargs) -> None: ...
    def get_config(self):  # -> dict[str, Any]:
        ...
    @functools.wraps(keras.Model.fit)
    def fit(self, *args, **kwargs): ...
    @functools.wraps(keras.Model.train_on_batch)
    def train_on_batch(self, *args, **kwargs): ...
    @functools.wraps(keras.Model.test_on_batch)
    def test_on_batch(self, *args, **kwargs): ...
    @functools.wraps(keras.Model.predict_on_batch)
    def predict_on_batch(self, *args, **kwargs): ...
    @functools.wraps(keras.Model.predict)
    def predict(self, *args, **kwargs): ...
    @functools.wraps(keras.Model.evaluate)
    def evaluate(self, *args, **kwargs): ...
    @classmethod
    def from_config(cls, config, **kwargs):  # -> Self:
        ...
    def get_head_mask(self, head_mask: tf.Tensor | None, num_hidden_layers: int) -> tf.Tensor: ...
    @tf.function
    def serving(self, inputs):  # -> ModelOutput:

        ...
    @property
    def input_signature(self) -> dict[str, tf.TensorSpec]: ...
    def serving_output(self, output):  # -> ModelOutput:

        ...
    @classmethod
    def can_generate(cls) -> bool: ...
    def get_input_embeddings(self) -> keras.layers.Layer: ...
    def prepare_tf_dataset(
        self,
        dataset: datasets.Dataset,
        batch_size: int = ...,
        shuffle: bool = ...,
        tokenizer: PreTrainedTokenizerBase | None = ...,
        collate_fn: Callable | None = ...,
        collate_fn_args: dict[str, Any] | None = ...,
        drop_remainder: bool | None = ...,
        prefetch: bool = ...,
    ): ...
    def compile(
        self,
        optimizer=...,
        loss=...,
        metrics=...,
        loss_weights=...,
        weighted_metrics=...,
        run_eagerly=...,
        steps_per_execution=...,
        **kwargs,
    ):  # -> None:

        ...
    def compute_loss(self, *args, **kwargs): ...
    def get_label_to_output_name_mapping(self):  # -> dict[str, str] | dict[Any, Any]:
        ...
    def train_step(self, data): ...
    def test_step(self, data): ...
    def create_model_card(
        self,
        output_dir,
        model_name: str,
        language: str | None = ...,
        license: str | None = ...,
        tags: str | None = ...,
        finetuned_from: str | None = ...,
        tasks: str | None = ...,
        dataset_tags: str | list[str] | None = ...,
        dataset: str | list[str] | None = ...,
        dataset_args: str | list[str] | None = ...,
    ):  # -> None:

        ...
    def set_input_embeddings(self, value):  # -> None:

        ...
    def get_output_embeddings(self) -> None | keras.layers.Layer: ...
    def set_output_embeddings(self, value):  # -> None:

        ...
    def get_output_layer_with_bias(self) -> None | keras.layers.Layer: ...
    def get_prefix_bias_name(self) -> None | str: ...
    def get_bias(self) -> None | dict[str, tf.Variable]: ...
    def set_bias(self, value):  # -> None:

        ...
    def get_lm_head(self) -> keras.layers.Layer: ...
    def resize_token_embeddings(self, new_num_tokens: int | None = ...) -> keras.layers.Embedding | tf.Variable: ...
    def prune_heads(self, heads_to_prune): ...
    def save_pretrained(
        self,
        save_directory,
        saved_model=...,
        version=...,
        push_to_hub=...,
        signatures=...,
        max_shard_size: int | str = ...,
        create_pr: bool = ...,
        safe_serialization: bool = ...,
        token: str | bool | None = ...,
        **kwargs,
    ):  # -> None:

        ...
    @classmethod
    def from_pretrained(
        cls,
        pretrained_model_name_or_path: str | os.PathLike | None,
        *model_args,
        config: PretrainedConfig | str | os.PathLike | None = ...,
        cache_dir: str | os.PathLike | None = ...,
        ignore_mismatched_sizes: bool = ...,
        force_download: bool = ...,
        local_files_only: bool = ...,
        token: str | bool | None = ...,
        revision: str = ...,
        use_safetensors: bool | None = ...,
        **kwargs,
    ):  # -> tuple[Any, dict[str, list[Any]]] | tuple[Any, dict[str, list[Any] | Any]] | tuple[Self, dict[str, set[Any] | list[str | Any] | list[Any]]] | Self:

        ...
    def push_to_hub(
        self,
        repo_id: str,
        use_temp_dir: bool | None = ...,
        commit_message: str | None = ...,
        private: bool | None = ...,
        max_shard_size: int | str | None = ...,
        token: bool | str | None = ...,
        use_auth_token: bool | str | None = ...,
        create_pr: bool = ...,
        **base_model_card_args,
    ) -> str: ...
    @classmethod
    def register_for_auto_class(cls, auto_class=...):  # -> None:

        ...

class TFConv1D(keras.layers.Layer):
    def __init__(self, nf, nx, initializer_range=..., **kwargs) -> None: ...
    def build(self, input_shape):  # -> None:
        ...
    def call(self, x): ...

class TFSharedEmbeddings(keras.layers.Layer):
    def __init__(self, vocab_size: int, hidden_size: int, initializer_range: float | None = ..., **kwargs) -> None: ...
    def build(self, input_shape):  # -> None:

        ...
    def get_config(self):  # -> dict[Any, Any]:
        ...
    def call(self, inputs: tf.Tensor, mode: str = ...) -> tf.Tensor: ...

class TFSequenceSummary(keras.layers.Layer):
    def __init__(self, config: PretrainedConfig, initializer_range: float = ..., **kwargs) -> None: ...
    def call(self, inputs, cls_index=..., training=...): ...
    def build(self, input_shape):  # -> None:
        ...

def get_initializer(initializer_range: float = ...) -> keras.initializers.TruncatedNormal: ...
