"""
This type stub file was generated by pyright.
"""

import os
from typing import Any, Optional, Union
from ...utils import is_tokenizers_available
from .configuration_auto import replace_list_option_in_docstrings
from ...tokenization_utils_fast import PreTrainedTokenizerFast

if is_tokenizers_available(): ...
else:
    PreTrainedTokenizerFast = ...
logger = ...
TOKENIZER_MAPPING_NAMES = ...
TOKENIZER_MAPPING = ...
CONFIG_TO_TYPE = ...

def tokenizer_class_from_name(class_name: str) -> Union[type[Any], None]: ...
def get_tokenizer_config(
    pretrained_model_name_or_path: Union[str, os.PathLike[str]],
    cache_dir: Optional[Union[str, os.PathLike[str]]] = ...,
    force_download: bool = ...,
    resume_download: Optional[bool] = ...,
    proxies: Optional[dict[str, str]] = ...,
    token: Optional[Union[bool, str]] = ...,
    revision: Optional[str] = ...,
    local_files_only: bool = ...,
    subfolder: str = ...,
    **kwargs,
) -> dict[str, Any]: ...

class AutoTokenizer:
    def __init__(self) -> None: ...
    @classmethod
    @replace_list_option_in_docstrings(TOKENIZER_MAPPING_NAMES)
    def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs): ...
    @staticmethod
    def register(config_class, slow_tokenizer_class=..., fast_tokenizer_class=..., exist_ok=...): ...

__all__ = ["TOKENIZER_MAPPING", "AutoTokenizer"]
