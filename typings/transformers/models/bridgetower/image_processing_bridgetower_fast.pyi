"""
This type stub file was generated by pyright.
"""

import torch
from collections.abc import Iterable
from typing import Optional, Union
from ...image_processing_utils_fast import (
    BaseImageProcessorFast,
    BatchFeature,
    DefaultFastImageProcessorKwargs,
    ImageInput,
    SizeDict,
    Unpack,
)
from ...utils import auto_docstring, is_torch_available, is_torchvision_available

"""Fast Image processor class for BridgeTower."""
if is_torch_available(): ...
if is_torchvision_available(): ...

def make_pixel_mask(image: torch.Tensor, output_size: tuple[int, int]) -> torch.Tensor:
    """
    Make a pixel mask for the image, where 1 indicates a valid pixel and 0 indicates padding.

    Args:
        image (`np.ndarray`):
            Image to make the pixel mask for.
        output_size (`tuple[int, int]`):
            Output size of the mask.
    """
    ...

def get_resize_output_image_size(
    input_image: torch.Tensor, shorter: int = ..., longer: int = ..., size_divisor: int = ...
) -> tuple[int, int]: ...

class BridgeTowerFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    """
    Args:
        size_divisor (`int`, *optional*, defaults to 32):
            The size by which to make sure both the height and width can be divided. Only has an effect if `do_resize`
            is set to `True`. Can be overridden by the `size_divisor` parameter in the `preprocess` method.
        do_pad (`bool`, *optional*, defaults to `True`):
            Whether to pad the image to the `(max_height, max_width)` of the images in the batch. Can be overridden by
            the `do_pad` parameter in the `preprocess` method.
    """

    size_divisor: int | None
    do_pad: bool | None
    ...

@auto_docstring
class BridgeTowerImageProcessorFast(BaseImageProcessorFast):
    resample = ...
    image_mean = ...
    image_std = ...
    size = ...
    default_to_square = ...
    crop_size = ...
    do_resize = ...
    do_center_crop = ...
    do_rescale = ...
    do_normalize = ...
    do_pad = ...
    size_divisor = ...
    valid_kwargs = BridgeTowerFastImageProcessorKwargs
    def __init__(self, **kwargs: Unpack[BridgeTowerFastImageProcessorKwargs]) -> None: ...
    @auto_docstring
    def preprocess(self, images: ImageInput, **kwargs: Unpack[BridgeTowerFastImageProcessorKwargs]) -> BatchFeature: ...
    def resize(
        self,
        image: torch.Tensor,
        size: SizeDict,
        size_divisor: int = ...,
        interpolation: F.InterpolationMode = ...,
        antialias: bool = ...,
        **kwargs,
    ) -> torch.Tensor:
        """
        Resize an image.

        Resizes the shorter side of the image to `size["shortest_edge"]` while preserving the aspect ratio. If the
        longer side is larger than the max size `(int(`size["shortest_edge"]` * 1333 / 800))`, the longer side is then
        resized to the max size while preserving the aspect ratio.

        Args:
            image (`torch.Tensor`):
                Image to resize.
            size (`SizeDict`):
                Dictionary in the format `{"height": int, "width": int}` specifying the size of the output image.
            size_divisor (`int`, *optional*, defaults to 32):
                The image is resized to a size that is a multiple of this value.
            resample (`InterpolationMode`, *optional*, defaults to `InterpolationMode.BILINEAR`):
                `InterpolationMode` filter to use when resizing the image e.g. `InterpolationMode.BICUBIC`.

        Returns:
            `torch.Tensor`: The resized image.
        """
        ...

    def center_crop(self, image: torch.Tensor, size: dict[str, int], **kwargs) -> torch.Tensor:
        """
        Center crop an image to `(size["height"], size["width"])`. If the input size is smaller than `crop_size` along
        any edge, the image is padded with 0's and then center cropped.

        Args:
            image (`torch.Tensor`):
                Image to center crop.
            size (`dict[str, int]`):
                Size of the output image in the form `{"height": h, "width": w}`.
        """
        ...

    def pad(
        self,
        images: list[torch.Tensor],
        constant_values: float | Iterable[float] = ...,
        return_pixel_mask: bool = ...,
        disable_grouping: bool | None = ...,
    ) -> tuple:
        """
        Pads a batch of images to the bottom and right of the image with zeros to the size of largest height and width
        in the batch and optionally returns their corresponding pixel mask.

        Args:
            image (`torch.Tensor`):
                Image to pad.
            constant_values (`float` or `Iterable[float]`, *optional*):
                The value to use for the padding if `mode` is `"constant"`.
            return_pixel_mask (`bool`, *optional*, defaults to `True`):
                Whether to return a pixel mask.
            disable_grouping (`bool`, *optional*, defaults to `False`):
                Whether to disable grouping of images by size.
            return_tensors (`str` or `TensorType`, *optional*):
                The type of tensors to return. Can be one of:
                    - Unset: Return a list of `np.ndarray`.
                    - `TensorType.TENSORFLOW` or `'tf'`: Return a batch of type `tf.Tensor`.
                    - `TensorType.PYTORCH` or `'pt'`: Return a batch of type `torch.Tensor`.
                    - `TensorType.NUMPY` or `'np'`: Return a batch of type `np.ndarray`.
                    - `TensorType.JAX` or `'jax'`: Return a batch of type `jax.numpy.ndarray`.
        """
        ...

    def to_dict(self):  # -> dict[str, Any]:
        ...

__all__ = ["BridgeTowerImageProcessorFast"]
