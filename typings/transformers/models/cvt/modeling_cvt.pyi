"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import nn
from ...modeling_outputs import ImageClassifierOutputWithNoAttention, ModelOutput
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_cvt import CvtConfig

"""PyTorch CvT model."""
logger = ...

@dataclass
@auto_docstring(
    custom_intro="""
    Base class for model's outputs, with potential hidden states and attentions.
    """
)
class BaseModelOutputWithCLSToken(ModelOutput):
    r"""
    cls_token_value (`torch.FloatTensor` of shape `(batch_size, 1, hidden_size)`):
        Classification token at the output of the last layer of the model.
    """

    last_hidden_state: torch.FloatTensor | None = ...
    cls_token_value: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor, ...] | None = ...

def drop_path(input: torch.Tensor, drop_prob: float = ..., training: bool = ...) -> torch.Tensor:
    """
    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).

    Comment by Ross Wightman: This is the same as the DropConnect impl I created for EfficientNet, etc networks,
    however, the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...
    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for changing the
    layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use 'survival rate' as the
    argument.
    """
    ...

class CvtDropPath(nn.Module):
    """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks)."""
    def __init__(self, drop_prob: float | None = ...) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...
    def extra_repr(self) -> str: ...

class CvtEmbeddings(nn.Module):
    """
    Construct the CvT embeddings.
    """
    def __init__(self, patch_size, num_channels, embed_dim, stride, padding, dropout_rate) -> None: ...
    def forward(self, pixel_values):  # -> Any:
        ...

class CvtConvEmbeddings(nn.Module):
    """
    Image to Conv Embedding.
    """
    def __init__(self, patch_size, num_channels, embed_dim, stride, padding) -> None: ...
    def forward(self, pixel_values):  # -> Any:
        ...

class CvtSelfAttentionConvProjection(nn.Module):
    def __init__(self, embed_dim, kernel_size, padding, stride) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class CvtSelfAttentionLinearProjection(nn.Module):
    def forward(self, hidden_state): ...

class CvtSelfAttentionProjection(nn.Module):
    def __init__(self, embed_dim, kernel_size, padding, stride, projection_method=...) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class CvtSelfAttention(nn.Module):
    def __init__(
        self,
        num_heads,
        embed_dim,
        kernel_size,
        padding_q,
        padding_kv,
        stride_q,
        stride_kv,
        qkv_projection_method,
        qkv_bias,
        attention_drop_rate,
        with_cls_token=...,
        **kwargs,
    ) -> None: ...
    def rearrange_for_multi_head_attention(self, hidden_state): ...
    def forward(self, hidden_state, height, width):  # -> Tensor:
        ...

class CvtSelfOutput(nn.Module):
    """
    The residual connection is defined in CvtLayer instead of here (as is the case with other models), due to the
    layernorm applied before each block.
    """
    def __init__(self, embed_dim, drop_rate) -> None: ...
    def forward(self, hidden_state, input_tensor):  # -> Any:
        ...

class CvtAttention(nn.Module):
    def __init__(
        self,
        num_heads,
        embed_dim,
        kernel_size,
        padding_q,
        padding_kv,
        stride_q,
        stride_kv,
        qkv_projection_method,
        qkv_bias,
        attention_drop_rate,
        drop_rate,
        with_cls_token=...,
    ) -> None: ...
    def prune_heads(self, heads):  # -> None:
        ...
    def forward(self, hidden_state, height, width):  # -> Any:
        ...

class CvtIntermediate(nn.Module):
    def __init__(self, embed_dim, mlp_ratio) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class CvtOutput(nn.Module):
    def __init__(self, embed_dim, mlp_ratio, drop_rate) -> None: ...
    def forward(self, hidden_state, input_tensor): ...

class CvtLayer(nn.Module):
    """
    CvtLayer composed by attention layers, normalization and multi-layer perceptrons (mlps).
    """
    def __init__(
        self,
        num_heads,
        embed_dim,
        kernel_size,
        padding_q,
        padding_kv,
        stride_q,
        stride_kv,
        qkv_projection_method,
        qkv_bias,
        attention_drop_rate,
        drop_rate,
        mlp_ratio,
        drop_path_rate,
        with_cls_token=...,
    ) -> None: ...
    def forward(self, hidden_state, height, width):  # -> Any:
        ...

class CvtStage(nn.Module):
    def __init__(self, config, stage) -> None: ...
    def forward(self, hidden_state):  # -> tuple[Tensor | Any, Tensor | None]:
        ...

class CvtEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self, pixel_values, output_hidden_states=..., return_dict=...
    ):  # -> tuple[Any | tuple[()] | tuple[Any, ...], ...] | BaseModelOutputWithCLSToken:
        ...

@auto_docstring
class CvtPreTrainedModel(PreTrainedModel):
    config: CvtConfig
    base_model_prefix = ...
    main_input_name = ...
    _no_split_modules = ...

@auto_docstring
class CvtModel(CvtPreTrainedModel):
    def __init__(self, config, add_pooling_layer=...) -> None:
        r"""
        add_pooling_layer (bool, *optional*, defaults to `True`):
            Whether to add a pooling layer
        """
        ...

    @auto_docstring
    def forward(
        self,
        pixel_values: torch.Tensor | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | BaseModelOutputWithCLSToken: ...

@auto_docstring(
    custom_intro="""
    Cvt Model transformer with an image classification head on top (a linear layer on top of the final hidden state of
    the [CLS] token) e.g. for ImageNet.
    """
)
class CvtForImageClassification(CvtPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        pixel_values: torch.Tensor | None = ...,
        labels: torch.Tensor | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | ImageClassifierOutputWithNoAttention:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
            Labels for computing the image classification/regression loss. Indices should be in `[0, ...,
            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If
            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).
        """
        ...

__all__ = ["CvtForImageClassification", "CvtModel", "CvtPreTrainedModel"]
