from dataclasses import dataclass

import torch
from torch import nn

from ...modeling_utils import PreTrainedAudioTokenizerBase
from ...utils import ModelOutput
from .configuration_dac import DacConfig

"""Transformers DAC model."""

@dataclass
class DacOutput(ModelOutput):
    loss: torch.FloatTensor | None = ...
    audio_values: torch.FloatTensor | None = ...
    quantized_representation: torch.FloatTensor | None = ...
    audio_codes: torch.LongTensor | None = ...
    projected_latents: torch.FloatTensor | None = ...

@dataclass
class DacEncoderOutput(ModelOutput):
    loss: torch.FloatTensor | None = ...
    quantized_representation: torch.FloatTensor | None = ...
    audio_codes: torch.FloatTensor | None = ...
    projected_latents: torch.FloatTensor | None = ...

@dataclass
class DacDecoderOutput(ModelOutput):
    audio_values: torch.FloatTensor | None = ...

class Snake1d(nn.Module):
    def __init__(self, hidden_dim) -> None: ...
    def forward(self, hidden_states): ...

class DacVectorQuantize(nn.Module):
    def __init__(self, config: DacConfig) -> None: ...
    def forward(self, hidden_state):  # -> tuple[Any, Tensor, Tensor, Tensor, Any]:

        ...
    def decode_latents(self, hidden_states):  # -> tuple[Any, Tensor]:
        ...

class DacResidualUnit(nn.Module):
    def __init__(self, dimension: int = ..., dilation: int = ...) -> None: ...
    def forward(self, hidden_state): ...

class DacEncoderBlock(nn.Module):
    def __init__(self, config: DacConfig, stride: int = ..., stride_index: int = ...) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class DacDecoderBlock(nn.Module):
    def __init__(self, config: DacConfig, stride: int = ..., stride_index: int = ...) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class DacResidualVectorQuantize(nn.Module):
    def __init__(self, config: DacConfig) -> None: ...
    def forward(
        self, hidden_state, n_quantizers: int | None = ...
    ):  # -> tuple[Any | Literal[0], Tensor, Tensor, Any | Literal[0], Any | Literal[0]]:

        ...
    def from_codes(self, audio_codes: torch.Tensor):  # -> tuple[float | Any, Tensor, Tensor]:

        ...
    def from_latents(self, latents: torch.Tensor):  # -> tuple[Any | Literal[0], Tensor]:

        ...

class DacDecoder(nn.Module):
    def __init__(self, config: DacConfig) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class DacEncoder(nn.Module):
    def __init__(self, config: DacConfig) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class DacPreTrainedModel(PreTrainedAudioTokenizerBase):
    config: DacConfig
    base_model_prefix = ...
    main_input_name = ...
    def apply_weight_norm(self):  # -> None:
        ...
    def remove_weight_norm(self):  # -> None:
        ...

class DacModel(DacPreTrainedModel):
    def __init__(self, config: DacConfig) -> None: ...
    def encode(
        self, input_values: torch.Tensor, n_quantizers: int | None = ..., return_dict: bool | None = ...
    ):  # -> tuple[Any, Any, Any, Any] | DacEncoderOutput:

        ...
    def decode(
        self,
        quantized_representation: torch.Tensor | None = ...,
        audio_codes: torch.Tensor | None = ...,
        return_dict: bool | None = ...,
    ):  # -> tuple[Any] | DacDecoderOutput:

        ...
    def forward(
        self, input_values: torch.Tensor, n_quantizers: int | None = ..., return_dict: bool | None = ...
    ):  # -> tuple[Any, Any, Any, Any, Any] | DacOutput:

        ...

__all__ = ["DacModel", "DacPreTrainedModel"]
