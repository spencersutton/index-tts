"""
This type stub file was generated by pyright.
"""

import torch
import torch.nn as nn
from typing import Optional, Union
from ...cache_utils import Cache
from ...image_processing_utils_fast import BatchFeature, DefaultFastImageProcessorKwargs
from ...image_utils import ChannelDimension, ImageInput, PILImageResampling
from ...processing_utils import Unpack
from ...tokenization_utils_base import PreTokenizedInput, TextInput
from ...utils import (
    TensorType,
    TransformersKwargs,
    auto_docstring,
    can_return_tuple,
    filter_out_non_signature_kwargs,
    is_torchvision_v2_available,
)
from ..auto import AutoConfig
from ..deepseek_vl.configuration_deepseek_vl import DeepseekVLConfig
from ..deepseek_vl.image_processing_deepseek_vl import DeepseekVLImageProcessor
from ..deepseek_vl.image_processing_deepseek_vl_fast import DeepseekVLImageProcessorFast
from ..deepseek_vl.modeling_deepseek_vl import (
    DeepseekVLForConditionalGeneration,
    DeepseekVLModel,
    DeepseekVLPreTrainedModel,
)
from ..deepseek_vl.processing_deepseek_vl import DeepseekVLProcessor, DeepseekVLProcessorKwargs
from ..idefics.modeling_idefics import IdeficsBaseModelOutputWithPast, IdeficsCausalLMOutputWithPast
from ..sam.modeling_sam import SamLayerNorm, SamVisionNeck

if is_torchvision_v2_available(): ...
else: ...
logger = ...
DEEPSEEK_VL_COMMON_CUSTOM_ARGS = ...

class DeepseekVLHybridConfig(DeepseekVLConfig):
    model_type = ...
    sub_configs = ...
    def __init__(
        self,
        text_config: AutoConfig = ...,
        vision_config: AutoConfig = ...,
        high_res_vision_config: AutoConfig = ...,
        image_token_id: int = ...,
        **kwargs,
    ) -> None: ...

class DeepseekVLHybridBaseModelOutputWithPast(IdeficsBaseModelOutputWithPast): ...
class DeepseekVLHybridCausalLMOutputWithPast(IdeficsCausalLMOutputWithPast): ...
class DeepseekVLHybridLayerNorm(SamLayerNorm): ...

class DeepseekVLSamVisionNeck(SamVisionNeck):
    def __init__(self, config) -> None: ...

class DeepseekVLSamVisionProj(nn.Module):
    def __init__(self, config, output_size: int = ...) -> None: ...
    def forward(self, features: torch.Tensor) -> torch.Tensor: ...

class DeepseekVLHybridAligner(nn.Module):
    def __init__(self, config: DeepseekVLHybridConfig) -> None: ...
    def forward(self, vision_encodings: torch.Tensor, high_res_vision_encodings: torch.Tensor) -> torch.Tensor: ...

class DeepseekVLHybridPreTrainedModel(DeepseekVLPreTrainedModel): ...

class DeepseekVLHybridModel(DeepseekVLModel):
    def __init__(self, config) -> None: ...
    def get_low_res_image_features(self, pixel_values): ...
    def get_high_res_image_features(self, pixel_values): ...
    def get_image_features(self, pixel_values, high_res_pixel_values): ...
    @can_return_tuple
    @auto_docstring(custom_args=DEEPSEEK_VL_COMMON_CUSTOM_ARGS)
    def forward(
        self,
        input_ids: torch.LongTensor = ...,
        pixel_values: torch.FloatTensor = ...,
        high_res_pixel_values: torch.FloatTensor = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        cache_position: Optional[torch.LongTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        use_cache: Optional[bool] = ...,
        logits_to_keep: Union[int, torch.Tensor] = ...,
        **kwargs,
    ): ...

class DeepseekVLHybridForConditionalGeneration(DeepseekVLForConditionalGeneration):
    @can_return_tuple
    @auto_docstring(custom_args=DEEPSEEK_VL_COMMON_CUSTOM_ARGS)
    def forward(
        self,
        input_ids: torch.LongTensor = ...,
        pixel_values: torch.FloatTensor = ...,
        high_res_pixel_values: torch.FloatTensor = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        cache_position: Optional[torch.LongTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        use_cache: Optional[bool] = ...,
        logits_to_keep: Union[int, torch.Tensor] = ...,
        **kwargs: Unpack[TransformersKwargs],
    ): ...
    def prepare_inputs_for_generation(
        self,
        input_ids,
        past_key_values=...,
        inputs_embeds=...,
        pixel_values=...,
        high_res_pixel_values=...,
        attention_mask=...,
        cache_position=...,
        logits_to_keep=...,
        **kwargs,
    ): ...

class DeepseekVLHybridImageProcessor(DeepseekVLImageProcessor):
    def __init__(
        self,
        do_resize: bool = ...,
        size: Optional[dict[str, int]] = ...,
        high_res_size: Optional[dict[str, int]] = ...,
        min_size: int = ...,
        resample: PILImageResampling = ...,
        high_res_resample: PILImageResampling = ...,
        do_rescale: bool = ...,
        rescale_factor: float = ...,
        do_normalize: bool = ...,
        image_mean: Optional[Union[float, list[float]]] = ...,
        image_std: Optional[Union[float, list[float]]] = ...,
        high_res_image_mean: Optional[Union[float, list[float]]] = ...,
        high_res_image_std: Optional[Union[float, list[float]]] = ...,
        do_convert_rgb: Optional[bool] = ...,
        **kwargs,
    ) -> None: ...
    @filter_out_non_signature_kwargs()
    def preprocess(
        self,
        images: ImageInput,
        do_resize: Optional[bool] = ...,
        size: Optional[dict[str, int]] = ...,
        high_res_size: Optional[dict[str, int]] = ...,
        resample: PILImageResampling = ...,
        high_res_resample: PILImageResampling = ...,
        do_rescale: Optional[bool] = ...,
        rescale_factor: Optional[float] = ...,
        do_normalize: Optional[bool] = ...,
        image_mean: Optional[Union[float, list[float]]] = ...,
        image_std: Optional[Union[float, list[float]]] = ...,
        high_res_image_mean: Optional[Union[float, list[float]]] = ...,
        high_res_image_std: Optional[Union[float, list[float]]] = ...,
        return_tensors: Optional[Union[str, TensorType]] = ...,
        data_format: Union[str, ChannelDimension] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        do_convert_rgb: Optional[bool] = ...,
    ): ...

class DeepseekVLHybridFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    min_size: int
    high_res_size: dict
    high_res_resample: PILImageResampling
    high_res_image_mean: list[float]
    high_res_image_std: list[float]
    ...

class DeepseekVLHybridImageProcessorFast(DeepseekVLImageProcessorFast):
    high_res_image_mean = ...
    high_res_image_std = ...
    high_res_size = ...
    high_res_resample = ...
    def __init__(self, **kwargs: Unpack[DeepseekVLHybridFastImageProcessorKwargs]) -> None: ...

class DeepseekVLHybridProcessorKwargs(DeepseekVLProcessorKwargs): ...

class DeepseekVLHybridProcessor(DeepseekVLProcessor):
    def __call__(
        self,
        text: Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput]] = ...,
        images: ImageInput = ...,
        **kwargs: Unpack[DeepseekVLHybridProcessorKwargs],
    ) -> BatchFeature: ...

__all__ = [
    "DeepseekVLHybridConfig",
    "DeepseekVLHybridPreTrainedModel",
    "DeepseekVLHybridModel",
    "DeepseekVLHybridForConditionalGeneration",
    "DeepseekVLHybridImageProcessor",
    "DeepseekVLHybridImageProcessorFast",
    "DeepseekVLHybridProcessor",
]
