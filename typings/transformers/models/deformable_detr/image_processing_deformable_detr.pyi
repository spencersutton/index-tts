"""
This type stub file was generated by pyright.
"""

import pathlib
import numpy as np
from collections.abc import Iterable
from typing import Any, Callable, Optional, Union
from ...feature_extraction_utils import BatchFeature
from ...image_processing_utils import BaseImageProcessor
from ...image_utils import AnnotationFormat, AnnotationType, ChannelDimension, ImageInput, PILImageResampling
from ...utils import TensorType, is_scipy_available, is_torch_available, is_vision_available
from ...utils.import_utils import requires

if is_torch_available(): ...
if is_vision_available(): ...
if is_scipy_available(): ...
logger = ...
SUPPORTED_ANNOTATION_FORMATS = ...

def get_size_with_aspect_ratio(image_size, size, max_size=...) -> tuple[int, int]: ...
def get_resize_output_image_size(
    input_image: np.ndarray,
    size: Union[int, tuple[int, int], list[int]],
    max_size: Optional[int] = ...,
    input_data_format: Optional[Union[str, ChannelDimension]] = ...,
) -> tuple[int, int]: ...
def get_image_size_for_max_height_width(
    input_image: np.ndarray,
    max_height: int,
    max_width: int,
    input_data_format: Optional[Union[str, ChannelDimension]] = ...,
) -> tuple[int, int]: ...
def get_numpy_to_framework_fn(arr) -> Callable: ...
def safe_squeeze(arr: np.ndarray, axis: Optional[int] = ...) -> np.ndarray: ...
def normalize_annotation(annotation: dict, image_size: tuple[int, int]) -> dict: ...
def max_across_indices(values: Iterable[Any]) -> list[Any]: ...
def get_max_height_width(
    images: list[np.ndarray], input_data_format: Optional[Union[str, ChannelDimension]] = ...
) -> list[int]: ...
def make_pixel_mask(
    image: np.ndarray, output_size: tuple[int, int], input_data_format: Optional[Union[str, ChannelDimension]] = ...
) -> np.ndarray: ...
def convert_coco_poly_to_mask(segmentations, height: int, width: int) -> np.ndarray: ...
def prepare_coco_detection_annotation(
    image,
    target,
    return_segmentation_masks: bool = ...,
    input_data_format: Optional[Union[ChannelDimension, str]] = ...,
): ...
def masks_to_boxes(masks: np.ndarray) -> np.ndarray: ...
def prepare_coco_panoptic_annotation(
    image: np.ndarray,
    target: dict,
    masks_path: Union[str, pathlib.Path],
    return_masks: bool = ...,
    input_data_format: Union[ChannelDimension, str] = ...,
) -> dict: ...
def get_segmentation_image(
    masks: np.ndarray, input_size: tuple, target_size: tuple, stuff_equiv_classes, deduplicate=...
): ...
def get_mask_area(seg_img: np.ndarray, target_size: tuple[int, int], n_classes: int) -> np.ndarray: ...
def score_labels_from_class_probabilities(logits: np.ndarray) -> tuple[np.ndarray, np.ndarray]: ...
def post_process_panoptic_sample(
    out_logits: np.ndarray,
    masks: np.ndarray,
    boxes: np.ndarray,
    processed_size: tuple[int, int],
    target_size: tuple[int, int],
    is_thing_map: dict,
    threshold=...,
) -> dict: ...
def resize_annotation(
    annotation: dict[str, Any],
    orig_size: tuple[int, int],
    target_size: tuple[int, int],
    threshold: float = ...,
    resample: PILImageResampling = ...,
): ...
def binary_mask_to_rle(mask): ...
def convert_segmentation_to_rle(segmentation): ...
def remove_low_and_no_objects(masks, scores, labels, object_mask_threshold, num_labels): ...
def check_segment_validity(mask_labels, mask_probs, k, mask_threshold=..., overlap_mask_area_threshold=...): ...
def compute_segments(
    mask_probs,
    pred_scores,
    pred_labels,
    mask_threshold: float = ...,
    overlap_mask_area_threshold: float = ...,
    label_ids_to_fuse: Optional[set[int]] = ...,
    target_size: Optional[tuple[int, int]] = ...,
): ...

@requires(backends=("torch", "vision"))
class DeformableDetrImageProcessor(BaseImageProcessor):
    model_input_names = ...
    def __init__(
        self,
        format: Union[str, AnnotationFormat] = ...,
        do_resize: bool = ...,
        size: Optional[dict[str, int]] = ...,
        resample: PILImageResampling = ...,
        do_rescale: bool = ...,
        rescale_factor: float = ...,
        do_normalize: bool = ...,
        image_mean: Optional[Union[float, list[float]]] = ...,
        image_std: Optional[Union[float, list[float]]] = ...,
        do_convert_annotations: Optional[bool] = ...,
        do_pad: bool = ...,
        pad_size: Optional[dict[str, int]] = ...,
        **kwargs,
    ) -> None: ...
    @classmethod
    def from_dict(cls, image_processor_dict: dict[str, Any], **kwargs): ...
    def prepare_annotation(
        self,
        image: np.ndarray,
        target: dict,
        format: Optional[AnnotationFormat] = ...,
        return_segmentation_masks: Optional[bool] = ...,
        masks_path: Optional[Union[str, pathlib.Path]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
    ) -> dict: ...
    def resize(
        self,
        image: np.ndarray,
        size: dict[str, int],
        resample: PILImageResampling = ...,
        data_format: Optional[ChannelDimension] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        **kwargs,
    ) -> np.ndarray: ...
    def resize_annotation(self, annotation, orig_size, size, resample: PILImageResampling = ...) -> dict: ...
    def rescale(
        self,
        image: np.ndarray,
        rescale_factor: float,
        data_format: Optional[Union[str, ChannelDimension]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
    ) -> np.ndarray: ...
    def normalize_annotation(self, annotation: dict, image_size: tuple[int, int]) -> dict: ...
    def pad(
        self,
        images: list[np.ndarray],
        annotations: Optional[Union[AnnotationType, list[AnnotationType]]] = ...,
        constant_values: Union[float, Iterable[float]] = ...,
        return_pixel_mask: bool = ...,
        return_tensors: Optional[Union[str, TensorType]] = ...,
        data_format: Optional[ChannelDimension] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        update_bboxes: bool = ...,
        pad_size: Optional[dict[str, int]] = ...,
    ) -> BatchFeature: ...
    def preprocess(
        self,
        images: ImageInput,
        annotations: Optional[Union[AnnotationType, list[AnnotationType]]] = ...,
        return_segmentation_masks: Optional[bool] = ...,
        masks_path: Optional[Union[str, pathlib.Path]] = ...,
        do_resize: Optional[bool] = ...,
        size: Optional[dict[str, int]] = ...,
        resample=...,
        do_rescale: Optional[bool] = ...,
        rescale_factor: Optional[Union[int, float]] = ...,
        do_normalize: Optional[bool] = ...,
        do_convert_annotations: Optional[bool] = ...,
        image_mean: Optional[Union[float, list[float]]] = ...,
        image_std: Optional[Union[float, list[float]]] = ...,
        do_pad: Optional[bool] = ...,
        format: Optional[Union[str, AnnotationFormat]] = ...,
        return_tensors: Optional[Union[TensorType, str]] = ...,
        data_format: Union[str, ChannelDimension] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        pad_size: Optional[dict[str, int]] = ...,
        **kwargs,
    ) -> BatchFeature: ...
    def post_process(self, outputs, target_sizes): ...
    def post_process_object_detection(
        self, outputs, threshold: float = ..., target_sizes: Union[TensorType, list[tuple]] = ..., top_k: int = ...
    ): ...

__all__ = ["DeformableDetrImageProcessor"]
