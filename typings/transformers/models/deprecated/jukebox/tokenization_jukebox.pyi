"""
This type stub file was generated by pyright.
"""

from typing import Any, Optional, Union
from ....tokenization_utils import PreTrainedTokenizer
from ....tokenization_utils_base import BatchEncoding
from ....utils import TensorType

logger = ...
VOCAB_FILES_NAMES = ...

class JukeboxTokenizer(PreTrainedTokenizer):
    vocab_files_names = ...
    model_input_names = ...
    def __init__(
        self,
        artists_file,
        genres_file,
        lyrics_file,
        version=...,
        max_n_lyric_tokens=...,
        n_genres=...,
        unk_token=...,
        **kwargs,
    ) -> None: ...
    @property
    def vocab_size(self): ...
    def get_vocab(self): ...
    def tokenize(self, artist, genre, lyrics, **kwargs): ...
    def prepare_for_tokenization(
        self, artists: str, genres: str, lyrics: str, is_split_into_words: bool = ...
    ) -> tuple[str, str, str, dict[str, Any]]: ...
    def convert_lyric_tokens_to_string(self, lyrics: list[str]) -> str: ...
    def convert_to_tensors(
        self, inputs, tensor_type: Optional[Union[str, TensorType]] = ..., prepend_batch_axis: bool = ...
    ): ...
    def __call__(self, artist, genres, lyrics=..., return_tensors=...) -> BatchEncoding: ...
    def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = ...) -> tuple[str]: ...

__all__ = ["JukeboxTokenizer"]
