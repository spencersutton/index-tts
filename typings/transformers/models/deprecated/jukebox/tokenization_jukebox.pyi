from typing import Any

from ....tokenization_utils import PreTrainedTokenizer
from ....tokenization_utils_base import BatchEncoding
from ....utils import TensorType

"""Tokenization classes for OpenAI Jukebox."""
logger = ...
VOCAB_FILES_NAMES = ...

class JukeboxTokenizer(PreTrainedTokenizer):
    vocab_files_names = ...
    model_input_names = ...
    def __init__(
        self,
        artists_file,
        genres_file,
        lyrics_file,
        version=...,
        max_n_lyric_tokens=...,
        n_genres=...,
        unk_token=...,
        **kwargs,
    ) -> None: ...
    @property
    def vocab_size(self):  # -> int:
        ...
    def get_vocab(self):  # -> dict[str, Any | dict[str, int]]:
        ...
    def tokenize(self, artist, genre, lyrics, **kwargs):  # -> tuple[str, str, list[Any]]:

        ...
    def prepare_for_tokenization(
        self, artists: str, genres: str, lyrics: str, is_split_into_words: bool = ...
    ) -> tuple[str, str, str, dict[str, Any]]: ...
    def convert_lyric_tokens_to_string(self, lyrics: list[str]) -> str: ...
    def convert_to_tensors(
        self, inputs, tensor_type: str | TensorType | None = ..., prepend_batch_axis: bool = ...
    ):  # -> NDArray[Any] | Tensor | list[Any]:

        ...
    def __call__(self, artist, genres, lyrics=..., return_tensors=...) -> BatchEncoding: ...
    def save_vocabulary(self, save_directory: str, filename_prefix: str | None = ...) -> tuple[str]: ...

__all__ = ["JukeboxTokenizer"]
