"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import nn
from ....modeling_outputs import BackboneOutput
from ....modeling_utils import PreTrainedModel
from ....utils import (
    ModelOutput,
    add_code_sample_docstrings,
    add_start_docstrings,
    add_start_docstrings_to_model_forward,
    is_natten_available,
    replace_return_docstrings,
)
from ....utils.backbone_utils import BackboneMixin
from .configuration_nat import NatConfig

if is_natten_available(): ...
else:
    def natten2dqkrpb(*args, **kwargs): ...
    def natten2dav(*args, **kwargs): ...

logger = ...
_CONFIG_FOR_DOC = ...
_CHECKPOINT_FOR_DOC = ...
_EXPECTED_OUTPUT_SHAPE = ...
_IMAGE_CLASS_CHECKPOINT = ...
_IMAGE_CLASS_EXPECTED_OUTPUT = ...

@dataclass
class NatEncoderOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    reshaped_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...

@dataclass
class NatModelOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    pooler_output: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    reshaped_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...

@dataclass
class NatImageClassifierOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    reshaped_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...

class NatEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values: Optional[torch.FloatTensor]) -> tuple[torch.Tensor]: ...

class NatPatchEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values: Optional[torch.FloatTensor]) -> torch.Tensor: ...

class NatDownsampler(nn.Module):
    def __init__(self, dim: int, norm_layer: nn.Module = ...) -> None: ...
    def forward(self, input_feature: torch.Tensor) -> torch.Tensor: ...

def drop_path(input: torch.Tensor, drop_prob: float = ..., training: bool = ...) -> torch.Tensor: ...

class NatDropPath(nn.Module):
    def __init__(self, drop_prob: Optional[float] = ...) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...
    def extra_repr(self) -> str: ...

class NeighborhoodAttention(nn.Module):
    def __init__(self, config, dim, num_heads, kernel_size) -> None: ...
    def transpose_for_scores(self, x): ...
    def forward(self, hidden_states: torch.Tensor, output_attentions: Optional[bool] = ...) -> tuple[torch.Tensor]: ...

class NeighborhoodAttentionOutput(nn.Module):
    def __init__(self, config, dim) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class NeighborhoodAttentionModule(nn.Module):
    def __init__(self, config, dim, num_heads, kernel_size) -> None: ...
    def prune_heads(self, heads): ...
    def forward(self, hidden_states: torch.Tensor, output_attentions: Optional[bool] = ...) -> tuple[torch.Tensor]: ...

class NatIntermediate(nn.Module):
    def __init__(self, config, dim) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class NatOutput(nn.Module):
    def __init__(self, config, dim) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class NatLayer(nn.Module):
    def __init__(self, config, dim, num_heads, drop_path_rate=...) -> None: ...
    def maybe_pad(self, hidden_states, height, width): ...
    def forward(
        self, hidden_states: torch.Tensor, output_attentions: Optional[bool] = ...
    ) -> tuple[torch.Tensor, torch.Tensor]: ...

class NatStage(nn.Module):
    def __init__(self, config, dim, depth, num_heads, drop_path_rate, downsample) -> None: ...
    def forward(self, hidden_states: torch.Tensor, output_attentions: Optional[bool] = ...) -> tuple[torch.Tensor]: ...

class NatEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        output_hidden_states_before_downsampling: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, NatEncoderOutput]: ...

class NatPreTrainedModel(PreTrainedModel):
    config: NatConfig
    base_model_prefix = ...
    main_input_name = ...

NAT_START_DOCSTRING = ...
NAT_INPUTS_DOCSTRING = ...

@add_start_docstrings(..., NAT_START_DOCSTRING)
class NatModel(NatPreTrainedModel):
    def __init__(self, config, add_pooling_layer=...) -> None: ...
    def get_input_embeddings(self): ...
    @add_start_docstrings_to_model_forward(NAT_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_CHECKPOINT_FOR_DOC,
        output_type=NatModelOutput,
        config_class=_CONFIG_FOR_DOC,
        modality="vision",
        expected_output=_EXPECTED_OUTPUT_SHAPE,
    )
    def forward(
        self,
        pixel_values: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, NatModelOutput]: ...

@add_start_docstrings(..., NAT_START_DOCSTRING)
class NatForImageClassification(NatPreTrainedModel):
    def __init__(self, config) -> None: ...
    @add_start_docstrings_to_model_forward(NAT_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_IMAGE_CLASS_CHECKPOINT,
        output_type=NatImageClassifierOutput,
        config_class=_CONFIG_FOR_DOC,
        expected_output=_IMAGE_CLASS_EXPECTED_OUTPUT,
    )
    def forward(
        self,
        pixel_values: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, NatImageClassifierOutput]: ...

@add_start_docstrings(..., NAT_START_DOCSTRING)
class NatBackbone(NatPreTrainedModel, BackboneMixin):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    @add_start_docstrings_to_model_forward(NAT_INPUTS_DOCSTRING)
    @replace_return_docstrings(output_type=BackboneOutput, config_class=_CONFIG_FOR_DOC)
    def forward(
        self,
        pixel_values: torch.Tensor,
        output_hidden_states: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> BackboneOutput: ...

__all__ = ["NatForImageClassification", "NatModel", "NatPreTrainedModel", "NatBackbone"]
