from dataclasses import dataclass

import torch
from torch import nn

from ....modeling_outputs import BackboneOutput
from ....modeling_utils import PreTrainedModel
from ....utils import (
    ModelOutput,
    add_code_sample_docstrings,
    add_start_docstrings,
    add_start_docstrings_to_model_forward,
    is_natten_available,
    replace_return_docstrings,
)
from ....utils.backbone_utils import BackboneMixin
from .configuration_nat import NatConfig

"""PyTorch Neighborhood Attention Transformer model."""
if is_natten_available(): ...
else:
    def natten2dqkrpb(*args, **kwargs): ...
    def natten2dav(*args, **kwargs): ...

logger = ...
_CONFIG_FOR_DOC = ...
_CHECKPOINT_FOR_DOC = ...
_EXPECTED_OUTPUT_SHAPE = ...
_IMAGE_CLASS_CHECKPOINT = ...
_IMAGE_CLASS_EXPECTED_OUTPUT = ...

@dataclass
class NatEncoderOutput(ModelOutput):
    last_hidden_state: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor, ...] | None = ...
    attentions: tuple[torch.FloatTensor, ...] | None = ...
    reshaped_hidden_states: tuple[torch.FloatTensor, ...] | None = ...

@dataclass
class NatModelOutput(ModelOutput):
    last_hidden_state: torch.FloatTensor | None = ...
    pooler_output: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor, ...] | None = ...
    attentions: tuple[torch.FloatTensor, ...] | None = ...
    reshaped_hidden_states: tuple[torch.FloatTensor, ...] | None = ...

@dataclass
class NatImageClassifierOutput(ModelOutput):
    loss: torch.FloatTensor | None = ...
    logits: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor, ...] | None = ...
    attentions: tuple[torch.FloatTensor, ...] | None = ...
    reshaped_hidden_states: tuple[torch.FloatTensor, ...] | None = ...

class NatEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values: torch.FloatTensor | None) -> tuple[torch.Tensor]: ...

class NatPatchEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values: torch.FloatTensor | None) -> torch.Tensor: ...

class NatDownsampler(nn.Module):
    def __init__(self, dim: int, norm_layer: nn.Module = ...) -> None: ...
    def forward(self, input_feature: torch.Tensor) -> torch.Tensor: ...

def drop_path(input: torch.Tensor, drop_prob: float = ..., training: bool = ...) -> torch.Tensor: ...

class NatDropPath(nn.Module):
    def __init__(self, drop_prob: float | None = ...) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...
    def extra_repr(self) -> str: ...

class NeighborhoodAttention(nn.Module):
    def __init__(self, config, dim, num_heads, kernel_size) -> None: ...
    def transpose_for_scores(self, x): ...
    def forward(self, hidden_states: torch.Tensor, output_attentions: bool | None = ...) -> tuple[torch.Tensor]: ...

class NeighborhoodAttentionOutput(nn.Module):
    def __init__(self, config, dim) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class NeighborhoodAttentionModule(nn.Module):
    def __init__(self, config, dim, num_heads, kernel_size) -> None: ...
    def prune_heads(self, heads):  # -> None:
        ...
    def forward(self, hidden_states: torch.Tensor, output_attentions: bool | None = ...) -> tuple[torch.Tensor]: ...

class NatIntermediate(nn.Module):
    def __init__(self, config, dim) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class NatOutput(nn.Module):
    def __init__(self, config, dim) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class NatLayer(nn.Module):
    def __init__(self, config, dim, num_heads, drop_path_rate=...) -> None: ...
    def maybe_pad(
        self, hidden_states, height, width
    ):  # -> tuple[Any, tuple[Literal[0], Literal[0], Literal[0], int, Literal[0], int] | tuple[Literal[0], Literal[0], Literal[0], Literal[0], Literal[0], Literal[0]]]:
        ...
    def forward(
        self, hidden_states: torch.Tensor, output_attentions: bool | None = ...
    ) -> tuple[torch.Tensor, torch.Tensor]: ...

class NatStage(nn.Module):
    def __init__(self, config, dim, depth, num_heads, drop_path_rate, downsample) -> None: ...
    def forward(self, hidden_states: torch.Tensor, output_attentions: bool | None = ...) -> tuple[torch.Tensor]: ...

class NatEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        output_hidden_states_before_downsampling: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | NatEncoderOutput: ...

class NatPreTrainedModel(PreTrainedModel):
    config: NatConfig
    base_model_prefix = ...
    main_input_name = ...

NAT_START_DOCSTRING = ...
NAT_INPUTS_DOCSTRING = ...

@add_start_docstrings(..., NAT_START_DOCSTRING)
class NatModel(NatPreTrainedModel):
    def __init__(self, config, add_pooling_layer=...) -> None: ...
    def get_input_embeddings(self):  # -> NatPatchEmbeddings:
        ...
    @add_start_docstrings_to_model_forward(NAT_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_CHECKPOINT_FOR_DOC,
        output_type=NatModelOutput,
        config_class=_CONFIG_FOR_DOC,
        modality="vision",
        expected_output=_EXPECTED_OUTPUT_SHAPE,
    )
    def forward(
        self,
        pixel_values: torch.FloatTensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | NatModelOutput: ...

@add_start_docstrings(
    ...,
    NAT_START_DOCSTRING,
)
class NatForImageClassification(NatPreTrainedModel):
    def __init__(self, config) -> None: ...
    @add_start_docstrings_to_model_forward(NAT_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_IMAGE_CLASS_CHECKPOINT,
        output_type=NatImageClassifierOutput,
        config_class=_CONFIG_FOR_DOC,
        expected_output=_IMAGE_CLASS_EXPECTED_OUTPUT,
    )
    def forward(
        self,
        pixel_values: torch.FloatTensor | None = ...,
        labels: torch.LongTensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | NatImageClassifierOutput: ...

@add_start_docstrings(..., NAT_START_DOCSTRING)
class NatBackbone(NatPreTrainedModel, BackboneMixin):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self):  # -> NatPatchEmbeddings:
        ...
    @add_start_docstrings_to_model_forward(NAT_INPUTS_DOCSTRING)
    @replace_return_docstrings(output_type=BackboneOutput, config_class=_CONFIG_FOR_DOC)
    def forward(
        self,
        pixel_values: torch.Tensor,
        output_hidden_states: bool | None = ...,
        output_attentions: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> BackboneOutput: ...

__all__ = ["NatBackbone", "NatForImageClassification", "NatModel", "NatPreTrainedModel"]
