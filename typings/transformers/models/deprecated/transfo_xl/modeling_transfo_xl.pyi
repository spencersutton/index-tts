"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import nn
from ....modeling_utils import PreTrainedModel
from ....utils import (
    ModelOutput,
    add_code_sample_docstrings,
    add_start_docstrings,
    add_start_docstrings_to_model_forward,
)
from .configuration_transfo_xl import TransfoXLConfig

logger = ...
_CHECKPOINT_FOR_DOC = ...
_CONFIG_FOR_DOC = ...

def build_tf_to_pytorch_map(model, config): ...
def load_tf_weights_in_transfo_xl(model, config, tf_path): ...

class PositionalEmbedding(nn.Module):
    def __init__(self, demb) -> None: ...
    def forward(self, pos_seq, bsz=...): ...

class PositionwiseFF(nn.Module):
    def __init__(self, d_model, d_inner, dropout, pre_lnorm=..., layer_norm_epsilon=...) -> None: ...
    def forward(self, inp): ...

class RelPartialLearnableMultiHeadAttn(nn.Module):
    def __init__(
        self,
        n_head,
        d_model,
        d_head,
        dropout,
        dropatt=...,
        pre_lnorm=...,
        r_r_bias=...,
        r_w_bias=...,
        layer_norm_epsilon=...,
    ) -> None: ...
    def forward(self, w, r, attn_mask=..., mems=..., head_mask=..., output_attentions=...): ...

class RelPartialLearnableDecoderLayer(nn.Module):
    def __init__(self, n_head, d_model, d_head, d_inner, dropout, layer_norm_epsilon=..., **kwargs) -> None: ...
    def forward(self, dec_inp, r, dec_attn_mask=..., mems=..., head_mask=..., output_attentions=...): ...

class AdaptiveEmbedding(nn.Module):
    def __init__(self, n_token, d_embed, d_proj, cutoffs, div_val=..., sample_softmax=...) -> None: ...
    def forward(self, inp): ...

class TransfoXLPreTrainedModel(PreTrainedModel):
    config: TransfoXLConfig
    load_tf_weights = ...
    base_model_prefix = ...
    def resize_token_embeddings(self, new_num_tokens: Optional[int] = ..., layer: Optional[int] = ...): ...

@dataclass
class TransfoXLModelOutput(ModelOutput):
    last_hidden_state: torch.FloatTensor
    mems: list[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
class TransfoXLSequenceClassifierOutputWithPast(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    mems: list[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
class TransfoXLLMHeadModelOutput(ModelOutput):
    losses: Optional[torch.FloatTensor] = ...
    prediction_scores: Optional[torch.FloatTensor] = ...
    mems: list[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...
    loss: Optional[torch.FloatTensor] = ...
    @property
    def logits(self): ...

TRANSFO_XL_START_DOCSTRING = ...
TRANSFO_XL_INPUTS_DOCSTRING = ...

@add_start_docstrings(..., TRANSFO_XL_START_DOCSTRING)
class TransfoXLModel(TransfoXLPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, new_embeddings): ...
    def backward_compatible(self): ...
    def reset_memory_length(self, mem_len): ...
    def init_mems(self, bsz): ...
    @add_start_docstrings_to_model_forward(TRANSFO_XL_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_CHECKPOINT_FOR_DOC, output_type=TransfoXLModelOutput, config_class=_CONFIG_FOR_DOC
    )
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        mems: Optional[list[torch.FloatTensor]] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, TransfoXLModelOutput]: ...

@add_start_docstrings(..., TRANSFO_XL_START_DOCSTRING)
class TransfoXLLMHeadModel(TransfoXLPreTrainedModel):
    _tied_weights_keys = ...
    def __init__(self, config) -> None: ...
    def tie_weights(self): ...
    def reset_memory_length(self, mem_len): ...
    def init_mems(self, bsz): ...
    @add_start_docstrings_to_model_forward(TRANSFO_XL_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_CHECKPOINT_FOR_DOC, output_type=TransfoXLLMHeadModelOutput, config_class=_CONFIG_FOR_DOC
    )
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        mems: Optional[list[torch.FloatTensor]] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, TransfoXLLMHeadModelOutput]: ...
    def get_output_embeddings(self): ...
    def prepare_inputs_for_generation(self, input_ids, past_key_values=..., **model_kwargs): ...

@add_start_docstrings(..., TRANSFO_XL_START_DOCSTRING)
class TransfoXLForSequenceClassification(TransfoXLPreTrainedModel):
    def __init__(self, config) -> None: ...
    @add_start_docstrings_to_model_forward(TRANSFO_XL_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_CHECKPOINT_FOR_DOC,
        output_type=TransfoXLSequenceClassifierOutputWithPast,
        config_class=_CONFIG_FOR_DOC,
    )
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        mems: Optional[list[torch.FloatTensor]] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, TransfoXLSequenceClassifierOutputWithPast]: ...

__all__ = [
    "AdaptiveEmbedding",
    "TransfoXLForSequenceClassification",
    "TransfoXLLMHeadModel",
    "TransfoXLModel",
    "TransfoXLPreTrainedModel",
    "load_tf_weights_in_transfo_xl",
]
