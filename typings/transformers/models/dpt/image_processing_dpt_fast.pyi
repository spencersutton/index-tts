"""
This type stub file was generated by pyright.
"""

import torch
from collections.abc import Iterable
from typing import Optional, TYPE_CHECKING, Union
from transformers.image_processing_base import BatchFeature
from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs
from ...image_utils import ImageInput, SizeDict
from ...processing_utils import Unpack
from ...utils import TensorType, auto_docstring, is_torch_available, is_torchvision_v2_available
from ...modeling_outputs import DepthEstimatorOutput
from torchvision.transforms.v2 import functional as F
from torchvision.transforms import functional as F

if TYPE_CHECKING: ...
if is_torch_available(): ...
if is_torchvision_v2_available(): ...
else: ...

class DPTFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    ensure_multiple_of: Optional[int]
    size_divisor: Optional[int]
    do_pad: Optional[bool]
    keep_aspect_ratio: Optional[bool]
    do_reduce_labels: Optional[bool]
    ...

def get_resize_output_image_size(
    input_image: torch.Tensor, output_size: Union[int, Iterable[int]], keep_aspect_ratio: bool, multiple: int
) -> SizeDict: ...

@auto_docstring
class DPTImageProcessorFast(BaseImageProcessorFast):
    resample = ...
    image_mean = ...
    image_std = ...
    size = ...
    default_to_square = ...
    crop_size = ...
    do_resize = ...
    do_center_crop = ...
    do_rescale = ...
    do_normalize = ...
    do_reduce_labels = ...
    valid_kwargs = DPTFastImageProcessorKwargs
    do_pad = ...
    rescale_factor = ...
    ensure_multiple_of = ...
    keep_aspect_ratio = ...
    def __init__(self, **kwargs: Unpack[DPTFastImageProcessorKwargs]) -> None: ...
    def reduce_label(self, labels: list[torch.Tensor]): ...
    @auto_docstring
    def preprocess(
        self,
        images: ImageInput,
        segmentation_maps: Optional[ImageInput] = ...,
        **kwargs: Unpack[DPTFastImageProcessorKwargs],
    ) -> BatchFeature: ...
    def post_process_semantic_segmentation(self, outputs, target_sizes: Optional[list[tuple]] = ...): ...
    def resize(
        self,
        image: torch.Tensor,
        size: SizeDict,
        interpolation: F.InterpolationMode = ...,
        antialias: bool = ...,
        ensure_multiple_of: Optional[int] = ...,
        keep_aspect_ratio: bool = ...,
    ) -> torch.Tensor: ...
    def pad_image(self, image: torch.Tensor, size_divisor: int = ...) -> torch.Tensor: ...
    def post_process_depth_estimation(
        self, outputs: DepthEstimatorOutput, target_sizes: Union[None, TensorType, list[tuple[int, int]]] = ...
    ) -> list[dict[str, TensorType]]: ...

__all__ = ["DPTImageProcessorFast"]
