from collections.abc import Iterable

import torch
from torchvision.transforms import functional as F
from torchvision.transforms.v2 import functional as F
from transformers.image_processing_base import BatchFeature

from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs
from ...image_utils import ImageInput, SizeDict
from ...modeling_outputs import DepthEstimatorOutput
from ...processing_utils import Unpack
from ...utils import TensorType, is_torch_available, is_torchvision_v2_available

if is_torch_available(): ...
if is_torchvision_v2_available(): ...

class DPTFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    ensure_multiple_of: int | None
    size_divisor: int | None
    do_pad: bool | None
    keep_aspect_ratio: bool | None
    do_reduce_labels: bool | None

def get_resize_output_image_size(
    input_image: torch.Tensor, output_size: int | Iterable[int], keep_aspect_ratio: bool, multiple: int
) -> SizeDict: ...

class DPTImageProcessorFast(BaseImageProcessorFast):
    resample = ...
    image_mean = ...
    image_std = ...
    size = ...
    default_to_square = ...
    crop_size = ...
    do_resize = ...
    do_center_crop = ...
    do_rescale = ...
    do_normalize = ...
    do_reduce_labels = ...
    valid_kwargs = DPTFastImageProcessorKwargs
    do_pad = ...
    rescale_factor = ...
    ensure_multiple_of = ...
    keep_aspect_ratio = ...
    def __init__(self, **kwargs: Unpack[DPTFastImageProcessorKwargs]) -> None: ...
    def reduce_label(self, labels: list[torch.Tensor]):  # -> Tensor:
        ...
    def preprocess(
        self,
        images: ImageInput,
        segmentation_maps: ImageInput | None = ...,
        **kwargs: Unpack[DPTFastImageProcessorKwargs],
    ) -> BatchFeature: ...
    def post_process_semantic_segmentation(self, outputs, target_sizes: list[tuple] | None = ...):  # -> list[Any]:

        ...
    def resize(
        self,
        image: torch.Tensor,
        size: SizeDict,
        interpolation: F.InterpolationMode = ...,
        antialias: bool = ...,
        ensure_multiple_of: int | None = ...,
        keep_aspect_ratio: bool = ...,
    ) -> torch.Tensor: ...
    def pad_image(self, image: torch.Tensor, size_divisor: int = ...) -> torch.Tensor: ...
    def post_process_depth_estimation(
        self,
        outputs: DepthEstimatorOutput,
        target_sizes: TensorType | list[tuple[int, int]] | None = ...,
    ) -> list[dict[str, TensorType]]: ...

__all__ = ["DPTImageProcessorFast"]
