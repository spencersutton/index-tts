"""
This type stub file was generated by pyright.
"""

import numpy as np
import torch
from typing import Optional, Union
from ... import is_torch_available, is_vision_available
from ...image_processing_utils import BaseImageProcessor, BatchFeature
from ...image_utils import ChannelDimension, ImageInput, PILImageResampling
from ...utils import TensorType
from PIL import Image
from .modeling_efficientloftr import KeypointMatchingOutput

if is_torch_available(): ...
if is_vision_available(): ...
logger = ...

def is_grayscale(image: np.ndarray, input_data_format: Optional[Union[str, ChannelDimension]] = ...): ...
def convert_to_grayscale(
    image: ImageInput, input_data_format: Optional[Union[str, ChannelDimension]] = ...
) -> ImageInput: ...
def validate_and_format_image_pairs(images: ImageInput): ...

class EfficientLoFTRImageProcessor(BaseImageProcessor):
    model_input_names = ...
    def __init__(
        self,
        do_resize: bool = ...,
        size: Optional[dict[str, int]] = ...,
        resample: PILImageResampling = ...,
        do_rescale: bool = ...,
        rescale_factor: float = ...,
        do_grayscale: bool = ...,
        **kwargs,
    ) -> None: ...
    def resize(
        self,
        image: np.ndarray,
        size: dict[str, int],
        data_format: Optional[Union[str, ChannelDimension]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        **kwargs,
    ): ...
    def preprocess(
        self,
        images,
        do_resize: Optional[bool] = ...,
        size: Optional[dict[str, int]] = ...,
        resample: PILImageResampling = ...,
        do_rescale: Optional[bool] = ...,
        rescale_factor: Optional[float] = ...,
        do_grayscale: Optional[bool] = ...,
        return_tensors: Optional[Union[str, TensorType]] = ...,
        data_format: ChannelDimension = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        **kwargs,
    ) -> BatchFeature: ...
    def post_process_keypoint_matching(
        self, outputs: KeypointMatchingOutput, target_sizes: Union[TensorType, list[tuple]], threshold: float = ...
    ) -> list[dict[str, torch.Tensor]]: ...
    def visualize_keypoint_matching(
        self, images: ImageInput, keypoint_matching_output: list[dict[str, torch.Tensor]]
    ) -> list[Image.Image]: ...

__all__ = ["EfficientLoFTRImageProcessor"]
