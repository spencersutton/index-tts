"""
This type stub file was generated by pyright.
"""

from typing import Optional, Union

from ...processing_utils import ProcessorMixin

"""
Processor class for EVOLLA.
"""
PROTEIN_VALID_KEYS = ...

class EvollaProcessor(ProcessorMixin):
    r"""
    Constructs a EVOLLA processor which wraps a LLama tokenizer and SaProt tokenizer (EsmTokenizer) into a single processor.

    [`EvollaProcessor`] offers all the functionalities of [`EsmTokenizer`] and [`LlamaTokenizerFast`]. See the
    docstring of [`~EvollaProcessor.__call__`] and [`~EvollaProcessor.decode`] for more information.

    Args:
        protein_tokenizer (`EsmTokenizer`):
            An instance of [`EsmTokenizer`]. The protein tokenizer is a required input.
        tokenizer (`LlamaTokenizerFast`, *optional*):
            An instance of [`LlamaTokenizerFast`]. The tokenizer is a required input.
        protein_max_length (`int`, *optional*, defaults to 1024):
            The maximum length of the sequence to be generated.
        text_max_length (`int`, *optional*, defaults to 512):
            The maximum length of the text to be generated.
    """

    attributes = ...
    valid_kwargs = ...
    protein_tokenizer_class = ...
    tokenizer_class = ...
    protein_tokenizer_dir_name = ...
    def __init__(
        self, protein_tokenizer, tokenizer=..., protein_max_length=..., text_max_length=..., **kwargs
    ) -> None: ...
    def process_proteins(self, proteins, protein_max_length=...): ...
    def process_text(self, texts, text_max_length: int = ...): ...
    def __call__(
        self,
        proteins: list[dict] | dict | None = ...,
        messages_list: list[list[dict]] | list[dict] | None = ...,
        protein_max_length: int | None = ...,
        text_max_length: int | None = ...,
        **kwargs,
    ):  # -> BatchFeature:
        r"""This method takes batched or non-batched proteins and messages_list and converts them into format that can be used by
        the model.

        Args:
            proteins (`Union[List[dict], dict]`):
                A list of dictionaries or a single dictionary containing the following keys:
                    - `"aa_seq"` (`str`) -- The amino acid sequence of the protein.
                    - `"foldseek"` (`str`) -- The foldseek string of the protein.
            messages_list (`Union[List[List[dict]], List[dict]]`):
                A list of lists of dictionaries or a list of dictionaries containing the following keys:
                    - `"role"` (`str`) -- The role of the message.
                    - `"content"` (`str`) -- The content of the message.
            protein_max_length (`int`, *optional*, defaults to 1024):
                The maximum length of the sequence to be generated.
            text_max_length (`int`, *optional*, defaults to 512):
                The maximum length of the text.

        Return:
            a dict with following keys:
                - `protein_input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) -- The input IDs for the protein sequence.
                - `protein_attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`) -- The attention mask for the protein sequence.
                - `text_input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) -- The input IDs for the text sequence.
                - `text_attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`) -- The attention mask for the text sequence.
        """
        ...

    def batch_decode(self, *args, **kwargs): ...
    def decode(self, *args, **kwargs): ...
    def protein_batch_decode(self, *args, **kwargs): ...
    def protein_decode(self, *args, **kwargs): ...
    def save_pretrained(self, save_directory, **kwargs):  # -> list[Any] | list[str]:
        ...
    @classmethod
    def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):  # -> EvollaProcessor:
        ...

__all__ = ["EvollaProcessor"]
