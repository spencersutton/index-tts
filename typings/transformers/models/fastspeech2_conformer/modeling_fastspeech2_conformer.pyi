"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import nn
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput, auto_docstring
from .configuration_fastspeech2_conformer import (
    FastSpeech2ConformerConfig,
    FastSpeech2ConformerHifiGanConfig,
    FastSpeech2ConformerWithHifiGanConfig,
)

logger = ...

@dataclass
@auto_docstring(custom_intro=...)
class FastSpeech2ConformerModelOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    spectrogram: Optional[torch.FloatTensor] = ...
    encoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    encoder_attentions: Optional[tuple[torch.FloatTensor]] = ...
    decoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    decoder_attentions: Optional[tuple[torch.FloatTensor]] = ...
    duration_outputs: Optional[torch.LongTensor] = ...
    pitch_outputs: Optional[torch.FloatTensor] = ...
    energy_outputs: Optional[torch.FloatTensor] = ...

@dataclass
@auto_docstring(custom_intro=...)
class FastSpeech2ConformerWithHifiGanOutput(FastSpeech2ConformerModelOutput):
    waveform: Optional[torch.FloatTensor] = ...

def length_regulator(encoded_embeddings, duration_labels, speaking_speed=...): ...

class FastSpeech2ConformerDurationPredictor(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig) -> None: ...
    def forward(self, encoder_hidden_states): ...

class FastSpeech2ConformerBatchNormConvLayer(nn.Module):
    def __init__(self, config, layer_id=...) -> None: ...
    def forward(self, hidden_states): ...

class FastSpeech2ConformerSpeechDecoderPostnet(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor): ...

class FastSpeech2ConformerPredictorLayer(nn.Module):
    def __init__(self, input_channels, num_chans, kernel_size, dropout_rate) -> None: ...
    def forward(self, hidden_states): ...

class FastSpeech2ConformerVariancePredictor(nn.Module):
    def __init__(
        self, config: FastSpeech2ConformerConfig, num_layers=..., num_chans=..., kernel_size=..., dropout_rate=...
    ) -> None: ...
    def forward(self, encoder_hidden_states, padding_masks=...): ...

class FastSpeech2ConformerVarianceEmbedding(nn.Module):
    def __init__(self, in_channels=..., out_channels=..., kernel_size=..., padding=..., dropout_rate=...) -> None: ...
    def forward(self, hidden_states): ...

class FastSpeech2ConformerAttention(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig, module_config) -> None: ...
    def shift_relative_position_tensor(self, pos_tensor): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        pos_emb: Optional[torch.Tensor] = ...,
        output_attentions: Optional[torch.Tensor] = ...,
    ) -> tuple[torch.Tensor, torch.Tensor]: ...

class FastSpeech2ConformerConvolutionModule(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig, module_config) -> None: ...
    def forward(self, hidden_states): ...

class FastSpeech2ConformerEncoderLayer(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig, module_config) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        pos_emb: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[torch.Tensor] = ...,
    ): ...

class FastSpeech2ConformerMultiLayeredConv1d(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig, module_config) -> None: ...
    def forward(self, hidden_states): ...

class FastSpeech2ConformerRelPositionalEncoding(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig, module_config) -> None: ...
    def extend_pos_enc(self, x): ...
    def forward(self, feature_representation): ...

class FastSpeech2ConformerEncoder(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig, module_config, use_encoder_input_layer=...) -> None: ...
    def forward(
        self,
        input_tensor: torch.LongTensor,
        attention_mask: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ): ...

class FastSpeech2ConformerLoss(nn.Module):
    def __init__(self, config: FastSpeech2ConformerConfig) -> None: ...
    def forward(
        self,
        outputs_after_postnet,
        outputs_before_postnet,
        duration_outputs,
        pitch_outputs,
        energy_outputs,
        spectrogram_labels,
        duration_labels,
        pitch_labels,
        energy_labels,
        duration_mask,
        spectrogram_mask,
    ): ...

@auto_docstring
class FastSpeech2ConformerPreTrainedModel(PreTrainedModel):
    config: FastSpeech2ConformerConfig
    base_model_prefix = ...
    main_input_name = ...

@auto_docstring(
    custom_intro="""
    FastSpeech2Conformer Model.
    """
)
class FastSpeech2ConformerModel(FastSpeech2ConformerPreTrainedModel):
    def __init__(self, config: FastSpeech2ConformerConfig) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: torch.LongTensor,
        attention_mask: Optional[torch.LongTensor] = ...,
        spectrogram_labels: Optional[torch.FloatTensor] = ...,
        duration_labels: Optional[torch.LongTensor] = ...,
        pitch_labels: Optional[torch.FloatTensor] = ...,
        energy_labels: Optional[torch.FloatTensor] = ...,
        speaker_ids: Optional[torch.LongTensor] = ...,
        lang_ids: Optional[torch.LongTensor] = ...,
        speaker_embedding: Optional[torch.FloatTensor] = ...,
        return_dict: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
    ) -> Union[tuple, FastSpeech2ConformerModelOutput]: ...

class HifiGanResidualBlock(nn.Module):
    def __init__(self, channels, kernel_size=..., dilation=..., leaky_relu_slope=...) -> None: ...
    def get_padding(self, kernel_size, dilation=...): ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    def forward(self, hidden_states): ...

@auto_docstring(
    custom_intro="""
    HiFi-GAN vocoder.
    """
)
class FastSpeech2ConformerHifiGan(PreTrainedModel):
    config: FastSpeech2ConformerHifiGanConfig
    main_input_name = ...
    def __init__(self, config: FastSpeech2ConformerHifiGanConfig) -> None: ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    @auto_docstring(custom_intro=...)
    def forward(self, spectrogram: torch.FloatTensor) -> torch.FloatTensor: ...

@auto_docstring(custom_intro=...)
class FastSpeech2ConformerWithHifiGan(PreTrainedModel):
    config: FastSpeech2ConformerWithHifiGanConfig
    def __init__(self, config: FastSpeech2ConformerWithHifiGanConfig) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: torch.LongTensor,
        attention_mask: Optional[torch.LongTensor] = ...,
        spectrogram_labels: Optional[torch.FloatTensor] = ...,
        duration_labels: Optional[torch.LongTensor] = ...,
        pitch_labels: Optional[torch.FloatTensor] = ...,
        energy_labels: Optional[torch.FloatTensor] = ...,
        speaker_ids: Optional[torch.LongTensor] = ...,
        lang_ids: Optional[torch.LongTensor] = ...,
        speaker_embedding: Optional[torch.FloatTensor] = ...,
        return_dict: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
    ) -> Union[tuple, FastSpeech2ConformerModelOutput]: ...

__all__ = [
    "FastSpeech2ConformerWithHifiGan",
    "FastSpeech2ConformerHifiGan",
    "FastSpeech2ConformerModel",
    "FastSpeech2ConformerPreTrainedModel",
]
