"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Any, Optional, TypeAlias, Union
from torch import nn
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPooling
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput, auto_docstring
from .configuration_flava import (
    FlavaConfig,
    FlavaImageCodebookConfig,
    FlavaImageConfig,
    FlavaMultimodalConfig,
    FlavaTextConfig,
)

logger = ...
_CHECKPOINT_FOR_CODEBOOK_DOC = ...
LOGIT_SCALE_CLAMP_MIN = ...
LOGIT_SCALE_CLAMP_MAX = ...
FlavaPossibleConfigs: TypeAlias = Union[FlavaTextConfig, FlavaImageConfig, FlavaMultimodalConfig]

@dataclass
@auto_docstring(custom_intro=...)
class FlavaModelOutput(ModelOutput):
    image_embeddings: Optional[torch.FloatTensor] = ...
    image_output: Optional[BaseModelOutputWithPooling] = ...
    text_embeddings: Optional[torch.FloatTensor] = ...
    text_output: Optional[BaseModelOutputWithPooling] = ...
    multimodal_embeddings: Optional[torch.FloatTensor] = ...
    multimodal_output: Optional[BaseModelOutputWithPooling] = ...
    def to_tuple(self) -> tuple[Any]: ...

@dataclass
@auto_docstring(custom_intro=...)
class FlavaLosses(ModelOutput):
    mim: Optional[torch.FloatTensor] = ...
    mlm: Optional[torch.FloatTensor] = ...
    itm: Optional[torch.FloatTensor] = ...
    global_contrastive: Optional[torch.FloatTensor] = ...
    mmm_image: Optional[torch.FloatTensor] = ...
    mmm_text: Optional[torch.FloatTensor] = ...
    def all_none(self) -> bool: ...

@dataclass
@auto_docstring(custom_intro=...)
class FlavaForPreTrainingOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    loss_info: FlavaLosses = ...
    image_embeddings: Optional[torch.FloatTensor] = ...
    image_output: Optional[BaseModelOutputWithPooling] = ...
    text_embeddings: Optional[torch.FloatTensor] = ...
    text_output: Optional[BaseModelOutputWithPooling] = ...
    multimodal_embeddings: Optional[torch.FloatTensor] = ...
    multimodal_output: Optional[BaseModelOutputWithPooling] = ...
    image_masked_embeddings: Optional[torch.FloatTensor] = ...
    image_masked_output: Optional[BaseModelOutputWithPooling] = ...
    text_masked_embeddings: Optional[torch.FloatTensor] = ...
    text_masked_output: Optional[BaseModelOutputWithPooling] = ...
    multimodal_masked_embeddings: Optional[torch.FloatTensor] = ...
    multimodal_masked_output: Optional[BaseModelOutputWithPooling] = ...
    mim_logits: Optional[torch.FloatTensor] = ...
    mlm_logits: Optional[torch.FloatTensor] = ...
    itm_logits: Optional[torch.FloatTensor] = ...
    contrastive_logits_per_image: Optional[torch.FloatTensor] = ...
    contrastive_logits_per_text: Optional[torch.FloatTensor] = ...
    mmm_image_logits: Optional[torch.FloatTensor] = ...
    mmm_text_logits: Optional[torch.FloatTensor] = ...
    def to_tuple(self) -> tuple[Any]: ...

class FlavaImageEmbeddings(nn.Module):
    def __init__(self, config: FlavaImageConfig, use_mask_token: bool = ...) -> None: ...
    def interpolate_pos_encoding(self, embeddings: torch.Tensor, height: int, width: int) -> torch.Tensor: ...
    def forward(
        self,
        pixel_values: torch.Tensor,
        bool_masked_pos: Optional[torch.BoolTensor] = ...,
        interpolate_pos_encoding: bool = ...,
    ) -> torch.Tensor: ...

class PatchEmbeddings(nn.Module):
    def __init__(
        self,
        image_size: int = ...,
        patch_size: Union[int, tuple[int, int]] = ...,
        num_channels: int = ...,
        embed_dim: int = ...,
    ) -> None: ...
    def forward(self, pixel_values: torch.Tensor, interpolate_pos_encoding: bool = ...) -> torch.Tensor: ...

class FlavaTextEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        input_ids: Optional[torch.Tensor] = ...,
        token_type_ids: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.Tensor] = ...,
    ): ...

class FlavaSelfAttention(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ) -> Union[tuple[torch.Tensor, torch.Tensor], tuple[torch.Tensor]]: ...

class FlavaSelfOutput(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class FlavaAttention(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def prune_heads(self, heads: set[int]) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ) -> Union[tuple[torch.Tensor, torch.Tensor], tuple[torch.Tensor]]: ...

class FlavaIntermediate(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class FlavaOutput(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class FlavaLayer(GradientCheckpointingLayer):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ) -> Union[tuple[torch.Tensor, torch.Tensor], tuple[torch.Tensor]]: ...

class FlavaEncoder(nn.Module):
    def __init__(self, config: FlavaConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
        output_hidden_states: bool = ...,
        return_dict: bool = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

class FlavaPooler(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor): ...

@auto_docstring
class FlavaPreTrainedModel(PreTrainedModel):
    config: FlavaConfig
    base_model_prefix = ...
    supports_gradient_checkpointing = ...

@auto_docstring
class FlavaImageModel(FlavaPreTrainedModel):
    config: FlavaImageConfig
    base_model_prefix = ...
    main_input_name = ...
    def __init__(self, config: FlavaImageConfig, add_pooling_layer: bool = ...) -> None: ...
    def get_input_embeddings(self) -> nn.Module: ...
    def set_input_embeddings(self, value: nn.Module): ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Optional[torch.Tensor] = ...,
        bool_masked_pos: Optional[torch.BoolTensor] = ...,
        interpolate_pos_encoding: Optional[bool] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutputWithPooling]: ...

@auto_docstring
class FlavaTextModel(FlavaPreTrainedModel):
    config: FlavaTextConfig
    base_model_prefix = ...
    def __init__(self, config: FlavaTextConfig, add_pooling_layer: bool = ...) -> None: ...
    def get_input_embeddings(self) -> PatchEmbeddings: ...
    def set_input_embeddings(self, value: nn.Module): ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        token_type_ids: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutputWithPooling]: ...

@auto_docstring
class FlavaMultimodalModel(FlavaPreTrainedModel):
    config: FlavaMultimodalConfig
    base_model_prefix = ...
    main_input_name = ...
    def __init__(self, config: FlavaMultimodalConfig, add_pooling_layer=...) -> None: ...
    @auto_docstring
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutputWithPooling]: ...

@auto_docstring
class FlavaModel(FlavaPreTrainedModel):
    config: FlavaConfig
    def __init__(self, config: FlavaConfig) -> None: ...
    @auto_docstring
    def get_text_features(
        self,
        input_ids: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        token_type_ids: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> torch.FloatTensor: ...
    @auto_docstring
    def get_image_features(
        self,
        pixel_values: Optional[torch.Tensor] = ...,
        bool_masked_pos: Optional[torch.BoolTensor] = ...,
        interpolate_pos_encoding: Optional[bool] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> torch.FloatTensor: ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        pixel_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        token_type_ids: Optional[torch.Tensor] = ...,
        bool_masked_pos: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        image_attention_mask: Optional[torch.Tensor] = ...,
        skip_multimodal_encoder: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: bool = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, FlavaOutput]: ...

class FlavaImageCodebookResPath(nn.Module):
    def __init__(self, in_size: int, out_size: int, **kwargs) -> None: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...

class FlavaImageCodebookBlock(nn.Module):
    def __init__(self, in_size: int, out_size: int, num_layers: int, **kwargs) -> None: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...

class FlavaImageCodebookLayerGroup(nn.Module):
    def __init__(self, num_blocks: int, num_layers: int, in_size: int, out_size: int, use_pool: bool = ...) -> None: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...

@auto_docstring(custom_intro=...)
class FlavaImageCodebook(FlavaPreTrainedModel):
    base_model_prefix = ...
    config: FlavaImageCodebookConfig
    main_input_name = ...
    supports_gradient_checkpointing = ...
    def __init__(self, config: FlavaImageCodebookConfig, **kwargs: Any) -> None: ...
    def get_codebook_indices(self, pixel_values: torch.Tensor) -> torch.Tensor: ...
    def get_codebook_probs(self, pixel_values: torch.Tensor) -> torch.Tensor: ...
    def forward(self, pixel_values: torch.FloatTensor) -> torch.Tensor: ...

class FlavaPredictionHeadTransform(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states): ...

class FlavaMaskedPredictionHead(nn.Module):
    def __init__(self, config, weight=...) -> None: ...
    def forward(self, x): ...

class FlavaITMHead(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, x): ...

class FlavaGlobalContrastiveHead(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, image_embeddings, text_embeddings, logit_scale): ...

@auto_docstring(custom_intro=...)
class FlavaForPreTraining(FlavaPreTrainedModel):
    _tied_weights_keys = ...
    def __init__(self, config: FlavaConfig, image_codebook: Optional[nn.Module] = ...) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        input_ids_masked: Optional[torch.LongTensor] = ...,
        pixel_values: Optional[torch.FloatTensor] = ...,
        codebook_pixel_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        token_type_ids: Optional[torch.Tensor] = ...,
        bool_masked_pos: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        image_attention_mask: Optional[torch.Tensor] = ...,
        skip_unmasked_multimodal_encoder: Optional[bool] = ...,
        mlm_labels: Optional[torch.Tensor] = ...,
        mim_labels: Optional[torch.Tensor] = ...,
        itm_labels: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: bool = ...,
        return_dict: Optional[bool] = ...,
        return_loss: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor], FlavaForPreTrainingOutput]: ...

__all__ = [
    "FlavaForPreTraining",
    "FlavaImageCodebook",
    "FlavaImageModel",
    "FlavaModel",
    "FlavaMultimodalModel",
    "FlavaPreTrainedModel",
    "FlavaTextModel",
]
