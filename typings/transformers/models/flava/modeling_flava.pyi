from dataclasses import dataclass
from typing import Any

import torch
from torch import nn

from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPooling
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput
from .configuration_flava import (
    FlavaConfig,
    FlavaImageCodebookConfig,
    FlavaImageConfig,
    FlavaMultimodalConfig,
    FlavaTextConfig,
)

"""PyTorch FLAVA model."""
logger = ...
_CHECKPOINT_FOR_CODEBOOK_DOC = ...
LOGIT_SCALE_CLAMP_MIN = ...
LOGIT_SCALE_CLAMP_MAX = ...
type FlavaPossibleConfigs = FlavaTextConfig | FlavaImageConfig | FlavaMultimodalConfig

@dataclass
class FlavaModelOutput(ModelOutput):
    image_embeddings: torch.FloatTensor | None = ...
    image_output: BaseModelOutputWithPooling | None = ...
    text_embeddings: torch.FloatTensor | None = ...
    text_output: BaseModelOutputWithPooling | None = ...
    multimodal_embeddings: torch.FloatTensor | None = ...
    multimodal_output: BaseModelOutputWithPooling | None = ...
    def to_tuple(self) -> tuple[Any]: ...

@dataclass
class FlavaLosses(ModelOutput):
    mim: torch.FloatTensor | None = ...
    mlm: torch.FloatTensor | None = ...
    itm: torch.FloatTensor | None = ...
    global_contrastive: torch.FloatTensor | None = ...
    mmm_image: torch.FloatTensor | None = ...
    mmm_text: torch.FloatTensor | None = ...
    def all_none(self) -> bool: ...

@dataclass
class FlavaForPreTrainingOutput(ModelOutput):
    loss: torch.FloatTensor | None = ...
    loss_info: FlavaLosses = ...
    image_embeddings: torch.FloatTensor | None = ...
    image_output: BaseModelOutputWithPooling | None = ...
    text_embeddings: torch.FloatTensor | None = ...
    text_output: BaseModelOutputWithPooling | None = ...
    multimodal_embeddings: torch.FloatTensor | None = ...
    multimodal_output: BaseModelOutputWithPooling | None = ...
    image_masked_embeddings: torch.FloatTensor | None = ...
    image_masked_output: BaseModelOutputWithPooling | None = ...
    text_masked_embeddings: torch.FloatTensor | None = ...
    text_masked_output: BaseModelOutputWithPooling | None = ...
    multimodal_masked_embeddings: torch.FloatTensor | None = ...
    multimodal_masked_output: BaseModelOutputWithPooling | None = ...
    mim_logits: torch.FloatTensor | None = ...
    mlm_logits: torch.FloatTensor | None = ...
    itm_logits: torch.FloatTensor | None = ...
    contrastive_logits_per_image: torch.FloatTensor | None = ...
    contrastive_logits_per_text: torch.FloatTensor | None = ...
    mmm_image_logits: torch.FloatTensor | None = ...
    mmm_text_logits: torch.FloatTensor | None = ...
    def to_tuple(self) -> tuple[Any]: ...

class FlavaImageEmbeddings(nn.Module):
    def __init__(self, config: FlavaImageConfig, use_mask_token: bool = ...) -> None: ...
    def interpolate_pos_encoding(self, embeddings: torch.Tensor, height: int, width: int) -> torch.Tensor: ...
    def forward(
        self,
        pixel_values: torch.Tensor,
        bool_masked_pos: torch.BoolTensor | None = ...,
        interpolate_pos_encoding: bool = ...,
    ) -> torch.Tensor: ...

class PatchEmbeddings(nn.Module):
    def __init__(
        self,
        image_size: int = ...,
        patch_size: int | tuple[int, int] = ...,
        num_channels: int = ...,
        embed_dim: int = ...,
    ) -> None: ...
    def forward(self, pixel_values: torch.Tensor, interpolate_pos_encoding: bool = ...) -> torch.Tensor: ...

class FlavaTextEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        input_ids: torch.Tensor | None = ...,
        token_type_ids: torch.Tensor | None = ...,
        position_ids: torch.Tensor | None = ...,
    ):  # -> Any:
        ...

class FlavaSelfAttention(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool = ...,
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class FlavaSelfOutput(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class FlavaAttention(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def prune_heads(self, heads: set[int]) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool = ...,
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class FlavaIntermediate(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class FlavaOutput(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class FlavaLayer(GradientCheckpointingLayer):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool = ...,
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class FlavaEncoder(nn.Module):
    def __init__(self, config: FlavaConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool = ...,
        output_hidden_states: bool = ...,
        return_dict: bool = ...,
    ) -> tuple | BaseModelOutput: ...

class FlavaPooler(nn.Module):
    def __init__(self, config: FlavaPossibleConfigs) -> None: ...
    def forward(self, hidden_states: torch.Tensor):  # -> Any:
        ...

class FlavaPreTrainedModel(PreTrainedModel):
    config: FlavaConfig
    base_model_prefix = ...
    supports_gradient_checkpointing = ...

class FlavaImageModel(FlavaPreTrainedModel):
    config: FlavaImageConfig
    base_model_prefix = ...
    main_input_name = ...
    def __init__(self, config: FlavaImageConfig, add_pooling_layer: bool = ...) -> None: ...
    def get_input_embeddings(self) -> nn.Module: ...
    def set_input_embeddings(self, value: nn.Module):  # -> None:
        ...
    def forward(
        self,
        pixel_values: torch.Tensor | None = ...,
        bool_masked_pos: torch.BoolTensor | None = ...,
        interpolate_pos_encoding: bool | None = ...,
        attention_mask: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | BaseModelOutputWithPooling: ...

class FlavaTextModel(FlavaPreTrainedModel):
    config: FlavaTextConfig
    base_model_prefix = ...
    def __init__(self, config: FlavaTextConfig, add_pooling_layer: bool = ...) -> None: ...
    def get_input_embeddings(self) -> PatchEmbeddings: ...
    def set_input_embeddings(self, value: nn.Module):  # -> None:
        ...
    def forward(
        self,
        input_ids: torch.Tensor | None = ...,
        attention_mask: torch.Tensor | None = ...,
        token_type_ids: torch.Tensor | None = ...,
        position_ids: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | BaseModelOutputWithPooling: ...

class FlavaMultimodalModel(FlavaPreTrainedModel):
    config: FlavaMultimodalConfig
    base_model_prefix = ...
    main_input_name = ...
    def __init__(self, config: FlavaMultimodalConfig, add_pooling_layer=...) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | BaseModelOutputWithPooling: ...

class FlavaModel(FlavaPreTrainedModel):
    config: FlavaConfig
    def __init__(self, config: FlavaConfig) -> None: ...
    def get_text_features(
        self,
        input_ids: torch.Tensor | None = ...,
        attention_mask: torch.Tensor | None = ...,
        token_type_ids: torch.Tensor | None = ...,
        position_ids: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> torch.FloatTensor: ...
    def get_image_features(
        self,
        pixel_values: torch.Tensor | None = ...,
        bool_masked_pos: torch.BoolTensor | None = ...,
        interpolate_pos_encoding: bool | None = ...,
        attention_mask: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> torch.FloatTensor: ...
    def forward(
        self,
        input_ids: torch.LongTensor | None = ...,
        pixel_values: torch.FloatTensor | None = ...,
        attention_mask: torch.Tensor | None = ...,
        token_type_ids: torch.Tensor | None = ...,
        bool_masked_pos: torch.Tensor | None = ...,
        position_ids: torch.LongTensor | None = ...,
        image_attention_mask: torch.Tensor | None = ...,
        skip_multimodal_encoder: bool | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool = ...,
        return_dict: bool | None = ...,
    ) -> tuple | FlavaOutput: ...

class FlavaImageCodebookResPath(nn.Module):
    def __init__(self, in_size: int, out_size: int, **kwargs) -> None: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...

class FlavaImageCodebookBlock(nn.Module):
    def __init__(self, in_size: int, out_size: int, num_layers: int, **kwargs) -> None: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...

class FlavaImageCodebookLayerGroup(nn.Module):
    def __init__(self, num_blocks: int, num_layers: int, in_size: int, out_size: int, use_pool: bool = ...) -> None: ...
    def forward(self, x: torch.Tensor) -> torch.Tensor: ...

class FlavaImageCodebook(FlavaPreTrainedModel):
    base_model_prefix = ...
    config: FlavaImageCodebookConfig
    main_input_name = ...
    supports_gradient_checkpointing = ...
    def __init__(self, config: FlavaImageCodebookConfig, **kwargs: Any) -> None: ...
    def get_codebook_indices(self, pixel_values: torch.Tensor) -> torch.Tensor: ...
    def get_codebook_probs(self, pixel_values: torch.Tensor) -> torch.Tensor: ...
    def forward(self, pixel_values: torch.FloatTensor) -> torch.Tensor: ...

class FlavaPredictionHeadTransform(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states):  # -> Any:
        ...

class FlavaMaskedPredictionHead(nn.Module):
    def __init__(self, config, weight=...) -> None: ...
    def forward(self, x):  # -> Any:
        ...

class FlavaITMHead(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, x):  # -> Any:
        ...

class FlavaGlobalContrastiveHead(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, image_embeddings, text_embeddings, logit_scale):  # -> tuple[Tensor, Tensor, Tensor | Any]:
        ...

class FlavaForPreTraining(FlavaPreTrainedModel):
    _tied_weights_keys = ...
    def __init__(self, config: FlavaConfig, image_codebook: nn.Module | None = ...) -> None: ...
    def forward(
        self,
        input_ids: torch.LongTensor | None = ...,
        input_ids_masked: torch.LongTensor | None = ...,
        pixel_values: torch.FloatTensor | None = ...,
        codebook_pixel_values: torch.FloatTensor | None = ...,
        attention_mask: torch.Tensor | None = ...,
        token_type_ids: torch.Tensor | None = ...,
        bool_masked_pos: torch.Tensor | None = ...,
        position_ids: torch.LongTensor | None = ...,
        image_attention_mask: torch.Tensor | None = ...,
        skip_unmasked_multimodal_encoder: bool | None = ...,
        mlm_labels: torch.Tensor | None = ...,
        mim_labels: torch.Tensor | None = ...,
        itm_labels: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool = ...,
        return_dict: bool | None = ...,
        return_loss: bool | None = ...,
    ) -> tuple[torch.Tensor] | FlavaForPreTrainingOutput: ...

__all__ = [
    "FlavaForPreTraining",
    "FlavaImageCodebook",
    "FlavaImageModel",
    "FlavaModel",
    "FlavaMultimodalModel",
    "FlavaPreTrainedModel",
    "FlavaTextModel",
]
