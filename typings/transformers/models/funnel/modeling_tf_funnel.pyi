"""
This type stub file was generated by pyright.
"""

import numpy as np
import tensorflow as tf
from dataclasses import dataclass
from ...modeling_tf_outputs import (
    TFBaseModelOutput,
    TFMaskedLMOutput,
    TFMultipleChoiceModelOutput,
    TFQuestionAnsweringModelOutput,
    TFSequenceClassifierOutput,
    TFTokenClassifierOutput,
)
from ...modeling_tf_utils import (
    TFMaskedLanguageModelingLoss,
    TFModelInputType,
    TFMultipleChoiceLoss,
    TFPreTrainedModel,
    TFQuestionAnsweringLoss,
    TFSequenceClassificationLoss,
    TFTokenClassificationLoss,
    keras,
    keras_serializable,
    unpack_inputs,
)
from ...utils import (
    ModelOutput,
    add_code_sample_docstrings,
    add_start_docstrings,
    add_start_docstrings_to_model_forward,
    replace_return_docstrings,
)
from .configuration_funnel import FunnelConfig

logger = ...
_CONFIG_FOR_DOC = ...
INF = ...

class TFFunnelEmbeddings(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def build(self, input_shape=...): ...
    def call(self, input_ids=..., inputs_embeds=..., training=...): ...

class TFFunnelAttentionStructure:
    cls_token_type_id: int = ...
    def __init__(self, config) -> None: ...
    def init_attention_inputs(self, inputs_embeds, attention_mask=..., token_type_ids=..., training=...): ...
    def token_type_ids_to_mat(self, token_type_ids): ...
    def get_position_embeds(self, seq_len, training=...): ...
    def stride_pool_pos(self, pos_id, block_index): ...
    def relative_pos(self, pos, stride, pooled_pos=..., shift=...): ...
    def stride_pool(self, tensor, axis): ...
    def pool_tensor(self, tensor, mode=..., stride=...): ...
    def pre_attention_pooling(self, output, attention_inputs): ...
    def post_attention_pooling(self, attention_inputs): ...

class TFFunnelRelMultiheadAttention(keras.layers.Layer):
    def __init__(self, config, block_index, **kwargs) -> None: ...
    def build(self, input_shape=...): ...
    def relative_positional_attention(self, position_embeds, q_head, context_len, cls_mask=...): ...
    def relative_token_type_attention(self, token_type_mat, q_head, cls_mask=...): ...
    def call(self, query, key, value, attention_inputs, output_attentions=..., training=...): ...

class TFFunnelPositionwiseFFN(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden, training=...): ...
    def build(self, input_shape=...): ...

class TFFunnelLayer(keras.layers.Layer):
    def __init__(self, config, block_index, **kwargs) -> None: ...
    def call(self, query, key, value, attention_inputs, output_attentions=..., training=...): ...
    def build(self, input_shape=...): ...

class TFFunnelEncoder(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(
        self,
        inputs_embeds,
        attention_mask=...,
        token_type_ids=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
        training=...,
    ): ...
    def build(self, input_shape=...): ...

def upsample(x, stride, target_len, separate_cls=..., truncate_seq=...): ...

class TFFunnelDecoder(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(
        self,
        final_hidden,
        first_block_hidden,
        attention_mask=...,
        token_type_ids=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
        training=...,
    ): ...
    def build(self, input_shape=...): ...

@keras_serializable
class TFFunnelBaseLayer(keras.layers.Layer):
    config_class = FunnelConfig
    def __init__(self, config, **kwargs) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    @unpack_inputs
    def call(
        self,
        input_ids=...,
        attention_mask=...,
        token_type_ids=...,
        inputs_embeds=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
        training=...,
    ): ...
    def build(self, input_shape=...): ...

@keras_serializable
class TFFunnelMainLayer(keras.layers.Layer):
    config_class = FunnelConfig
    def __init__(self, config, **kwargs) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    @unpack_inputs
    def call(
        self,
        input_ids=...,
        attention_mask=...,
        token_type_ids=...,
        inputs_embeds=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
        training=...,
    ): ...
    def build(self, input_shape=...): ...

class TFFunnelDiscriminatorPredictions(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, discriminator_hidden_states): ...
    def build(self, input_shape=...): ...

class TFFunnelMaskedLMHead(keras.layers.Layer):
    def __init__(self, config, input_embeddings, **kwargs) -> None: ...
    def build(self, input_shape): ...
    def get_output_embeddings(self): ...
    def set_output_embeddings(self, value): ...
    def get_bias(self): ...
    def set_bias(self, value): ...
    def call(self, hidden_states, training=...): ...

class TFFunnelClassificationHead(keras.layers.Layer):
    def __init__(self, config, n_labels, **kwargs) -> None: ...
    def call(self, hidden, training=...): ...
    def build(self, input_shape=...): ...

class TFFunnelPreTrainedModel(TFPreTrainedModel):
    config_class = FunnelConfig
    base_model_prefix = ...
    @property
    def dummy_inputs(self): ...

@dataclass
class TFFunnelForPreTrainingOutput(ModelOutput):
    logits: tf.Tensor | None = ...
    hidden_states: tuple[tf.Tensor] | None = ...
    attentions: tuple[tf.Tensor] | None = ...

FUNNEL_START_DOCSTRING = ...
FUNNEL_INPUTS_DOCSTRING = ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelBaseModel(TFFunnelPreTrainedModel):
    def __init__(self, config: FunnelConfig, *inputs, **kwargs) -> None: ...
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @add_code_sample_docstrings(
        checkpoint="funnel-transformer/small-base", output_type=TFBaseModelOutput, config_class=_CONFIG_FOR_DOC
    )
    @unpack_inputs
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFBaseModelOutput: ...
    def serving_output(self, output): ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelModel(TFFunnelPreTrainedModel):
    def __init__(self, config: FunnelConfig, *inputs, **kwargs) -> None: ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @add_code_sample_docstrings(
        checkpoint="funnel-transformer/small", output_type=TFBaseModelOutput, config_class=_CONFIG_FOR_DOC
    )
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFBaseModelOutput: ...
    def serving_output(self, output): ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelForPreTraining(TFFunnelPreTrainedModel):
    def __init__(self, config: FunnelConfig, **kwargs) -> None: ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @replace_return_docstrings(output_type=TFFunnelForPreTrainingOutput, config_class=_CONFIG_FOR_DOC)
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool = ...,
        **kwargs,
    ) -> tuple[tf.Tensor] | TFFunnelForPreTrainingOutput: ...
    def serving_output(self, output): ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelForMaskedLM(TFFunnelPreTrainedModel, TFMaskedLanguageModelingLoss):
    def __init__(self, config: FunnelConfig, *inputs, **kwargs) -> None: ...
    def get_lm_head(self) -> TFFunnelMaskedLMHead: ...
    def get_prefix_bias_name(self) -> str: ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @add_code_sample_docstrings(
        checkpoint="funnel-transformer/small", output_type=TFMaskedLMOutput, config_class=_CONFIG_FOR_DOC
    )
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        labels: np.ndarray | tf.Tensor | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFMaskedLMOutput: ...
    def serving_output(self, output: TFMaskedLMOutput) -> TFMaskedLMOutput: ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelForSequenceClassification(TFFunnelPreTrainedModel, TFSequenceClassificationLoss):
    def __init__(self, config: FunnelConfig, *inputs, **kwargs) -> None: ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @add_code_sample_docstrings(
        checkpoint="funnel-transformer/small-base", output_type=TFSequenceClassifierOutput, config_class=_CONFIG_FOR_DOC
    )
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        labels: np.ndarray | tf.Tensor | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFSequenceClassifierOutput: ...
    def serving_output(self, output: TFSequenceClassifierOutput) -> TFSequenceClassifierOutput: ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelForMultipleChoice(TFFunnelPreTrainedModel, TFMultipleChoiceLoss):
    def __init__(self, config: FunnelConfig, *inputs, **kwargs) -> None: ...
    @property
    def dummy_inputs(self): ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, num_choices, sequence_length"))
    @add_code_sample_docstrings(
        checkpoint="funnel-transformer/small-base",
        output_type=TFMultipleChoiceModelOutput,
        config_class=_CONFIG_FOR_DOC,
    )
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        labels: np.ndarray | tf.Tensor | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFMultipleChoiceModelOutput: ...
    def serving_output(self, output: TFMultipleChoiceModelOutput) -> TFMultipleChoiceModelOutput: ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelForTokenClassification(TFFunnelPreTrainedModel, TFTokenClassificationLoss):
    def __init__(self, config: FunnelConfig, *inputs, **kwargs) -> None: ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @add_code_sample_docstrings(
        checkpoint="funnel-transformer/small", output_type=TFTokenClassifierOutput, config_class=_CONFIG_FOR_DOC
    )
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        labels: np.ndarray | tf.Tensor | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFTokenClassifierOutput: ...
    def serving_output(self, output: TFTokenClassifierOutput) -> TFTokenClassifierOutput: ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., FUNNEL_START_DOCSTRING)
class TFFunnelForQuestionAnswering(TFFunnelPreTrainedModel, TFQuestionAnsweringLoss):
    def __init__(self, config: FunnelConfig, *inputs, **kwargs) -> None: ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(FUNNEL_INPUTS_DOCSTRING.format("batch_size, sequence_length"))
    @add_code_sample_docstrings(
        checkpoint="funnel-transformer/small", output_type=TFQuestionAnsweringModelOutput, config_class=_CONFIG_FOR_DOC
    )
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        start_positions: np.ndarray | tf.Tensor | None = ...,
        end_positions: np.ndarray | tf.Tensor | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFQuestionAnsweringModelOutput: ...
    def serving_output(self, output: TFQuestionAnsweringModelOutput) -> TFQuestionAnsweringModelOutput: ...
    def build(self, input_shape=...): ...

__all__ = [
    "TFFunnelBaseModel",
    "TFFunnelForMaskedLM",
    "TFFunnelForMultipleChoice",
    "TFFunnelForPreTraining",
    "TFFunnelForQuestionAnswering",
    "TFFunnelForSequenceClassification",
    "TFFunnelForTokenClassification",
    "TFFunnelModel",
    "TFFunnelPreTrainedModel",
]
