"""
This type stub file was generated by pyright.
"""

import numpy as np
import torch
from typing import Optional, Union
from ...image_processing_utils import BaseImageProcessor, BatchFeature
from ...image_utils import ChannelDimension, ImageInput, PILImageResampling
from ...utils import TensorType, filter_out_non_signature_kwargs, is_torch_available

if is_torch_available(): ...
logger = ...

def make_list_of_list_of_images(
    images: Union[list[list[ImageInput]], list[ImageInput], ImageInput],
) -> list[list[ImageInput]]: ...

class FuyuBatchFeature(BatchFeature):
    def convert_to_tensors(self, tensor_type: Optional[Union[str, TensorType]] = ...): ...
    def to(self, *args, **kwargs) -> BatchFeature: ...

class FuyuImageProcessor(BaseImageProcessor):
    model_input_names = ...
    def __init__(
        self,
        do_resize: bool = ...,
        size: Optional[dict[str, int]] = ...,
        resample: PILImageResampling = ...,
        do_pad: bool = ...,
        padding_value: float = ...,
        padding_mode: str = ...,
        do_normalize: bool = ...,
        image_mean: Union[float, list[float]] = ...,
        image_std: Union[float, list[float]] = ...,
        do_rescale: bool = ...,
        rescale_factor: float = ...,
        patch_size: Optional[dict[str, int]] = ...,
        **kwargs,
    ) -> None: ...
    def resize(
        self,
        image: np.ndarray,
        size: dict[str, int],
        resample: PILImageResampling = ...,
        data_format: Optional[Union[str, ChannelDimension]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        **kwargs,
    ) -> np.ndarray: ...
    def pad_image(
        self,
        image: np.ndarray,
        size: dict[str, int],
        mode: str = ...,
        constant_values: float = ...,
        data_format: Optional[Union[str, ChannelDimension]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
    ) -> np.ndarray: ...
    @filter_out_non_signature_kwargs()
    def preprocess(
        self,
        images,
        do_resize: Optional[bool] = ...,
        size: Optional[dict[str, int]] = ...,
        resample: Optional[PILImageResampling] = ...,
        do_pad: Optional[bool] = ...,
        padding_value: Optional[float] = ...,
        padding_mode: Optional[str] = ...,
        do_normalize: Optional[bool] = ...,
        image_mean: Optional[float] = ...,
        image_std: Optional[float] = ...,
        do_rescale: Optional[bool] = ...,
        rescale_factor: Optional[float] = ...,
        patch_size: Optional[dict[str, int]] = ...,
        data_format: Optional[Union[str, ChannelDimension]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        return_tensors: Optional[TensorType] = ...,
    ): ...
    def get_num_patches(
        self, image_height: int, image_width: int, patch_size: Optional[dict[str, int]] = ...
    ) -> int: ...
    def patchify_image(self, image: torch.Tensor, patch_size: Optional[dict[str, int]] = ...) -> torch.Tensor: ...
    def preprocess_with_tokenizer_info(
        self,
        image_input: torch.Tensor,
        image_present: torch.Tensor,
        image_unpadded_h: torch.Tensor,
        image_unpadded_w: torch.Tensor,
        image_placeholder_id: int,
        image_newline_id: int,
        variable_sized: bool,
        patch_size: Optional[dict[str, int]] = ...,
    ) -> FuyuBatchFeature: ...

__all__ = ["FuyuImageProcessor"]
