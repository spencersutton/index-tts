import torch

from ...image_utils import ImageInput
from ...processing_utils import ProcessingKwargs, ProcessorMixin, Unpack
from ...tokenization_utils_base import PreTokenizedInput, TextInput
from ...utils import is_torch_available
from ...utils.import_utils import requires
from .image_processing_fuyu import FuyuBatchFeature

"""
Image/Text processor class for GIT
"""
if is_torch_available(): ...
logger = ...
if is_torch_available(): ...
TEXT_REPR_BBOX_OPEN = ...
TEXT_REPR_BBOX_CLOSE = ...
TEXT_REPR_POINT_OPEN = ...
TEXT_REPR_POINT_CLOSE = ...
TOKEN_BBOX_OPEN_STRING = ...
TOKEN_BBOX_CLOSE_STRING = ...
TOKEN_POINT_OPEN_STRING = ...
TOKEN_POINT_CLOSE_STRING = ...
BEGINNING_OF_ANSWER_STRING = ...

class FuyuProcessorKwargs(ProcessingKwargs, total=False):
    _defaults = ...

def full_unpacked_stream_to_tensor(
    all_bi_tokens_to_place: list[int],
    full_unpacked_stream: list[torch.Tensor],
    fill_value: int,
    batch_size: int,
    new_seq_len: int,
    offset: int,
) -> torch.Tensor: ...
def construct_full_unpacked_stream(
    num_real_text_tokens: list[list[int]] | torch.Tensor,
    input_stream: torch.Tensor,
    image_tokens: list[list[torch.Tensor]],
    batch_size: int,
    num_sub_sequences: int,
) -> list[torch.Tensor]: ...
def original_to_transformed_h_coords(original_coords, scale_h): ...
def original_to_transformed_w_coords(original_coords, scale_w): ...
def scale_point_to_transformed_image(x: float, y: float, scale_factor: float) -> list[int]: ...
def scale_bbox_to_transformed_image(
    top: float, left: float, bottom: float, right: float, scale_factor: float
) -> list[int]: ...

@requires(backends=("vision",))
class FuyuProcessor(ProcessorMixin):
    attributes = ...
    image_processor_class = ...
    tokenizer_class = ...
    def __init__(self, image_processor, tokenizer, **kwargs) -> None: ...
    def get_sample_encoding(
        self,
        prompts,
        scale_factors,
        image_unpadded_heights,
        image_unpadded_widths,
        image_placeholder_id,
        image_newline_id,
        tensor_batch_images,
    ):  # -> dict[str, Tensor]:
        ...
    def __call__(
        self,
        images: ImageInput = ...,
        text: str | list[str] | TextInput | PreTokenizedInput | None = ...,
        audio=...,
        videos=...,
        **kwargs: Unpack[FuyuProcessorKwargs],
    ) -> FuyuBatchFeature: ...
    def post_process_box_coordinates(self, outputs, target_sizes=...):  # -> list[Any]:

        ...
    def post_process_image_text_to_text(self, generated_outputs, skip_special_tokens=..., **kwargs): ...
    def batch_decode(self, *args, **kwargs): ...
    def decode(self, *args, **kwargs): ...

__all__ = ["FuyuProcessor"]
