"""
This type stub file was generated by pyright.
"""

import os
from typing import Optional, Union
from ...modeling_tf_utils import keras
from ...utils.import_utils import is_keras_nlp_available, requires
from .tokenization_gpt2 import GPT2Tokenizer

if is_keras_nlp_available(): ...

@requires(backends=("keras_nlp",))
class TFGPT2Tokenizer(keras.layers.Layer):
    """
    This is an in-graph tokenizer for GPT2. It should be initialized similarly to other tokenizers, using the
    `from_pretrained()` method. It can also be initialized with the `from_tokenizer()` method, which imports settings
    from an existing standard tokenizer object.

    In-graph tokenizers, unlike other Hugging Face tokenizers, are actually Keras layers and are designed to be run
    when the model is called, rather than during preprocessing. As a result, they have somewhat more limited options
    than standard tokenizer classes. They are most useful when you want to create an end-to-end model that goes
    straight from `tf.string` inputs to outputs.

    Args:
        vocab (dict[str, int]): Vocabulary dict for Byte Pair Tokenizer
        merges (list[str]): Merges list for Byte Pair Tokenizer
    """
    def __init__(
        self,
        vocab: dict[str, int],
        merges: list[str],
        max_length: Optional[int] = ...,
        pad_token_id: Optional[int] = ...,
    ) -> None: ...
    @classmethod
    def from_tokenizer(cls, tokenizer: GPT2Tokenizer, *args, **kwargs):  # -> Self:
        """Creates TFGPT2Tokenizer from GPT2Tokenizer

        Args:
            tokenizer (GPT2Tokenizer)

        Examples:

        ```python
        from transformers import AutoTokenizer, TFGPT2Tokenizer

        tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2")
        tf_tokenizer = TFGPT2Tokenizer.from_tokenizer(tokenizer)
        ```
        """
        ...

    @classmethod
    def from_pretrained(
        cls, pretrained_model_name_or_path: Union[str, os.PathLike], *init_inputs, **kwargs
    ):  # -> Self:
        """Creates TFGPT2Tokenizer from pretrained GPT2Tokenizer

        Args:
            pretrained_model_name_or_path (Union[str, os.PathLike]): Path to pretrained model

        Examples:

        ```python
        from transformers import TFGPT2Tokenizer

        tf_tokenizer = TFGPT2Tokenizer.from_pretrained("openai-community/gpt2")
        ```
        """
        ...

    @classmethod
    def from_config(cls, config):  # -> Self:
        """Creates TFGPT2Tokenizer from configurations

        Args:
            config (Dict): Dictionary with keys such as stated in `get_config`.
        """
        ...

    def get_config(self):  # -> dict[str, dict[str, int] | list[str] | int | None]:
        ...
    def call(self, x, max_length: Optional[int] = ...):  # -> dict[str, Any]:
        ...

__all__ = ["TFGPT2Tokenizer"]
