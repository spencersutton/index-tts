"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import Tensor, nn
from ...file_utils import ModelOutput, is_timm_available
from ...integrations import use_kernel_forward_from_hub
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_grounding_dino import GroundingDinoConfig

if is_timm_available(): ...
logger = ...

@use_kernel_forward_from_hub("MultiScaleDeformableAttention")
class MultiScaleDeformableAttention(nn.Module):
    def forward(
        self,
        value: Tensor,
        value_spatial_shapes: Tensor,
        value_spatial_shapes_list: list[tuple],
        level_start_index: Tensor,
        sampling_locations: Tensor,
        attention_weights: Tensor,
        im2col_step: int,
    ): ...

@dataclass
@auto_docstring(custom_intro=...)
class GroundingDinoDecoderOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    intermediate_hidden_states: Optional[torch.FloatTensor] = ...
    intermediate_reference_points: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class GroundingDinoEncoderOutput(ModelOutput):
    last_hidden_state_vision: Optional[torch.FloatTensor] = ...
    last_hidden_state_text: Optional[torch.FloatTensor] = ...
    vision_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    text_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class GroundingDinoModelOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    init_reference_points: Optional[torch.FloatTensor] = ...
    intermediate_hidden_states: Optional[torch.FloatTensor] = ...
    intermediate_reference_points: Optional[torch.FloatTensor] = ...
    decoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    decoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    encoder_last_hidden_state_vision: Optional[torch.FloatTensor] = ...
    encoder_last_hidden_state_text: Optional[torch.FloatTensor] = ...
    encoder_vision_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    encoder_text_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    encoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    enc_outputs_class: Optional[torch.FloatTensor] = ...
    enc_outputs_coord_logits: Optional[torch.FloatTensor] = ...
    encoder_logits: Optional[torch.FloatTensor] = ...
    encoder_pred_boxes: Optional[torch.FloatTensor] = ...

@dataclass
@auto_docstring(custom_intro=...)
class GroundingDinoObjectDetectionOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    loss_dict: Optional[dict] = ...
    logits: Optional[torch.FloatTensor] = ...
    pred_boxes: Optional[torch.FloatTensor] = ...
    auxiliary_outputs: Optional[list[dict]] = ...
    last_hidden_state: Optional[torch.FloatTensor] = ...
    init_reference_points: Optional[torch.FloatTensor] = ...
    intermediate_hidden_states: Optional[torch.FloatTensor] = ...
    intermediate_reference_points: Optional[torch.FloatTensor] = ...
    decoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    decoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    encoder_last_hidden_state_vision: Optional[torch.FloatTensor] = ...
    encoder_last_hidden_state_text: Optional[torch.FloatTensor] = ...
    encoder_vision_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    encoder_text_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    encoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    enc_outputs_class: Optional[torch.FloatTensor] = ...
    enc_outputs_coord_logits: Optional[torch.FloatTensor] = ...
    encoder_logits: Optional[torch.FloatTensor] = ...
    encoder_pred_boxes: Optional[torch.FloatTensor] = ...
    input_ids: Optional[torch.LongTensor] = ...

class GroundingDinoFrozenBatchNorm2d(nn.Module):
    def __init__(self, n) -> None: ...
    def forward(self, x): ...

def replace_batch_norm(model): ...

class GroundingDinoConvEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values: torch.Tensor, pixel_mask: torch.Tensor): ...

class GroundingDinoConvModel(nn.Module):
    def __init__(self, conv_encoder, position_embedding) -> None: ...
    def forward(self, pixel_values, pixel_mask): ...

class GroundingDinoSinePositionEmbedding(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values, pixel_mask): ...

class GroundingDinoLearnedPositionEmbedding(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values, pixel_mask=...): ...

def build_position_encoding(config): ...

class GroundingDinoMultiscaleDeformableAttention(nn.Module):
    def __init__(self, config: GroundingDinoConfig, num_heads: int, n_points: int) -> None: ...
    def with_pos_embed(self, tensor: torch.Tensor, position_embeddings: Optional[Tensor]): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        encoder_hidden_states=...,
        encoder_attention_mask=...,
        position_embeddings: Optional[torch.Tensor] = ...,
        reference_points=...,
        spatial_shapes=...,
        spatial_shapes_list=...,
        level_start_index=...,
        output_attentions: bool = ...,
    ): ...

class GroundingDinoTextEnhancerLayer(nn.Module):
    def __init__(self, config) -> None: ...
    def with_pos_embed(self, hidden_state: Tensor, position_embeddings: Optional[Tensor]): ...
    def forward(
        self,
        hidden_states: torch.FloatTensor,
        attention_masks: Optional[torch.BoolTensor] = ...,
        position_embeddings: Optional[torch.FloatTensor] = ...,
    ) -> tuple[torch.FloatTensor, torch.FloatTensor]: ...

class GroundingDinoBiMultiHeadAttention(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        vision_features: torch.FloatTensor,
        text_features: torch.FloatTensor,
        vision_attention_mask: Optional[torch.BoolTensor] = ...,
        text_attention_mask: Optional[torch.BoolTensor] = ...,
    ) -> tuple[tuple[torch.FloatTensor, torch.FloatTensor], tuple[torch.FloatTensor, torch.FloatTensor]]: ...

def drop_path(input: torch.Tensor, drop_prob: float = ..., training: bool = ...) -> torch.Tensor: ...

class GroundingDinoDropPath(nn.Module):
    def __init__(self, drop_prob: Optional[float] = ...) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...
    def extra_repr(self) -> str: ...

class GroundingDinoFusionLayer(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        vision_features: torch.FloatTensor,
        text_features: torch.FloatTensor,
        attention_mask_vision: Optional[torch.BoolTensor] = ...,
        attention_mask_text: Optional[torch.BoolTensor] = ...,
    ) -> tuple[tuple[torch.FloatTensor, torch.FloatTensor], tuple[torch.FloatTensor, torch.FloatTensor]]: ...

class GroundingDinoDeformableLayer(nn.Module):
    def __init__(self, config: GroundingDinoConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor,
        position_embeddings: Optional[torch.Tensor] = ...,
        reference_points=...,
        spatial_shapes=...,
        spatial_shapes_list=...,
        level_start_index=...,
        output_attentions: bool = ...,
    ): ...

def get_sine_pos_embed(
    pos_tensor: torch.Tensor, num_pos_feats: int = ..., temperature: int = ..., exchange_xy: bool = ...
) -> Tensor: ...

class GroundingDinoEncoderLayer(nn.Module):
    def __init__(self, config) -> None: ...
    def get_text_position_embeddings(
        self,
        text_features: Tensor,
        text_position_embedding: Optional[torch.Tensor],
        text_position_ids: Optional[torch.Tensor],
    ) -> Tensor: ...
    def forward(
        self,
        vision_features: Tensor,
        vision_position_embedding: Tensor,
        spatial_shapes: Tensor,
        spatial_shapes_list: list[tuple[int, int]],
        level_start_index: Tensor,
        key_padding_mask: Tensor,
        reference_points: Tensor,
        text_features: Optional[Tensor] = ...,
        text_attention_mask: Optional[Tensor] = ...,
        text_position_embedding: Optional[Tensor] = ...,
        text_self_attention_masks: Optional[Tensor] = ...,
        text_position_ids: Optional[Tensor] = ...,
    ): ...

class GroundingDinoMultiheadAttention(nn.Module):
    def __init__(self, config, num_attention_heads=...) -> None: ...
    def forward(
        self,
        queries: torch.Tensor,
        keys: torch.Tensor,
        values: torch.Tensor,
        attention_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> tuple[torch.Tensor]: ...

class GroundingDinoDecoderLayer(nn.Module):
    def __init__(self, config: GroundingDinoConfig) -> None: ...
    def with_pos_embed(self, tensor: torch.Tensor, position_embeddings: Optional[Tensor]): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        position_embeddings: Optional[torch.Tensor] = ...,
        reference_points=...,
        spatial_shapes=...,
        spatial_shapes_list=...,
        level_start_index=...,
        vision_encoder_hidden_states: Optional[torch.Tensor] = ...,
        vision_encoder_attention_mask: Optional[torch.Tensor] = ...,
        text_encoder_hidden_states: Optional[torch.Tensor] = ...,
        text_encoder_attention_mask: Optional[torch.Tensor] = ...,
        self_attn_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
    ): ...

class GroundingDinoContrastiveEmbedding(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        vision_hidden_state: torch.FloatTensor,
        text_hidden_state: torch.FloatTensor,
        text_token_mask: torch.BoolTensor,
    ) -> torch.FloatTensor: ...

@auto_docstring
class GroundingDinoPreTrainedModel(PreTrainedModel):
    config: GroundingDinoConfig
    base_model_prefix = ...
    main_input_name = ...

class GroundingDinoEncoder(GroundingDinoPreTrainedModel):
    def __init__(self, config: GroundingDinoConfig) -> None: ...
    @staticmethod
    def get_reference_points(spatial_shapes, valid_ratios, device): ...
    def forward(
        self,
        vision_features: Tensor,
        vision_attention_mask: Tensor,
        vision_position_embedding: Tensor,
        spatial_shapes: Tensor,
        spatial_shapes_list: list[tuple[int, int]],
        level_start_index: Tensor,
        valid_ratios=...,
        text_features: Optional[Tensor] = ...,
        text_attention_mask: Optional[Tensor] = ...,
        text_position_embedding: Optional[Tensor] = ...,
        text_self_attention_masks: Optional[Tensor] = ...,
        text_position_ids: Optional[Tensor] = ...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
    ): ...

class GroundingDinoDecoder(GroundingDinoPreTrainedModel):
    def __init__(self, config: GroundingDinoConfig) -> None: ...
    def forward(
        self,
        inputs_embeds,
        vision_encoder_hidden_states,
        vision_encoder_attention_mask=...,
        text_encoder_hidden_states=...,
        text_encoder_attention_mask=...,
        reference_points=...,
        spatial_shapes=...,
        spatial_shapes_list=...,
        level_start_index=...,
        valid_ratios=...,
        self_attn_mask=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
    ): ...

SPECIAL_TOKENS = ...

def generate_masks_with_special_tokens_and_transfer_map(input_ids: torch.LongTensor) -> tuple[Tensor, Tensor]: ...

@auto_docstring(custom_intro=...)
class GroundingDinoModel(GroundingDinoPreTrainedModel):
    def __init__(self, config: GroundingDinoConfig) -> None: ...
    def get_encoder(self): ...
    def get_decoder(self): ...
    def freeze_backbone(self): ...
    def unfreeze_backbone(self): ...
    def get_valid_ratio(self, mask): ...
    def generate_encoder_output_proposals(self, enc_output, padding_mask, spatial_shapes): ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Tensor,
        input_ids: Tensor,
        token_type_ids: Optional[Tensor] = ...,
        attention_mask: Optional[Tensor] = ...,
        pixel_mask: Optional[Tensor] = ...,
        encoder_outputs=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
    ): ...

class GroundingDinoMLPPredictionHead(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers) -> None: ...
    def forward(self, x): ...

def build_label_maps(logits: torch.FloatTensor, input_ids: torch.LongTensor) -> tuple[torch.FloatTensor]: ...
def build_text_mask(logits, attention_mask): ...

@auto_docstring(custom_intro=...)
class GroundingDinoForObjectDetection(GroundingDinoPreTrainedModel):
    _tied_weights_keys = ...
    def __init__(self, config: GroundingDinoConfig) -> None: ...
    @auto_docstring
    def forward(
        self,
        pixel_values: torch.FloatTensor,
        input_ids: torch.LongTensor,
        token_type_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        pixel_mask: Optional[torch.BoolTensor] = ...,
        encoder_outputs: Optional[Union[GroundingDinoEncoderOutput, tuple]] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        labels: Optional[list[dict[str, Union[torch.LongTensor, torch.FloatTensor]]]] = ...,
    ): ...

__all__ = ["GroundingDinoForObjectDetection", "GroundingDinoModel", "GroundingDinoPreTrainedModel"]
