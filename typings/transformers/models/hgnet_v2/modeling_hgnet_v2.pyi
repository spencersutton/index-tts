"""
This type stub file was generated by pyright.
"""

import torch
from typing import Optional
from torch import Tensor, nn
from ...modeling_outputs import BackboneOutput, BaseModelOutputWithNoAttention, ImageClassifierOutputWithNoAttention
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from ...utils.backbone_utils import BackboneMixin
from .configuration_hgnet_v2 import HGNetV2Config

@auto_docstring
class HGNetV2PreTrainedModel(PreTrainedModel):
    config: HGNetV2Config
    base_model_prefix = ...
    main_input_name = ...
    _no_split_modules = ...

class HGNetV2LearnableAffineBlock(nn.Module):
    def __init__(self, scale_value: float = ..., bias_value: float = ...) -> None: ...
    def forward(self, hidden_state: Tensor) -> Tensor: ...

class HGNetV2ConvLayer(nn.Module):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int,
        stride: int = ...,
        groups: int = ...,
        activation: str = ...,
        use_learnable_affine_block: bool = ...,
    ) -> None: ...
    def forward(self, input: Tensor) -> Tensor: ...

class HGNetV2ConvLayerLight(nn.Module):
    def __init__(
        self, in_channels: int, out_channels: int, kernel_size: int, use_learnable_affine_block: bool = ...
    ) -> None: ...
    def forward(self, hidden_state: Tensor) -> Tensor: ...

class HGNetV2Embeddings(nn.Module):
    def __init__(self, config: HGNetV2Config) -> None: ...
    def forward(self, pixel_values: Tensor) -> Tensor: ...

class HGNetV2BasicLayer(nn.Module):
    def __init__(
        self,
        in_channels: int,
        middle_channels: int,
        out_channels: int,
        layer_num: int,
        kernel_size: int = ...,
        residual: bool = ...,
        light_block: bool = ...,
        drop_path: float = ...,
        use_learnable_affine_block: bool = ...,
    ) -> None: ...
    def forward(self, hidden_state: Tensor) -> Tensor: ...

class HGNetV2Stage(nn.Module):
    def __init__(self, config: HGNetV2Config, stage_index: int, drop_path: float = ...) -> None: ...
    def forward(self, hidden_state: Tensor) -> Tensor: ...

class HGNetV2Encoder(nn.Module):
    def __init__(self, config: HGNetV2Config) -> None: ...
    def forward(
        self, hidden_state: Tensor, output_hidden_states: bool = ..., return_dict: bool = ...
    ) -> BaseModelOutputWithNoAttention: ...

class HGNetV2Backbone(HGNetV2PreTrainedModel, BackboneMixin):
    def __init__(self, config: HGNetV2Config) -> None: ...
    @auto_docstring
    def forward(
        self, pixel_values: Tensor, output_hidden_states: Optional[bool] = ..., return_dict: Optional[bool] = ...
    ) -> BackboneOutput:
        r"""
        Examples:

        ```python
        >>> from transformers import RTDetrResNetConfig, RTDetrResNetBackbone
        >>> import torch

        >>> config = RTDetrResNetConfig()
        >>> model = RTDetrResNetBackbone(config)

        >>> pixel_values = torch.randn(1, 3, 224, 224)

        >>> with torch.no_grad():
        ...     outputs = model(pixel_values)

        >>> feature_maps = outputs.feature_maps
        >>> list(feature_maps[-1].shape)
        [1, 2048, 7, 7]
        ```"""
        ...

@auto_docstring(
    custom_intro="""
    HGNetV2 Model with an image classification head on top (a linear layer on top of the pooled features), e.g. for
    ImageNet.
    """
)
class HGNetV2ForImageClassification(HGNetV2PreTrainedModel):
    def __init__(self, config: HGNetV2Config) -> None: ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> ImageClassifierOutputWithNoAttention:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
            Labels for computing the image classification/regression loss. Indices should be in `[0, ...,
            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If
            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).

        Examples:
        ```python
        >>> import torch
        >>> import requests
        >>> from transformers import HGNetV2ForImageClassification, AutoImageProcessor
        >>> from PIL import Image

        >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
        >>> image = Image.open(requests.get(url, stream=True).raw)

        >>> model = HGNetV2ForImageClassification.from_pretrained("ustc-community/hgnet-v2")
        >>> processor = AutoImageProcessor.from_pretrained("ustc-community/hgnet-v2")

        >>> inputs = processor(images=image, return_tensors="pt")
        >>> with torch.no_grad():
        ...     outputs = model(**inputs)
        >>> outputs.logits.shape
        torch.Size([1, 2])
        ```"""
        ...

__all__ = ["HGNetV2Backbone", "HGNetV2PreTrainedModel", "HGNetV2ForImageClassification"]
