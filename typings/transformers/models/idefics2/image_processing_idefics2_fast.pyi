import torch
from torchvision.transforms import functional as F

from ...image_processing_utils_fast import (
    BaseImageProcessorFast,
    BatchFeature,
    DefaultFastImageProcessorKwargs,
    SizeDict,
)
from ...image_utils import ImageInput
from ...processing_utils import Unpack
from ...utils import is_torchvision_available

if is_torchvision_available(): ...
logger = ...

def get_resize_output_image_size(image: torch.Tensor, size: SizeDict) -> tuple[int, int]: ...
def get_max_height_width(images_list: list[list[torch.Tensor]]) -> tuple[int, int]: ...
def make_pixel_mask(image: torch.Tensor, output_size: tuple[int, int]) -> torch.Tensor: ...

class Idefics2FastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    do_image_splitting: bool | None
    do_pad: bool | None

class Idefics2ImageProcessorFast(BaseImageProcessorFast):
    resample = ...
    image_mean = ...
    image_std = ...
    do_resize = ...
    do_rescale = ...
    do_normalize = ...
    do_pad = ...
    do_convert_rgb = ...
    do_image_splitting = ...
    size = ...
    model_input_names = ...
    valid_kwargs = Idefics2FastImageProcessorKwargs
    def convert_to_rgb(self, image: ImageInput) -> ImageInput: ...
    def resize(
        self, image: torch.Tensor, size: SizeDict, interpolation: F.InterpolationMode | None = ..., **kwargs
    ) -> torch.Tensor: ...
    def split_images(self, images: torch.Tensor) -> list[torch.Tensor]: ...
    def pad(
        self, image: torch.Tensor, padded_size: tuple[int, int], fill: int = ...
    ) -> tuple[torch.Tensor, torch.Tensor]: ...
    def preprocess(self, images: ImageInput, **kwargs: Unpack[Idefics2FastImageProcessorKwargs]) -> BatchFeature: ...

__all__ = ["Idefics2ImageProcessorFast"]
