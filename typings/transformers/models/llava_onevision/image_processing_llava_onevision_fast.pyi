"""
This type stub file was generated by pyright.
"""

from typing import Optional, Union

import torch

from ...image_processing_utils import BatchFeature
from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs
from ...image_utils import ImageInput
from ...processing_utils import Unpack
from ...utils import auto_docstring, is_torchvision_v2_available

if is_torchvision_v2_available(): ...
else: ...

class LlavaOnevisionFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    """
    image_grid_pinpoints (`list[list[int]]`, *optional*):
        A list of possible resolutions to use for processing high resolution images. The best resolution is selected
        based on the original size of the image. Can be overridden by `image_grid_pinpoints` in the `preprocess`
        method.
    do_pad (`bool`, *optional*):
        Whether to pad the image. If `True`, will pad the patch dimension of the images in the batch to the largest
        number of patches in the batch. Padding will be applied to the bottom and right with zeros.
    """

    image_grid_pinpoints: list[list[int]] | None
    do_pad: bool | None
    ...

@auto_docstring
class LlavaOnevisionImageProcessorFast(BaseImageProcessorFast):
    resample = ...
    image_mean = ...
    image_std = ...
    size = ...
    default_to_square = ...
    crop_size = ...
    do_resize = ...
    do_center_crop = ...
    do_rescale = ...
    do_normalize = ...
    do_convert_rgb = ...
    do_pad = ...
    image_grid_pinpoints = ...
    valid_kwargs = LlavaOnevisionFastImageProcessorKwargs
    model_input_names = ...
    def __init__(self, **kwargs: Unpack[LlavaOnevisionFastImageProcessorKwargs]) -> None: ...
    @auto_docstring
    def preprocess(
        self, images: ImageInput, **kwargs: Unpack[LlavaOnevisionFastImageProcessorKwargs]
    ) -> BatchFeature: ...
    def pad_to_square(self, images: torch.Tensor, background_color: int | tuple[int, int, int] = ...) -> torch.Tensor:
        """
        Pads an image to a square based on the longest edge.

        Args:
            images (`np.ndarray`):
                The images to pad.
            background_color (`int` or `tuple[int, int, int]`, *optional*, defaults to 0):
                The color to use for the padding. Can be an integer for single channel or a
                tuple of integers representing for multi-channel images. If passed as integer
                in mutli-channel mode, it will default to `0` in subsequent channels.
        Returns:
            `torch.Tensor`: The padded images.
        """
        ...

__all__ = ["LlavaOnevisionImageProcessorFast"]
