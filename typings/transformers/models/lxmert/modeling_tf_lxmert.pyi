"""
This type stub file was generated by pyright.
"""

import numpy as np
import tensorflow as tf
from dataclasses import dataclass
from ...modeling_tf_utils import TFModelInputType, TFPreTrainedModel, keras, keras_serializable, unpack_inputs
from ...utils import (
    ModelOutput,
    add_code_sample_docstrings,
    add_start_docstrings,
    add_start_docstrings_to_model_forward,
    replace_return_docstrings,
)
from .configuration_lxmert import LxmertConfig

logger = ...
_CHECKPOINT_FOR_DOC = ...
_CONFIG_FOR_DOC = ...

@dataclass
class TFLxmertModelOutput(ModelOutput):
    language_output: tf.Tensor | None = ...
    vision_output: tf.Tensor | None = ...
    pooled_output: tf.Tensor | None = ...
    language_hidden_states: tuple[tf.Tensor] | None = ...
    vision_hidden_states: tuple[tf.Tensor] | None = ...
    language_attentions: tuple[tf.Tensor] | None = ...
    vision_attentions: tuple[tf.Tensor] | None = ...
    cross_encoder_attentions: tuple[tf.Tensor] | None = ...

@dataclass
class TFLxmertForPreTrainingOutput(ModelOutput):
    loss: tf.Tensor | None = ...
    prediction_logits: tf.Tensor | None = ...
    cross_relationship_score: tf.Tensor | None = ...
    question_answering_score: tf.Tensor | None = ...
    language_hidden_states: tuple[tf.Tensor] | None = ...
    vision_hidden_states: tuple[tf.Tensor] | None = ...
    language_attentions: tuple[tf.Tensor] | None = ...
    vision_attentions: tuple[tf.Tensor] | None = ...
    cross_encoder_attentions: tuple[tf.Tensor] | None = ...

class TFLxmertVisualFeatureEncoder(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, visn_input, training=...): ...
    def build(self, input_shape=...): ...

class TFLxmertEmbeddings(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def build(self, input_shape=...): ...
    def call(self, input_ids=..., token_type_ids=..., inputs_embeds=..., training=...): ...

class TFLxmertAttention(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def transpose_for_scores(self, x, batch_size): ...
    def call(self, hidden_states, context, attention_mask, output_attentions, training=...): ...
    def build(self, input_shape=...): ...

class TFLxmertIntermediate(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden_states): ...
    def build(self, input_shape=...): ...

class TFLxmertOutput(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden_states, input_tensor, training=...): ...
    def build(self, input_shape=...): ...

class TFLxmertAttentionOutput(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden_states, input_tensor, training=...): ...
    def build(self, input_shape=...): ...

class TFLxmertSelfAttentionLayer(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, input_tensor, attention_mask, output_attentions, training=...): ...
    def build(self, input_shape=...): ...

class TFLxmertCrossAttentionLayer(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, input_tensor, ctx_tensor, ctx_att_mask, output_attentions=..., training=...): ...
    def build(self, input_shape=...): ...

class TFLxmertLayer(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden_states, attention_mask, output_attentions, training=...): ...
    def build(self, input_shape=...): ...

class TFLxmertXLayer(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def cross_att(
        self, lang_input, lang_attention_mask, visn_input, visn_attention_mask, output_attentions, training=...
    ): ...
    def self_att(self, lang_input, lang_attention_mask, visn_input, visn_attention_mask, training=...): ...
    def output_fc(self, lang_input, visn_input, training=...): ...
    def call(
        self, lang_feats, lang_attention_mask, visn_feats, visn_attention_mask, output_attentions, training=...
    ): ...
    def build(self, input_shape=...): ...

class TFLxmertEncoder(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(
        self,
        lang_feats=...,
        lang_attention_mask=...,
        visual_feats=...,
        visual_pos=...,
        visual_attention_mask=...,
        output_attentions=...,
        training=...,
    ): ...
    def build(self, input_shape=...): ...

@keras_serializable
class TFLxmertMainLayer(keras.layers.Layer):
    config_class = LxmertConfig
    def __init__(self, config, **kwargs) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    @unpack_inputs
    def call(
        self,
        input_ids=...,
        visual_feats=...,
        visual_pos=...,
        attention_mask=...,
        visual_attention_mask=...,
        token_type_ids=...,
        inputs_embeds=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
        training=...,
    ): ...
    def build(self, input_shape=...): ...

class TFLxmertPreTrainedModel(TFPreTrainedModel):
    config_class = LxmertConfig
    base_model_prefix = ...
    @property
    def dummy_inputs(self): ...
    @property
    def input_signature(self): ...

LXMERT_START_DOCSTRING = ...
LXMERT_INPUTS_DOCSTRING = ...

@add_start_docstrings(..., LXMERT_START_DOCSTRING)
class TFLxmertModel(TFLxmertPreTrainedModel):
    def __init__(self, config, *inputs, **kwargs) -> None: ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(LXMERT_INPUTS_DOCSTRING)
    @add_code_sample_docstrings(
        checkpoint=_CHECKPOINT_FOR_DOC, output_type=TFLxmertModelOutput, config_class=_CONFIG_FOR_DOC
    )
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        visual_feats: tf.Tensor | None = ...,
        visual_pos: tf.Tensor | None = ...,
        attention_mask: np.ndarray | tf.Tensor | None = ...,
        visual_attention_mask: np.ndarray | tf.Tensor | None = ...,
        token_type_ids: np.ndarray | tf.Tensor | None = ...,
        inputs_embeds: np.ndarray | tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool = ...,
    ) -> tuple | TFLxmertModelOutput: ...
    def build(self, input_shape=...): ...

class TFLxmertPooler(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden_states): ...
    def build(self, input_shape=...): ...

class TFLxmertPredictionHeadTransform(keras.layers.Layer):
    def __init__(self, config: LxmertConfig, **kwargs) -> None: ...
    def call(self, hidden_states: tf.Tensor) -> tf.Tensor: ...
    def build(self, input_shape=...): ...

class TFLxmertLMPredictionHead(keras.layers.Layer):
    def __init__(self, config: LxmertConfig, input_embeddings: keras.layers.Layer, **kwargs) -> None: ...
    def build(self, input_shape=...): ...
    def get_output_embeddings(self) -> keras.layers.Layer: ...
    def set_output_embeddings(self, value: tf.Variable): ...
    def get_bias(self) -> dict[str, tf.Variable]: ...
    def set_bias(self, value: tf.Variable): ...
    def call(self, hidden_states: tf.Tensor) -> tf.Tensor: ...

class TFLxmertMLMHead(keras.layers.Layer):
    def __init__(self, config: LxmertConfig, input_embeddings: keras.layers.Layer, **kwargs) -> None: ...
    def call(self, sequence_output: tf.Tensor) -> tf.Tensor: ...
    def build(self, input_shape=...): ...

class TFLxmertPreTrainingHeads(keras.layers.Layer):
    def __init__(self, config, input_embeddings, **kwargs) -> None: ...
    def call(self, sequence_output, pooled_output): ...
    def build(self, input_shape=...): ...

class TFLxmertVisualAnswerHead(keras.layers.Layer):
    def __init__(self, config, num_labels, **kwargs) -> None: ...
    def call(self, hidden_states): ...
    def build(self, input_shape=...): ...

class TFLxmertVisualObjHead(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden_states): ...
    def build(self, input_shape=...): ...

@add_start_docstrings(..., LXMERT_START_DOCSTRING)
class TFLxmertForPreTraining(TFLxmertPreTrainedModel):
    def __init__(self, config, *inputs, **kwargs) -> None: ...
    @property
    def dummy_inputs(self): ...
    def get_lm_head(self): ...
    def get_prefix_bias_name(self): ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(LXMERT_INPUTS_DOCSTRING)
    @replace_return_docstrings(output_type=TFLxmertForPreTrainingOutput, config_class=_CONFIG_FOR_DOC)
    def call(
        self,
        input_ids: TFModelInputType | None = ...,
        visual_feats: tf.Tensor | None = ...,
        visual_pos: tf.Tensor | None = ...,
        attention_mask: tf.Tensor | None = ...,
        visual_attention_mask: tf.Tensor | None = ...,
        token_type_ids: tf.Tensor | None = ...,
        inputs_embeds: tf.Tensor | None = ...,
        masked_lm_labels: tf.Tensor | None = ...,
        obj_labels: dict[str, tuple[tf.Tensor, tf.Tensor]] | None = ...,
        matched_label: tf.Tensor | None = ...,
        ans: tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool = ...,
    ) -> tuple[tf.Tensor] | TFLxmertForPreTrainingOutput: ...
    def build(self, input_shape=...): ...

__all__ = [
    "TFLxmertForPreTraining",
    "TFLxmertMainLayer",
    "TFLxmertModel",
    "TFLxmertPreTrainedModel",
    "TFLxmertVisualFeatureEncoder",
]
