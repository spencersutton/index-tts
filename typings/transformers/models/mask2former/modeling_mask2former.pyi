"""
This type stub file was generated by pyright.
"""

import numpy as np
import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import Tensor, nn
from ...file_utils import ModelOutput, is_scipy_available
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutputWithCrossAttentions
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring, is_accelerate_available
from .configuration_mask2former import Mask2FormerConfig

if is_scipy_available(): ...
if is_accelerate_available(): ...
logger = ...

@dataclass
@auto_docstring(custom_intro=...)
class Mask2FormerPixelDecoderOutput(ModelOutput):
    multi_scale_features: tuple[torch.FloatTensor] = ...
    mask_features: Optional[torch.FloatTensor] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class Mask2FormerMaskedAttentionDecoderOutput(BaseModelOutputWithCrossAttentions):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[torch.FloatTensor] = ...
    masks_queries_logits: tuple[torch.FloatTensor] = ...
    intermediate_hidden_states: tuple[torch.FloatTensor] = ...

@dataclass
@auto_docstring(custom_intro=...)
class Mask2FormerPixelLevelModuleOutput(ModelOutput):
    encoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    decoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    decoder_hidden_states: tuple[torch.FloatTensor] = ...

@dataclass
@auto_docstring(custom_intro=...)
class Mask2FormerModelOutput(ModelOutput):
    encoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    pixel_decoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    transformer_decoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    pixel_decoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    transformer_decoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    transformer_decoder_intermediate_states: tuple[torch.FloatTensor] = ...
    masks_queries_logits: tuple[torch.FloatTensor] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class Mask2FormerForUniversalSegmentationOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    class_queries_logits: Optional[torch.FloatTensor] = ...
    masks_queries_logits: Optional[torch.FloatTensor] = ...
    auxiliary_logits: Optional[list[dict[str, torch.FloatTensor]]] = ...
    encoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    pixel_decoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    transformer_decoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    pixel_decoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    transformer_decoder_hidden_states: Optional[torch.FloatTensor] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

def sample_point(
    input_features: torch.Tensor, point_coordinates: torch.Tensor, add_dim=..., **kwargs
) -> torch.Tensor: ...
def dice_loss(inputs: Tensor, labels: Tensor, num_masks: int) -> Tensor: ...
def sigmoid_cross_entropy_loss(inputs: torch.Tensor, labels: torch.Tensor, num_masks: int) -> torch.Tensor: ...
def pair_wise_dice_loss(inputs: Tensor, labels: Tensor) -> Tensor: ...
def pair_wise_sigmoid_cross_entropy_loss(inputs: torch.Tensor, labels: torch.Tensor) -> torch.Tensor: ...

class Mask2FormerHungarianMatcher(nn.Module):
    def __init__(
        self, cost_class: float = ..., cost_mask: float = ..., cost_dice: float = ..., num_points: int = ...
    ) -> None: ...
    @torch.no_grad()
    def forward(
        self,
        masks_queries_logits: torch.Tensor,
        class_queries_logits: torch.Tensor,
        mask_labels: torch.Tensor,
        class_labels: torch.Tensor,
    ) -> list[tuple[Tensor]]: ...

class Mask2FormerLoss(nn.Module):
    def __init__(self, config: Mask2FormerConfig, weight_dict: dict[str, float]) -> None: ...
    def loss_labels(
        self, class_queries_logits: Tensor, class_labels: list[Tensor], indices: tuple[np.array]
    ) -> dict[str, Tensor]: ...
    def loss_masks(
        self,
        masks_queries_logits: torch.Tensor,
        mask_labels: list[torch.Tensor],
        indices: tuple[np.array],
        num_masks: int,
    ) -> dict[str, torch.Tensor]: ...
    def calculate_uncertainty(self, logits: torch.Tensor) -> torch.Tensor: ...
    def sample_points_using_uncertainty(
        self,
        logits: torch.Tensor,
        uncertainty_function,
        num_points: int,
        oversample_ratio: int,
        importance_sample_ratio: float,
    ) -> torch.Tensor: ...
    def forward(
        self,
        masks_queries_logits: torch.Tensor,
        class_queries_logits: torch.Tensor,
        mask_labels: list[torch.Tensor],
        class_labels: list[torch.Tensor],
        auxiliary_predictions: Optional[dict[str, torch.Tensor]] = ...,
    ) -> dict[str, torch.Tensor]: ...
    def get_num_masks(self, class_labels: torch.Tensor, device: torch.device) -> torch.Tensor: ...

def multi_scale_deformable_attention(
    value: Tensor,
    value_spatial_shapes: Union[Tensor, list[tuple]],
    sampling_locations: Tensor,
    attention_weights: Tensor,
) -> Tensor: ...

class Mask2FormerSinePositionEmbedding(nn.Module):
    def __init__(
        self, num_pos_feats: int = ..., temperature: int = ..., normalize: bool = ..., scale: Optional[float] = ...
    ) -> None: ...
    def forward(self, x: Tensor, mask: Optional[Tensor] = ...) -> Tensor: ...

class Mask2FormerPixelDecoderEncoderMultiscaleDeformableAttention(nn.Module):
    def __init__(self, embed_dim: int, num_heads: int, n_levels: int, n_points: int) -> None: ...
    def with_pos_embed(self, tensor: torch.Tensor, position_embeddings: Optional[Tensor]): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        encoder_hidden_states=...,
        encoder_attention_mask=...,
        position_embeddings: Optional[torch.Tensor] = ...,
        reference_points=...,
        spatial_shapes_list=...,
        level_start_index=...,
        output_attentions: bool = ...,
    ): ...

class Mask2FormerPixelDecoderEncoderLayer(nn.Module):
    def __init__(self, config: Mask2FormerConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor,
        position_embeddings: Optional[torch.Tensor] = ...,
        reference_points=...,
        spatial_shapes_list=...,
        level_start_index=...,
        output_attentions: bool = ...,
    ): ...

class Mask2FormerPixelDecoderEncoderOnly(nn.Module):
    def __init__(self, config: Mask2FormerConfig) -> None: ...
    @staticmethod
    def get_reference_points(spatial_shapes_list, valid_ratios, device): ...
    def forward(
        self,
        inputs_embeds=...,
        attention_mask=...,
        position_embeddings=...,
        spatial_shapes_list=...,
        level_start_index=...,
        valid_ratios=...,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
    ): ...

class Mask2FormerPixelDecoder(nn.Module):
    def __init__(self, config: Mask2FormerConfig, feature_channels) -> None: ...
    def get_valid_ratio(self, mask, dtype=...): ...
    def forward(
        self, features, encoder_outputs=..., output_attentions=..., output_hidden_states=..., return_dict=...
    ): ...

class Mask2FormerPixelLevelModule(nn.Module):
    def __init__(self, config: Mask2FormerConfig) -> None: ...
    def forward(self, pixel_values: Tensor, output_hidden_states: bool = ...) -> Mask2FormerPixelLevelModuleOutput: ...

class Mask2FormerAttention(nn.Module):
    def __init__(
        self, embed_dim: int, num_heads: int, dropout: float = ..., is_decoder: bool = ..., bias: bool = ...
    ) -> None: ...
    def with_pos_embed(self, tensor: torch.Tensor, position_embeddings: Optional[Tensor]): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        position_embeddings: Optional[torch.Tensor] = ...,
        key_value_states: Optional[torch.Tensor] = ...,
        key_value_position_embeddings: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ) -> tuple[torch.Tensor, Optional[torch.Tensor], Optional[tuple[torch.Tensor]]]: ...

class Mask2FormerMaskedAttentionDecoderLayer(GradientCheckpointingLayer):
    def __init__(self, config: Mask2FormerConfig) -> None: ...
    def with_pos_embed(self, tensor, pos: Optional[Tensor]): ...
    def forward_post(
        self,
        hidden_states: torch.Tensor,
        level_index: Optional[int] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_embeddings: Optional[torch.Tensor] = ...,
        query_position_embeddings: Optional[torch.Tensor] = ...,
        encoder_hidden_states: Optional[torch.Tensor] = ...,
        encoder_attention_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
    ): ...
    def forward_pre(
        self,
        hidden_states: torch.Tensor,
        level_index: Optional[int] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_embeddings: Optional[torch.Tensor] = ...,
        query_position_embeddings: Optional[torch.Tensor] = ...,
        encoder_hidden_states: Optional[torch.Tensor] = ...,
        encoder_attention_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
    ): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        level_index: Optional[int] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_embeddings: Optional[torch.Tensor] = ...,
        query_position_embeddings: Optional[torch.Tensor] = ...,
        encoder_hidden_states: Optional[torch.Tensor] = ...,
        encoder_attention_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
    ): ...

class Mask2FormerMaskedAttentionDecoder(nn.Module):
    def __init__(self, config: Mask2FormerConfig) -> None: ...
    def forward(
        self,
        inputs_embeds: Optional[torch.Tensor] = ...,
        multi_stage_positional_embeddings: Optional[torch.Tensor] = ...,
        pixel_embeddings: Optional[torch.Tensor] = ...,
        encoder_hidden_states: Optional[torch.Tensor] = ...,
        query_position_embeddings: Optional[torch.Tensor] = ...,
        feature_size_list: Optional[list] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ): ...

class Mask2FormerPredictionBlock(nn.Module):
    def __init__(self, in_dim: int, out_dim: int, activation: nn.Module) -> None: ...
    def forward(self, input: Tensor) -> Tensor: ...

class Mask2FormerMLPPredictionHead(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, num_layers: int = ...) -> None: ...
    def forward(self, input: Tensor) -> Tensor: ...

class Mask2FormerMaskPredictor(nn.Module):
    def __init__(self, hidden_size: int, num_heads: int, mask_feature_size: torch.Tensor) -> None: ...
    def forward(
        self, outputs: torch.Tensor, pixel_embeddings: torch.Tensor, attention_mask_target_size: Optional[int] = ...
    ): ...

class Mask2FormerTransformerModule(nn.Module):
    def __init__(self, in_features: int, config: Mask2FormerConfig) -> None: ...
    def forward(
        self,
        multi_scale_features: list[Tensor],
        mask_features: Tensor,
        output_hidden_states: bool = ...,
        output_attentions: bool = ...,
    ) -> Mask2FormerMaskedAttentionDecoderOutput: ...

@auto_docstring
class Mask2FormerPreTrainedModel(PreTrainedModel):
    config: Mask2FormerConfig
    base_model_prefix = ...
    main_input_name = ...

@auto_docstring
class Mask2FormerModel(Mask2FormerPreTrainedModel):
    main_input_name = ...
    def __init__(self, config: Mask2FormerConfig) -> None: ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Tensor,
        pixel_mask: Optional[Tensor] = ...,
        output_hidden_states: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Mask2FormerModelOutput: ...

@auto_docstring(custom_intro=...)
class Mask2FormerForUniversalSegmentation(Mask2FormerPreTrainedModel):
    main_input_name = ...
    def __init__(self, config: Mask2FormerConfig) -> None: ...
    def get_loss_dict(
        self,
        masks_queries_logits: Tensor,
        class_queries_logits: Tensor,
        mask_labels: Tensor,
        class_labels: Tensor,
        auxiliary_predictions: dict[str, Tensor],
    ) -> dict[str, Tensor]: ...
    def get_loss(self, loss_dict: dict[str, Tensor]) -> Tensor: ...
    def get_auxiliary_logits(self, classes: torch.Tensor, output_masks: torch.Tensor): ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Tensor,
        mask_labels: Optional[list[Tensor]] = ...,
        class_labels: Optional[list[Tensor]] = ...,
        pixel_mask: Optional[Tensor] = ...,
        output_hidden_states: Optional[bool] = ...,
        output_auxiliary_logits: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Mask2FormerForUniversalSegmentationOutput: ...

__all__ = ["Mask2FormerForUniversalSegmentation", "Mask2FormerModel", "Mask2FormerPreTrainedModel"]
