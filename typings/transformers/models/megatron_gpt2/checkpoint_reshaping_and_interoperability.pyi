def add_checkpointing_args(parser): ...
def add_megatron_checkpoint_args(parser): ...
def add_transformers_checkpoint_args(parser): ...

megatron_to_transformers = ...
transformers_to_megatron = ...
tensor_parallel_params = ...

def recursive_print(name, val, spaces=...):  # -> None:

    ...
def megatron_to_transformers_fix_query_key_value_ordering(
    param, checkpoint_version, num_splits, num_heads, hidden_size
): ...
def transformers_to_megatron_fix_query_key_value_ordering(
    param, checkpoint_version, num_splits, num_heads, hidden_size
): ...
def merge_transformers_sharded_states(path, num_checkpoints):  # -> dict[Any, Any]:

    ...
def get_megatron_sharded_states(args, tp_size, pp_size, pp_rank):  # -> list[Any]:

    ...
def get_element_from_dict_by_path(d, path): ...
def convert_checkpoint_from_megatron_to_transformers(args):  # -> None:

    ...
def convert_checkpoint_from_transformers_to_megatron(args):  # -> None:

    ...
def main():  # -> None:
    ...

if __name__ == "__main__": ...
