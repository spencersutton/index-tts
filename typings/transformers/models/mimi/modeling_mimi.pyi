"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import nn
from ...cache_utils import Cache
from ...modeling_flash_attention_utils import is_flash_attn_available
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutputWithPast
from ...modeling_rope_utils import dynamic_rope_update
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput, auto_docstring
from .configuration_mimi import MimiConfig

if is_flash_attn_available(): ...
logger = ...

@dataclass
@auto_docstring
class MimiOutput(ModelOutput):
    audio_codes: Optional[torch.LongTensor] = ...
    audio_values: Optional[torch.FloatTensor] = ...
    encoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...
    decoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...

class MimiConv1dPaddingCache:
    def __init__(
        self,
        num_layers: int,
        per_layer_padding: list[int],
        per_layer_padding_mode: list[str],
        per_layer_in_channels: list[int],
    ) -> None: ...
    def update(self, hidden_states: torch.Tensor, layer_idx: int): ...

@dataclass
@auto_docstring
class MimiEncoderOutput(ModelOutput):
    audio_codes: Optional[torch.LongTensor] = ...
    encoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...
    padding_cache: Optional[MimiConv1dPaddingCache] = ...

@dataclass
@auto_docstring
class MimiDecoderOutput(ModelOutput):
    audio_values: Optional[torch.FloatTensor] = ...
    decoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...

class MimiConv1d(nn.Module):
    def __init__(
        self,
        config,
        in_channels: int,
        out_channels: int,
        kernel_size: int,
        stride: int = ...,
        dilation: int = ...,
        groups: int = ...,
        pad_mode: Optional[str] = ...,
        bias: bool = ...,
        layer_idx: Optional[int] = ...,
    ) -> None: ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    def forward(self, hidden_states, padding_cache=...): ...

class MimiConvTranspose1d(nn.Module):
    def __init__(
        self,
        config,
        in_channels: int,
        out_channels: int,
        kernel_size: int,
        stride: int = ...,
        groups: int = ...,
        bias=...,
    ) -> None: ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    def forward(self, hidden_states): ...

class MimiResnetBlock(nn.Module):
    def __init__(self, config: MimiConfig, dim: int, dilations: list[int]) -> None: ...
    def forward(self, hidden_states, padding_cache=...): ...

class MimiEncoder(nn.Module):
    def __init__(self, config: MimiConfig) -> None: ...
    def forward(self, hidden_states, padding_cache=...): ...

class MimiLayerScale(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, x: torch.Tensor): ...

class MimiRotaryEmbedding(nn.Module):
    def __init__(self, config: MimiConfig, device=...) -> None: ...
    @torch.no_grad()
    @dynamic_rope_update
    def forward(self, x, position_ids): ...

def rotate_half(x): ...
def apply_rotary_pos_emb(q, k, cos, sin, position_ids=..., unsqueeze_dim=...): ...

class MimiMLP(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor: ...

class MimiAttention(nn.Module):
    def __init__(self, config: MimiConfig, layer_idx: Optional[int] = ...) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_value: Optional[Cache] = ...,
        output_attentions: bool = ...,
        use_cache: bool = ...,
        cache_position: Optional[torch.LongTensor] = ...,
    ) -> tuple[torch.Tensor, Optional[torch.Tensor], Optional[tuple[torch.Tensor]]]: ...

class MimiFlashAttention2(MimiAttention):
    def __init__(self, *args, **kwargs) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.LongTensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_value: Optional[Cache] = ...,
        output_attentions: bool = ...,
        use_cache: bool = ...,
        cache_position: Optional[torch.LongTensor] = ...,
    ) -> tuple[torch.Tensor, Optional[torch.Tensor], Optional[tuple[torch.Tensor]]]: ...

class MimiSdpaAttention(MimiAttention):
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_value: Optional[Cache] = ...,
        output_attentions: bool = ...,
        use_cache: bool = ...,
        cache_position: Optional[torch.LongTensor] = ...,
        **kwargs,
    ) -> tuple[torch.Tensor, Optional[torch.Tensor], Optional[tuple[torch.Tensor]]]: ...

MIMI_ATTENTION_CLASSES = ...

class MimiTransformerLayer(GradientCheckpointingLayer):
    def __init__(self, config: MimiConfig, layer_idx: int) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_value: Optional[Cache] = ...,
        output_attentions: Optional[bool] = ...,
        use_cache: Optional[bool] = ...,
        cache_position: Optional[torch.LongTensor] = ...,
        **kwargs,
    ) -> tuple[torch.FloatTensor, Optional[tuple[torch.FloatTensor, torch.FloatTensor]]]: ...

class MimiTransformerModel(nn.Module):
    def __init__(self, config: MimiConfig) -> None: ...
    def forward(
        self,
        hidden_states: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        cache_position: Optional[torch.LongTensor] = ...,
    ) -> Union[tuple, BaseModelOutputWithPast]: ...

class MimiDecoder(nn.Module):
    def __init__(self, config: MimiConfig) -> None: ...
    def forward(self, hidden_states): ...

class MimiEuclideanCodebook(nn.Module):
    def __init__(self, config: MimiConfig, epsilon: float = ...) -> None: ...
    @property
    def embed(self) -> torch.Tensor: ...
    def quantize(self, hidden_states): ...
    def encode(self, hidden_states): ...
    def decode(self, embed_ind): ...

class MimiVectorQuantization(nn.Module):
    def __init__(self, config: MimiConfig) -> None: ...
    def encode(self, hidden_states): ...
    def decode(self, embed_ind): ...

class MimiResidualVectorQuantizer(nn.Module):
    def __init__(self, config: MimiConfig, num_quantizers: Optional[int] = ...) -> None: ...
    def encode(self, embeddings: torch.Tensor, num_quantizers: Optional[int] = ...) -> torch.Tensor: ...
    def decode(self, codes: torch.Tensor) -> torch.Tensor: ...

class MimiSplitResidualVectorQuantizer(nn.Module):
    def __init__(self, config: MimiConfig) -> None: ...
    def encode(self, embeddings: torch.Tensor, num_quantizers: Optional[float] = ...) -> torch.Tensor: ...
    def decode(self, codes: torch.Tensor) -> torch.Tensor: ...

@auto_docstring
class MimiPreTrainedModel(PreTrainedModel):
    config: MimiConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...
    _no_split_modules = ...
    _skip_keys_device_placement = ...
    _supports_flash_attn = ...
    _supports_sdpa = ...
    _can_compile_fullgraph = ...

@auto_docstring(
    custom_intro="""
    The Mimi neural audio codec model.
    """
)
class MimiModel(MimiPreTrainedModel):
    def __init__(self, config: MimiConfig) -> None: ...
    def get_encoder(self): ...
    def get_decoder(self): ...
    def get_encoded_length(self, input_length: torch.LongTensor) -> torch.LongTensor: ...
    def get_audio_codes_mask(self, padding_mask: torch.Tensor, padding_side: str = ...): ...
    def encode(
        self,
        input_values: torch.Tensor,
        padding_mask: Optional[torch.Tensor] = ...,
        num_quantizers: Optional[float] = ...,
        encoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...,
        padding_cache: Optional[MimiConv1dPaddingCache] = ...,
        use_streaming: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor, Optional[torch.Tensor]], MimiEncoderOutput]: ...
    def decode(
        self,
        audio_codes: torch.Tensor,
        padding_mask: Optional[torch.Tensor] = ...,
        decoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor, torch.Tensor], MimiDecoderOutput]: ...
    @auto_docstring
    def forward(
        self,
        input_values: torch.Tensor,
        padding_mask: Optional[torch.Tensor] = ...,
        num_quantizers: Optional[int] = ...,
        audio_codes: Optional[torch.Tensor] = ...,
        encoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...,
        decoder_past_key_values: Optional[Union[Cache, list[torch.FloatTensor]]] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor, torch.Tensor], MimiOutput]: ...

__all__ = ["MimiModel", "MimiPreTrainedModel"]
