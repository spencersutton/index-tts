from transformers.tokenization_utils_fast import PreTrainedTokenizerFast

from ...utils import is_levenshtein_available, is_nltk_available

"""
Fast tokenizer class for Nougat.
"""
if is_levenshtein_available(): ...
if is_nltk_available(): ...
logger = ...
VOCAB_FILES_NAMES = ...

def markdown_compatible(text: str) -> str: ...
def normalize_list_like_lines(generation):  # -> LiteralString:

    ...
def find_next_punctuation(text: str, start_idx=...):  # -> int | None:

    ...
def truncate_repetitions(text: str, min_len: int = ...) -> str: ...
def remove_numbers(lines):  # -> str | list[Any]:
    ...
def get_slices(lines, clean_lines):  # -> list[Any]:

    ...
def remove_slice_from_lines(lines, clean_text, slice) -> str: ...

class NougatTokenizerFast(PreTrainedTokenizerFast):
    vocab_files_names = ...
    model_input_names = ...
    slow_tokenizer_class = ...
    def __init__(
        self,
        vocab_file=...,
        tokenizer_file=...,
        clean_up_tokenization_spaces=...,
        unk_token=...,
        bos_token=...,
        eos_token=...,
        pad_token=...,
        **kwargs,
    ) -> None: ...
    def remove_hallucinated_references(self, text: str) -> str: ...
    def correct_tables(self, generation: str) -> str: ...
    def post_process_single(self, generation: str, fix_markdown: bool = ...) -> str: ...
    def post_process_generation(
        self, generation: str | list[str], fix_markdown: bool = ..., num_workers: int | None = ...
    ) -> str | list[str]: ...

__all__ = ["NougatTokenizerFast"]
