"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from functools import lru_cache
from typing import Optional, Union
from torch import Tensor, nn
from ...file_utils import ModelOutput
from ...integrations import use_kernel_forward_from_hub
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_omdet_turbo import OmDetTurboConfig

logger = ...

@dataclass
@auto_docstring(custom_intro=...)
class OmDetTurboEncoderOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...
    extracted_states: tuple[torch.FloatTensor] = ...

@dataclass
@auto_docstring(custom_intro=...)
class OmDetTurboDecoderOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    decoder_coords: Optional[torch.FloatTensor] = ...
    decoder_classes: Optional[torch.FloatTensor] = ...
    encoder_coord_logits: Optional[torch.FloatTensor] = ...
    encoder_class_logits: tuple[torch.FloatTensor] = ...
    init_reference_points: Optional[torch.FloatTensor] = ...
    intermediate_reference_points: tuple[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class OmDetTurboObjectDetectionOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    decoder_coord_logits: Optional[torch.FloatTensor] = ...
    decoder_class_logits: Optional[torch.FloatTensor] = ...
    init_reference_points: Optional[torch.FloatTensor] = ...
    intermediate_reference_points: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    encoder_coord_logits: Optional[torch.FloatTensor] = ...
    encoder_class_logits: tuple[torch.FloatTensor] = ...
    encoder_extracted_states: Optional[torch.FloatTensor] = ...
    decoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    decoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    encoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = ...
    classes_structure: Optional[torch.LongTensor] = ...

@use_kernel_forward_from_hub("MultiScaleDeformableAttention")
class MultiScaleDeformableAttention(nn.Module):
    def forward(
        self,
        value: Tensor,
        value_spatial_shapes: Tensor,
        value_spatial_shapes_list: list[tuple],
        level_start_index: Tensor,
        sampling_locations: Tensor,
        attention_weights: Tensor,
        im2col_step: int,
    ): ...

class OmDetTurboLRUCache:
    def __init__(self, capacity: int) -> None: ...
    def has(self, key) -> bool: ...
    def get(self, key): ...
    def put(self, key, value) -> None: ...

class OmDetTurboLanguageBackbone(nn.Module):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    def forward(self, hidden_states, mask=..., encode_type=...): ...

class OmDetTurboVisionBackbone(nn.Module):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    def forward(self, pixel_values): ...

class OmDetTurboMultiscaleDeformableAttention(nn.Module):
    def __init__(self, config: OmDetTurboConfig, num_heads: int, n_points: int) -> None: ...
    def with_pos_embed(self, tensor: torch.Tensor, position_embeddings: Optional[Tensor]): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        encoder_hidden_states=...,
        encoder_attention_mask=...,
        position_embeddings: Optional[torch.Tensor] = ...,
        reference_points=...,
        spatial_shapes=...,
        spatial_shapes_list=...,
        level_start_index=...,
        output_attentions: bool = ...,
    ): ...

class OmDetTurboConvNormLayer(nn.Module):
    def __init__(self, config, in_channels, out_channels, kernel_size, stride, padding=..., activation=...) -> None: ...
    def forward(self, hidden_state): ...

class OmDetTurboRepVggBlock(nn.Module):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    def forward(self, x): ...

class OmDetTurboCSPRepLayer(nn.Module):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    def forward(self, hidden_state): ...

class OmDetTurboMultiheadAttention(nn.Module):
    def __init__(self, config, hidden_size, num_attention_heads, dropout) -> None: ...
    def forward(
        self,
        queries: torch.Tensor,
        keys: torch.Tensor,
        values: torch.Tensor,
        attention_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> tuple[torch.Tensor]: ...

class OmDetTurboEncoderLayer(nn.Module):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    @staticmethod
    def with_pos_embed(tensor, pos_embed): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor,
        position_embeddings: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ): ...

class OmDetTurboEncoder(nn.Module):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    def forward(
        self, src, src_mask=..., pos_embed=..., output_attentions: bool = ...
    ) -> tuple[Union[torch.Tensor, tuple[torch.Tensor]]]: ...

class OmDetTurboHybridEncoder(nn.Module):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    @staticmethod
    def build_2d_sincos_position_embedding(width, height, embed_dim=..., temperature=..., device=..., dtype=...): ...
    def forward(self, inputs_embeddings=..., output_attentions=..., output_hidden_states=..., return_dict=...): ...

class OmDetTurboMLPWithDropout(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, x): ...

class OmDetTurboMLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers) -> None: ...
    def forward(self, x): ...

class OmDetTurboResidualLayer(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, x, y): ...

class OmDetTurboTaskEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, x): ...

class OmDetTurboDeformableTransformerDecoderLayer(GradientCheckpointingLayer):
    def __init__(self, config) -> None: ...
    @staticmethod
    def with_pos_embed(tensor, pos): ...
    def forward(
        self,
        decoder_embeddings,
        task_features,
        reference_points,
        vision_features,
        vision_shapes,
        vision_shapes_list,
        level_start_index=...,
        attention_mask=...,
        padding_mask=...,
        query_position=...,
        output_attentions=...,
        output_hidden_states=...,
    ): ...

@auto_docstring
class OmDetTurboPreTrainedModel(PreTrainedModel):
    config: OmDetTurboConfig
    base_model_prefix = ...
    main_input_name = ...
    def get_cached_class_embeddings(self, classes_input_ids, classes_attention_mask): ...
    def get_cached_task_embeddings(self, tasks_input_ids, tasks_attention_mask): ...
    def get_language_embedding(
        self, classes_input_ids, classes_attention_mask, tasks_input_ids, tasks_attention_mask, classes_structure
    ): ...

def get_class_similarity(class_distance_type, cls_feature, class_proj): ...

class OmDetTurboDecoder(OmDetTurboPreTrainedModel):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    @lru_cache(maxsize=32)
    def generate_anchors(self, spatial_shapes=..., grid_size=..., device=..., dtype=...): ...
    def forward(
        self,
        vision_features,
        class_features,
        task_features,
        task_mask,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
    ): ...

@auto_docstring(custom_intro=...)
class OmDetTurboForObjectDetection(OmDetTurboPreTrainedModel):
    def __init__(self, config: OmDetTurboConfig) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    def resize_token_embeddings(
        self, new_num_tokens: Optional[int] = ..., pad_to_multiple_of=..., mean_resizing: bool = ...
    ) -> nn.Embedding: ...
    @auto_docstring
    def forward(
        self,
        pixel_values: torch.FloatTensor,
        classes_input_ids: torch.LongTensor,
        classes_attention_mask: torch.LongTensor,
        tasks_input_ids: torch.LongTensor,
        tasks_attention_mask: torch.LongTensor,
        classes_structure: torch.LongTensor,
        labels: Optional[torch.LongTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.FloatTensor], OmDetTurboObjectDetectionOutput]: ...

__all__ = ["OmDetTurboForObjectDetection", "OmDetTurboPreTrainedModel"]
