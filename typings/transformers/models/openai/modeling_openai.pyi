"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Any, Optional, Union
from torch import nn
from ...generation import GenerationMixin
from ...modeling_outputs import BaseModelOutput, CausalLMOutput, SequenceClassifierOutput
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput, auto_docstring
from .configuration_openai import OpenAIGPTConfig

logger = ...

def load_tf_weights_in_openai_gpt(model, config, openai_checkpoint_folder_path): ...

ACT_FNS = ...

class Attention(nn.Module):
    def __init__(self, nx, n_positions, config, scale=...) -> None: ...
    def prune_heads(self, heads): ...
    def merge_heads(self, x): ...
    def split_heads(self, x, k=...): ...
    def forward(self, x, attention_mask=..., head_mask=..., output_attentions=...): ...

class MLP(nn.Module):
    def __init__(self, n_state, config) -> None: ...
    def forward(self, x): ...

class Block(nn.Module):
    def __init__(self, n_positions, config, scale=...) -> None: ...
    def forward(self, x, attention_mask=..., head_mask=..., output_attentions=...): ...

class OpenAIGPTSequenceSummary(nn.Module):
    def __init__(self, config: OpenAIGPTConfig) -> None: ...
    def forward(
        self, hidden_states: torch.FloatTensor, cls_index: Optional[torch.LongTensor] = ...
    ) -> torch.FloatTensor: ...

@auto_docstring
class OpenAIGPTPreTrainedModel(PreTrainedModel):
    config: OpenAIGPTConfig
    load_tf_weights = ...
    base_model_prefix = ...

@dataclass
@auto_docstring(custom_intro=...)
class OpenAIGPTDoubleHeadsModelOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    mc_loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    mc_logits: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@auto_docstring
class OpenAIGPTModel(OpenAIGPTPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, new_embeddings): ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.FloatTensor] = ...,
        token_type_ids: Optional[torch.LongTensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor], BaseModelOutput]: ...

@auto_docstring(custom_intro=...)
class OpenAIGPTLMHeadModel(OpenAIGPTPreTrainedModel, GenerationMixin):
    _tied_weights_keys = ...
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.FloatTensor] = ...,
        token_type_ids: Optional[torch.LongTensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        **kwargs,
    ) -> Union[tuple[torch.Tensor], CausalLMOutput]: ...
    def prepare_inputs_for_generation(self, input_ids: torch.LongTensor, **kwargs) -> dict[str, Any]: ...

@auto_docstring(custom_intro=...)
class OpenAIGPTDoubleHeadsModel(OpenAIGPTPreTrainedModel):
    _tied_weights_keys = ...
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.FloatTensor] = ...,
        token_type_ids: Optional[torch.LongTensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        mc_token_ids: Optional[torch.LongTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        mc_labels: Optional[torch.LongTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor], OpenAIGPTDoubleHeadsModelOutput]: ...

@auto_docstring(custom_intro=...)
class OpenAIGPTForSequenceClassification(OpenAIGPTPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.FloatTensor] = ...,
        token_type_ids: Optional[torch.LongTensor] = ...,
        position_ids: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs_embeds: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.LongTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor], SequenceClassifierOutput]: ...

__all__ = [
    "OpenAIGPTDoubleHeadsModel",
    "OpenAIGPTForSequenceClassification",
    "OpenAIGPTLMHeadModel",
    "OpenAIGPTModel",
    "OpenAIGPTPreTrainedModel",
    "load_tf_weights_in_openai_gpt",
]
