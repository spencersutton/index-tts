import torch
from transformers.models.owlvit.image_processing_owlvit_fast import OwlViTImageProcessorFast

from ...image_processing_utils_fast import DefaultFastImageProcessorKwargs
from ...image_utils import ImageInput, SizeDict
from ...processing_utils import Unpack
from ...utils import is_torch_available, is_torchvision_v2_available

"""Fast Image processor class for OWLv2."""
if is_torch_available(): ...
if is_torchvision_v2_available(): ...

class Owlv2FastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    do_pad: bool | None

class Owlv2ImageProcessorFast(OwlViTImageProcessorFast):
    resample = ...
    image_mean = ...
    image_std = ...
    size = ...
    rescale_factor = ...
    do_resize = ...
    do_rescale = ...
    do_normalize = ...
    do_pad = ...
    valid_kwargs = Owlv2FastImageProcessorKwargs
    crop_size = ...
    do_center_crop = ...
    def __init__(self, **kwargs: Unpack[Owlv2FastImageProcessorKwargs]) -> None: ...
    def preprocess(self, images: ImageInput, **kwargs: Unpack[Owlv2FastImageProcessorKwargs]):  # -> BatchFeature:
        ...
    def pad(
        self, images: list[torch.Tensor], disable_grouping: bool | None, constant_value: float = ...
    ) -> list[torch.Tensor]: ...
    def resize(
        self, image: torch.Tensor, size: SizeDict, anti_aliasing: bool = ..., anti_aliasing_sigma=..., **kwargs
    ) -> torch.Tensor: ...

__all__ = ["Owlv2ImageProcessorFast"]
