"""
This type stub file was generated by pyright.
"""

import abc
import torch
from collections.abc import Mapping
from dataclasses import dataclass
from typing import Any, Callable, Optional, TypeAlias, Union
from torch import nn
from ...modeling_outputs import BaseModelOutputWithCrossAttentions
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput, auto_docstring
from .configuration_perceiver import PerceiverConfig

ModalitySizeType: TypeAlias = Mapping[str, int]
PreprocessorOutputType: TypeAlias = tuple[torch.Tensor, Optional[torch.Tensor], torch.Tensor]
PreprocessorType: TypeAlias = Callable[..., PreprocessorOutputType]
PostprocessorType: TypeAlias = Callable[..., Any]
logger = ...

@dataclass
@auto_docstring(custom_intro=...)
class PerceiverModelOutput(ModelOutput):
    logits: Optional[torch.FloatTensor] = ...
    last_hidden_state: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...
    cross_attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class PerceiverDecoderOutput(ModelOutput):
    logits: Optional[torch.FloatTensor] = ...
    cross_attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class PerceiverMaskedLMOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...
    cross_attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class PerceiverClassifierOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...
    cross_attentions: Optional[tuple[torch.FloatTensor]] = ...

class PerceiverEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, batch_size: int): ...

class PerceiverSelfAttention(nn.Module):
    def __init__(
        self, config, is_cross_attention=..., qk_channels=..., v_channels=..., num_heads=..., q_dim=..., kv_dim=...
    ) -> None: ...
    def transpose_for_scores(self, x, channels_per_head): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.FloatTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs: Optional[torch.FloatTensor] = ...,
        inputs_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> tuple[torch.Tensor]: ...

class PerceiverSelfOutput(nn.Module):
    def __init__(self, config, input_channels, output_channels) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class PerceiverAttention(nn.Module):
    def __init__(
        self,
        config,
        is_cross_attention=...,
        qk_channels=...,
        v_channels=...,
        num_heads=...,
        q_dim=...,
        kv_dim=...,
        use_query_residual=...,
    ) -> None: ...
    def prune_heads(self, heads): ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.FloatTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs: Optional[torch.FloatTensor] = ...,
        inputs_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> tuple[torch.Tensor]: ...

class PerceiverMLP(nn.Module):
    def __init__(self, config, input_size, widening_factor) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class PerceiverLayer(nn.Module):
    def __init__(
        self,
        config,
        is_cross_attention=...,
        qk_channels=...,
        v_channels=...,
        num_heads=...,
        q_dim=...,
        kv_dim=...,
        widening_factor=...,
        use_query_residual=...,
    ) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.FloatTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs: Optional[torch.FloatTensor] = ...,
        inputs_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> tuple[torch.Tensor]: ...
    def feed_forward_chunk(self, attention_output): ...

class PerceiverEncoder(nn.Module):
    def __init__(self, config, kv_dim=...) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.FloatTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        inputs: Optional[torch.FloatTensor] = ...,
        inputs_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutputWithCrossAttentions]: ...

@auto_docstring
class PerceiverPreTrainedModel(PreTrainedModel):
    config: PerceiverConfig
    base_model_prefix = ...
    main_input_name = ...

@auto_docstring(custom_intro=...)
class PerceiverModel(PerceiverPreTrainedModel):
    def __init__(
        self,
        config,
        decoder: Optional[PerceiverAbstractDecoder] = ...,
        input_preprocessor: PreprocessorType = ...,
        output_postprocessor: PostprocessorType = ...,
    ) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    @auto_docstring
    def forward(
        self,
        inputs: torch.FloatTensor,
        attention_mask: Optional[torch.FloatTensor] = ...,
        subsampled_output_points: Optional[dict[str, torch.Tensor]] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        interpolate_pos_encoding: bool = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, PerceiverModelOutput]: ...

@auto_docstring(custom_intro=...)
class PerceiverForMaskedLM(PerceiverPreTrainedModel):
    def __init__(self, config: PerceiverConfig) -> None: ...
    @auto_docstring
    def forward(
        self,
        inputs: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        return_dict: Optional[bool] = ...,
        input_ids: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, PerceiverMaskedLMOutput]: ...

@auto_docstring(custom_intro=...)
class PerceiverForSequenceClassification(PerceiverPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        inputs: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        return_dict: Optional[bool] = ...,
        input_ids: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, PerceiverClassifierOutput]: ...

@auto_docstring(custom_intro=...)
class PerceiverForImageClassificationLearned(PerceiverPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        inputs: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        interpolate_pos_encoding: bool = ...,
        return_dict: Optional[bool] = ...,
        pixel_values: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, PerceiverClassifierOutput]: ...

@auto_docstring(custom_intro=...)
class PerceiverForImageClassificationFourier(PerceiverPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        inputs: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        return_dict: Optional[bool] = ...,
        pixel_values: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, PerceiverClassifierOutput]: ...

@auto_docstring(custom_intro=...)
class PerceiverForImageClassificationConvProcessing(PerceiverPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        inputs: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        return_dict: Optional[bool] = ...,
        pixel_values: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, PerceiverClassifierOutput]: ...

@auto_docstring(custom_intro=...)
class PerceiverForOpticalFlow(PerceiverPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        inputs: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, PerceiverClassifierOutput]: ...

@auto_docstring(custom_intro=...)
class PerceiverForMultimodalAutoencoding(PerceiverPreTrainedModel):
    def __init__(self, config: PerceiverConfig) -> None: ...
    @auto_docstring
    def forward(
        self,
        inputs: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        subsampled_output_points: Optional[dict[str, torch.Tensor]] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, PerceiverClassifierOutput]: ...

def build_position_encoding(
    position_encoding_type,
    out_channels=...,
    project_pos_dim=...,
    trainable_position_encoding_kwargs=...,
    fourier_position_encoding_kwargs=...,
): ...

class PerceiverAbstractDecoder(nn.Module, metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def decoder_query(self, inputs, modality_sizes=..., inputs_without_pos=..., subsampled_points=...): ...
    @property
    @abc.abstractmethod
    def num_query_channels(self): ...
    @abc.abstractmethod
    def forward(self, query, z, query_mask=...): ...

class PerceiverProjectionDecoder(PerceiverAbstractDecoder):
    def __init__(self, config) -> None: ...
    def decoder_query(self, inputs, modality_sizes=..., inputs_without_pos=..., subsampled_points=...): ...
    def forward(
        self, query: torch.Tensor, z: torch.FloatTensor, query_mask: Optional[torch.FloatTensor] = ...
    ) -> torch.FloatTensor: ...

class PerceiverBasicDecoder(PerceiverAbstractDecoder):
    def __init__(
        self,
        config: PerceiverConfig,
        output_num_channels: int,
        position_encoding_type: Optional[str] = ...,
        output_index_dims: Optional[int] = ...,
        num_channels: Optional[int] = ...,
        subsampled_index_dims: Optional[int] = ...,
        qk_channels: Optional[int] = ...,
        v_channels: Optional[int] = ...,
        num_heads: Optional[int] = ...,
        widening_factor: Optional[int] = ...,
        use_query_residual: Optional[bool] = ...,
        concat_preprocessed_input: Optional[bool] = ...,
        final_project: Optional[bool] = ...,
        position_encoding_only: Optional[bool] = ...,
        **position_encoding_kwargs,
    ) -> None: ...
    @property
    def num_query_channels(self) -> int: ...
    def decoder_query(self, inputs, modality_sizes=..., inputs_without_pos=..., subsampled_points=...): ...
    def forward(
        self,
        query: torch.Tensor,
        z: torch.FloatTensor,
        query_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> PerceiverDecoderOutput: ...

class PerceiverClassificationDecoder(PerceiverAbstractDecoder):
    def __init__(self, config, **decoder_kwargs) -> None: ...
    @property
    def num_query_channels(self) -> int: ...
    def decoder_query(self, inputs, modality_sizes=..., inputs_without_pos=..., subsampled_points=...): ...
    def forward(
        self,
        query: torch.Tensor,
        z: torch.FloatTensor,
        query_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> PerceiverDecoderOutput: ...

class PerceiverOpticalFlowDecoder(PerceiverAbstractDecoder):
    def __init__(
        self, config, output_image_shape, output_num_channels=..., rescale_factor=..., **decoder_kwargs
    ) -> None: ...
    @property
    def num_query_channels(self) -> int: ...
    def decoder_query(self, inputs, modality_sizes=..., inputs_without_pos=..., subsampled_points=...): ...
    def forward(
        self,
        query: torch.Tensor,
        z: torch.FloatTensor,
        query_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> PerceiverDecoderOutput: ...

class PerceiverBasicVideoAutoencodingDecoder(PerceiverAbstractDecoder):
    def __init__(
        self, config: PerceiverConfig, output_shape: list[int], position_encoding_type: str, **decoder_kwargs
    ) -> None: ...
    @property
    def num_query_channels(self) -> int: ...
    def decoder_query(self, inputs, modality_sizes=..., inputs_without_pos=..., subsampled_points=...): ...
    def forward(
        self, query: torch.Tensor, z: torch.FloatTensor, query_mask: Optional[torch.FloatTensor] = ...
    ) -> PerceiverDecoderOutput: ...

def restructure(modality_sizes: ModalitySizeType, inputs: torch.Tensor) -> Mapping[str, torch.Tensor]: ...

class PerceiverMultimodalDecoder(PerceiverAbstractDecoder):
    def __init__(
        self,
        config: PerceiverConfig,
        modalities: dict[str, PerceiverAbstractDecoder],
        num_outputs: int,
        output_num_channels: int,
        min_padding_size: Optional[int] = ...,
        subsampled_index_dims: Optional[dict[str, PerceiverAbstractDecoder]] = ...,
        **decoder_kwargs,
    ) -> None: ...
    @property
    def num_query_channels(self) -> int: ...
    def decoder_query(self, inputs, modality_sizes, inputs_without_pos=..., subsampled_points=...): ...
    def forward(
        self,
        query: torch.Tensor,
        z: torch.FloatTensor,
        query_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
    ) -> torch.Tensor: ...

def space_to_depth(
    frames: torch.Tensor, temporal_block_size: int = ..., spatial_block_size: int = ...
) -> torch.Tensor: ...

class Conv2dSamePadding(nn.Conv2d):
    def __init__(self, *args, **kwargs) -> None: ...
    def forward(self, input): ...

class Conv2DDownsample(nn.Module):
    def __init__(
        self, num_layers: int = ..., in_channels: int = ..., out_channels: int = ..., use_batchnorm: bool = ...
    ) -> None: ...
    def forward(self, inputs: torch.Tensor) -> torch.Tensor: ...

def generate_fourier_features(pos, num_bands, max_resolution=..., concat_pos=..., sine_only=...): ...
def build_linear_positions(index_dims, output_range=...): ...

class PerceiverAbstractPositionEncoding(nn.Module, metaclass=abc.ABCMeta):
    @property
    @abc.abstractmethod
    def num_dimensions(self) -> int: ...
    @abc.abstractmethod
    def output_size(self, *args, **kwargs) -> int: ...
    @abc.abstractmethod
    def forward(self, batch_size, pos): ...

class PerceiverTrainablePositionEncoding(PerceiverAbstractPositionEncoding):
    def __init__(self, index_dims, num_channels=...) -> None: ...
    @property
    def num_dimensions(self) -> int: ...
    def output_size(self, *args, **kwargs) -> int: ...
    def interpolate_pos_encoding(self, position_embeddings: torch.Tensor, height: int, width: int) -> torch.Tensor: ...
    def forward(
        self, batch_size: int, interpolate_pos_encoding: bool = ..., input_size: torch.Size = ...
    ) -> torch.Tensor: ...

class PerceiverFourierPositionEncoding(PerceiverAbstractPositionEncoding):
    def __init__(self, num_bands, max_resolution, concat_pos=..., sine_only=...) -> None: ...
    @property
    def num_dimensions(self) -> int: ...
    def output_size(self): ...
    def forward(
        self,
        index_dims: list[int],
        batch_size: int,
        device: torch.device,
        dtype: torch.dtype,
        pos: Optional[torch.FloatTensor] = ...,
    ) -> torch.FloatTensor: ...

class AbstractPreprocessor(nn.Module):
    @property
    def num_channels(self) -> int: ...

class PerceiverTextPreprocessor(AbstractPreprocessor):
    def __init__(self, config: PerceiverConfig) -> None: ...
    @property
    def num_channels(self) -> int: ...
    def forward(
        self,
        inputs: torch.LongTensor,
        pos: Optional[torch.Tensor] = ...,
        network_input_is_1d: bool = ...,
        interpolate_pos_encoding: bool = ...,
    ): ...

class PerceiverEmbeddingDecoder(nn.Module):
    def __init__(self, config: PerceiverConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor, embedding_layer: torch.Tensor) -> torch.Tensor: ...

class PerceiverMultimodalPostprocessor(nn.Module):
    def __init__(self, modalities: Mapping[str, PostprocessorType], input_is_dict: bool = ...) -> None: ...
    def forward(
        self, inputs: torch.Tensor, pos: Optional[torch.Tensor] = ..., modality_sizes=...
    ) -> Mapping[str, torch.Tensor]: ...

class PerceiverClassificationPostprocessor(nn.Module):
    def __init__(self, config: PerceiverConfig, in_channels: int) -> None: ...
    def forward(self, inputs, pos: Optional[torch.Tensor] = ..., modality_sizes=...) -> torch.Tensor: ...

class PerceiverAudioPostprocessor(nn.Module):
    def __init__(self, config: PerceiverConfig, in_channels: int, postproc_type: str = ...) -> None: ...
    def forward(self, inputs: torch.Tensor, pos: Optional[torch.Tensor] = ..., modality_sizes=...) -> torch.Tensor: ...

class PerceiverProjectionPostprocessor(nn.Module):
    def __init__(self, in_channels: int, out_channels: int) -> None: ...
    def forward(self, inputs: torch.Tensor, pos: Optional[torch.Tensor] = ..., modality_sizes=...) -> torch.Tensor: ...

class PerceiverImagePreprocessor(AbstractPreprocessor):
    def __init__(
        self,
        config,
        prep_type=...,
        spatial_downsample: int = ...,
        temporal_downsample: int = ...,
        position_encoding_type: str = ...,
        in_channels: int = ...,
        out_channels: int = ...,
        conv_after_patching: bool = ...,
        conv_after_patching_in_channels: int = ...,
        conv2d_use_batchnorm: bool = ...,
        concat_or_add_pos: str = ...,
        project_pos_dim: int = ...,
        **position_encoding_kwargs,
    ) -> None: ...
    @property
    def num_channels(self) -> int: ...
    def forward(
        self,
        inputs: torch.Tensor,
        pos: Optional[torch.Tensor] = ...,
        network_input_is_1d: bool = ...,
        interpolate_pos_encoding: bool = ...,
    ): ...

class PerceiverOneHotPreprocessor(AbstractPreprocessor):
    def __init__(self, config: PerceiverConfig) -> None: ...
    @property
    def num_channels(self) -> int: ...
    def forward(self, inputs: torch.Tensor, pos: Optional[torch.Tensor] = ..., network_input_is_1d: bool = ...): ...

class PerceiverAudioPreprocessor(AbstractPreprocessor):
    def __init__(
        self,
        config,
        prep_type: str = ...,
        samples_per_patch: int = ...,
        position_encoding_type: str = ...,
        concat_or_add_pos: str = ...,
        out_channels=...,
        project_pos_dim=...,
        **position_encoding_kwargs,
    ) -> None: ...
    @property
    def num_channels(self) -> int: ...
    def forward(
        self,
        inputs: torch.Tensor,
        pos: Optional[torch.Tensor] = ...,
        network_input_is_1d: bool = ...,
        interpolate_pos_encoding: bool = ...,
    ): ...

class PerceiverMultimodalPreprocessor(AbstractPreprocessor):
    def __init__(
        self,
        modalities: Mapping[str, PreprocessorType],
        mask_probs: Optional[Mapping[str, float]] = ...,
        min_padding_size: int = ...,
    ) -> None: ...
    @property
    def num_channels(self) -> int: ...
    def forward(
        self,
        inputs: Mapping[str, torch.Tensor],
        pos: Optional[torch.Tensor] = ...,
        network_input_is_1d: bool = ...,
        interpolate_pos_encoding: bool = ...,
    ) -> PreprocessorOutputType: ...

__all__ = [
    "PerceiverForImageClassificationConvProcessing",
    "PerceiverForImageClassificationFourier",
    "PerceiverForImageClassificationLearned",
    "PerceiverForMaskedLM",
    "PerceiverForMultimodalAutoencoding",
    "PerceiverForOpticalFlow",
    "PerceiverForSequenceClassification",
    "PerceiverLayer",
    "PerceiverModel",
    "PerceiverPreTrainedModel",
]
