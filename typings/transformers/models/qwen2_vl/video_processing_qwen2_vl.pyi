"""
This type stub file was generated by pyright.
"""

import torch
from typing import Optional, Union
from ...processing_utils import Unpack, VideosKwargs
from ...utils import add_start_docstrings, is_torch_available, is_torchvision_available, is_vision_available
from ...utils.import_utils import requires
from ...video_processing_utils import BASE_VIDEO_PROCESSOR_DOCSTRING, BaseVideoProcessor
from ...video_utils import VideoMetadata

if is_vision_available(): ...
if is_torchvision_available(): ...
if is_torch_available(): ...

class Qwen2VLVideoProcessorInitKwargs(VideosKwargs):
    min_pixels: Optional[int]
    max_pixels: Optional[int]
    patch_size: Optional[int]
    temporal_patch_size: Optional[int]
    merge_size: Optional[int]
    min_frames: Optional[int]
    max_frames: Optional[int]
    ...

@add_start_docstrings(..., BASE_VIDEO_PROCESSOR_DOCSTRING, ...)
@requires(backends=("torchvision",))
class Qwen2VLVideoProcessor(BaseVideoProcessor):
    resample = ...
    size = ...
    image_mean = ...
    image_std = ...
    do_resize = ...
    do_rescale = ...
    do_normalize = ...
    do_convert_rgb = ...
    min_pixels = ...
    max_pixels = ...
    patch_size = ...
    temporal_patch_size = ...
    merge_size = ...
    min_frames = ...
    max_frames = ...
    do_sample_frames = ...
    valid_kwargs = Qwen2VLVideoProcessorInitKwargs
    model_input_names = ...
    def __init__(self, **kwargs: Unpack[Qwen2VLVideoProcessorInitKwargs]) -> None: ...
    def sample_frames(
        self,
        video: torch.Tensor,
        frame_factor: int,
        min_frames: int,
        max_frames: int,
        metadata: Optional[Union[VideoMetadata, dict]] = ...,
        num_frames: Optional[int] = ...,
        fps: Optional[Union[int, float]] = ...,
    ): ...
    def get_num_of_video_patches(self, num_frames: int, height: int, width: int, videos_kwargs=...): ...

__all__ = ["Qwen2VLVideoProcessor"]
