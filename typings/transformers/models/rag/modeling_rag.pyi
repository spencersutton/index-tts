"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Callable, Optional, Union
from ...cache_utils import Cache
from ...configuration_utils import PretrainedConfig
from ...generation import GenerationConfig, GenerationMixin, LogitsProcessorList, StoppingCriteriaList
from ...modeling_outputs import ModelOutput
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_rag import RagConfig
from .retrieval_rag import RagRetriever

logger = ...

@dataclass
@auto_docstring(custom_intro=...)
class RetrievAugLMMarginOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    doc_scores: Optional[torch.FloatTensor] = ...
    past_key_values: Optional[Cache] = ...
    retrieved_doc_embeds: Optional[torch.FloatTensor] = ...
    retrieved_doc_ids: Optional[torch.LongTensor] = ...
    context_input_ids: Optional[torch.LongTensor] = ...
    context_attention_mask: Optional[torch.LongTensor] = ...
    question_encoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    question_enc_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    question_enc_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_enc_last_hidden_state: Optional[torch.FloatTensor] = ...
    generator_enc_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_enc_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_dec_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_dec_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_cross_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...

@dataclass
@auto_docstring
class RetrievAugLMOutput(ModelOutput):
    logits: Optional[torch.FloatTensor] = ...
    doc_scores: Optional[torch.FloatTensor] = ...
    past_key_values: Optional[Cache] = ...
    retrieved_doc_embeds: Optional[torch.FloatTensor] = ...
    retrieved_doc_ids: Optional[torch.LongTensor] = ...
    context_input_ids: Optional[torch.LongTensor] = ...
    context_attention_mask: Optional[torch.LongTensor] = ...
    question_encoder_last_hidden_state: Optional[torch.FloatTensor] = ...
    question_enc_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    question_enc_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_enc_last_hidden_state: Optional[torch.FloatTensor] = ...
    generator_enc_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_enc_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_dec_hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_dec_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...
    generator_cross_attentions: Optional[tuple[torch.FloatTensor, ...]] = ...

@auto_docstring(custom_intro=...)
@auto_docstring
class RagPreTrainedModel(PreTrainedModel):
    config: RagConfig
    base_model_prefix = ...
    _supports_flash_attn = ...
    _supports_sdpa = ...
    @classmethod
    def from_pretrained_question_encoder_generator(
        cls,
        question_encoder_pretrained_model_name_or_path: Optional[str] = ...,
        generator_pretrained_model_name_or_path: Optional[str] = ...,
        retriever: RagRetriever = ...,
        **kwargs,
    ) -> PreTrainedModel: ...

@auto_docstring
class RagModel(RagPreTrainedModel):
    def __init__(
        self,
        config: Optional[PretrainedConfig] = ...,
        question_encoder: Optional[PreTrainedModel] = ...,
        generator: Optional[PreTrainedModel] = ...,
        retriever: Optional[RagRetriever] = ...,
        **kwargs,
    ) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        encoder_outputs: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        decoder_input_ids: Optional[torch.LongTensor] = ...,
        decoder_attention_mask: Optional[torch.BoolTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        doc_scores: Optional[torch.FloatTensor] = ...,
        context_input_ids: Optional[torch.LongTensor] = ...,
        context_attention_mask: Optional[torch.LongTensor] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        output_retrieved: Optional[bool] = ...,
        n_docs: Optional[int] = ...,
    ) -> Union[tuple[torch.Tensor], RetrievAugLMOutput]: ...

@auto_docstring(custom_intro=...)
class RagSequenceForGeneration(RagPreTrainedModel):
    def __init__(
        self,
        config: Optional[PretrainedConfig] = ...,
        question_encoder: Optional[PreTrainedModel] = ...,
        generator: Optional[PreTrainedModel] = ...,
        retriever: Optional[RagRetriever] = ...,
        **kwargs,
    ) -> None: ...
    def set_retriever(self, retriever: RagRetriever): ...
    def set_context_encoder_for_training(self, ctx_encoder: PreTrainedModel): ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        encoder_outputs: Optional[tuple[tuple[torch.Tensor]]] = ...,
        decoder_input_ids: Optional[torch.LongTensor] = ...,
        decoder_attention_mask: Optional[torch.BoolTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        context_input_ids: Optional[torch.LongTensor] = ...,
        context_attention_mask: Optional[torch.LongTensor] = ...,
        doc_scores: Optional[torch.FloatTensor] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        output_retrieved: Optional[bool] = ...,
        exclude_bos_score: Optional[bool] = ...,
        reduce_loss: Optional[bool] = ...,
        labels: Optional[torch.LongTensor] = ...,
        n_docs: Optional[int] = ...,
        **kwargs,
    ) -> RetrievAugLMMarginOutput: ...
    @property
    def retriever(self): ...
    @property
    def generator(self): ...
    @property
    def question_encoder(self): ...
    @torch.no_grad()
    def generate(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        context_input_ids: Optional[torch.LongTensor] = ...,
        context_attention_mask: Optional[torch.LongTensor] = ...,
        doc_scores: Optional[torch.FloatTensor] = ...,
        do_deduplication: Optional[bool] = ...,
        num_return_sequences: Optional[int] = ...,
        num_beams: Optional[int] = ...,
        n_docs: Optional[int] = ...,
        **model_kwargs,
    ) -> torch.LongTensor: ...
    def get_nll(
        self, seq_logits, doc_scores, target, reduce_loss=..., epsilon=..., exclude_bos_score=..., n_docs=...
    ): ...

@auto_docstring(custom_intro=...)
class RagTokenForGeneration(RagPreTrainedModel, GenerationMixin):
    def __init__(
        self,
        config: Optional[PretrainedConfig] = ...,
        question_encoder: Optional[PreTrainedModel] = ...,
        generator: Optional[PreTrainedModel] = ...,
        retriever: Optional[RagRetriever] = ...,
        **kwargs,
    ) -> None: ...
    def set_retriever(self, retriever: RagRetriever): ...
    def set_context_encoder_for_training(self, ctx_encoder: PreTrainedModel): ...
    def prepare_inputs_for_generation(
        self,
        decoder_input_ids,
        past_key_values=...,
        attention_mask=...,
        use_cache=...,
        encoder_outputs=...,
        doc_scores=...,
        n_docs=...,
        **kwargs,
    ): ...
    @property
    def retriever(self): ...
    @property
    def generator(self): ...
    @property
    def question_encoder(self): ...
    def marginalize(self, seq_logits, doc_scores, n_docs=...): ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.FloatTensor] = ...,
        encoder_outputs: Optional[tuple[tuple[torch.Tensor]]] = ...,
        decoder_input_ids: Optional[torch.LongTensor] = ...,
        decoder_attention_mask: Optional[torch.BoolTensor] = ...,
        past_key_values: Optional[Cache] = ...,
        context_input_ids: Optional[torch.LongTensor] = ...,
        context_attention_mask: Optional[torch.LongTensor] = ...,
        doc_scores: Optional[torch.FloatTensor] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        output_retrieved: Optional[bool] = ...,
        do_marginalize: Optional[bool] = ...,
        reduce_loss: Optional[bool] = ...,
        labels: Optional[torch.LongTensor] = ...,
        n_docs: Optional[int] = ...,
        **kwargs,
    ) -> RetrievAugLMMarginOutput: ...
    @torch.no_grad()
    def generate(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        context_input_ids: Optional[torch.LongTensor] = ...,
        context_attention_mask: Optional[torch.LongTensor] = ...,
        doc_scores: Optional[torch.FloatTensor] = ...,
        n_docs: Optional[int] = ...,
        generation_config: Optional[GenerationConfig] = ...,
        prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], list[int]]] = ...,
        logits_processor: Optional[LogitsProcessorList] = ...,
        stopping_criteria: Optional[StoppingCriteriaList] = ...,
        **kwargs,
    ) -> torch.LongTensor: ...
    def get_input_embeddings(self): ...
    def get_output_embeddings(self): ...
    def set_output_embeddings(self, new_embeddings): ...
    def shift_tokens_right(self, input_ids, start_token_id=...): ...
    def get_nll(self, seq_logits, doc_scores, target, reduce_loss=..., epsilon=..., n_docs=...): ...

__all__ = ["RagModel", "RagPreTrainedModel", "RagSequenceForGeneration", "RagTokenForGeneration"]
