import flax.linen as nn
import jax
import jax.numpy as jnp
from flax.core.frozen_dict import FrozenDict

from ...modeling_flax_outputs import FlaxBaseModelOutputWithNoAttention, FlaxBaseModelOutputWithPoolingAndNoAttention
from ...modeling_flax_utils import FlaxPreTrainedModel
from ...utils import add_start_docstrings, add_start_docstrings_to_model_forward
from .configuration_resnet import ResNetConfig

RESNET_START_DOCSTRING = ...
RESNET_INPUTS_DOCSTRING = ...

class Identity(nn.Module):
    @nn.compact
    def __call__(self, x, **kwargs): ...

class FlaxResNetConvLayer(nn.Module):
    out_channels: int
    kernel_size: int = ...
    stride: int = ...
    activation: str | None = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, x: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetEmbeddings(nn.Module):
    config: ResNetConfig
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, pixel_values: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetShortCut(nn.Module):
    out_channels: int
    stride: int = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, x: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetBasicLayerCollection(nn.Module):
    out_channels: int
    stride: int = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, hidden_state: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetBasicLayer(nn.Module):
    in_channels: int
    out_channels: int
    stride: int = ...
    activation: str | None = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, hidden_state, deterministic: bool = ...): ...

class FlaxResNetBottleNeckLayerCollection(nn.Module):
    out_channels: int
    stride: int = ...
    activation: str | None = ...
    reduction: int = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, hidden_state: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetBottleNeckLayer(nn.Module):
    in_channels: int
    out_channels: int
    stride: int = ...
    activation: str | None = ...
    reduction: int = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, hidden_state: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetStageLayersCollection(nn.Module):
    config: ResNetConfig
    in_channels: int
    out_channels: int
    stride: int = ...
    depth: int = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, x: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetStage(nn.Module):
    config: ResNetConfig
    in_channels: int
    out_channels: int
    stride: int = ...
    depth: int = ...
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, x: jnp.ndarray, deterministic: bool = ...) -> jnp.ndarray: ...

class FlaxResNetStageCollection(nn.Module):
    config: ResNetConfig
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(
        self, hidden_state: jnp.ndarray, output_hidden_states: bool = ..., deterministic: bool = ...
    ) -> FlaxBaseModelOutputWithNoAttention: ...

class FlaxResNetEncoder(nn.Module):
    config: ResNetConfig
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(
        self,
        hidden_state: jnp.ndarray,
        output_hidden_states: bool = ...,
        return_dict: bool = ...,
        deterministic: bool = ...,
    ) -> FlaxBaseModelOutputWithNoAttention: ...

class FlaxResNetPreTrainedModel(FlaxPreTrainedModel):
    config_class = ResNetConfig
    base_model_prefix = ...
    main_input_name = ...
    module_class: nn.Module = ...
    def __init__(
        self,
        config: ResNetConfig,
        input_shape=...,
        seed: int = ...,
        dtype: jnp.dtype = ...,
        _do_init: bool = ...,
        **kwargs,
    ) -> None: ...
    def init_weights(self, rng: jax.random.PRNGKey, input_shape: tuple, params: FrozenDict = ...) -> FrozenDict: ...
    @add_start_docstrings_to_model_forward(RESNET_INPUTS_DOCSTRING)
    def __call__(
        self,
        pixel_values,
        params: dict | None = ...,
        train: bool = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ): ...

class FlaxResNetModule(nn.Module):
    config: ResNetConfig
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(
        self, pixel_values, deterministic: bool = ..., output_hidden_states: bool = ..., return_dict: bool = ...
    ) -> FlaxBaseModelOutputWithPoolingAndNoAttention: ...

@add_start_docstrings(..., RESNET_START_DOCSTRING)
class FlaxResNetModel(FlaxResNetPreTrainedModel):
    module_class = ...

FLAX_VISION_MODEL_DOCSTRING = ...

class FlaxResNetClassifierCollection(nn.Module):
    config: ResNetConfig
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(self, x: jnp.ndarray) -> jnp.ndarray: ...

class FlaxResNetForImageClassificationModule(nn.Module):
    config: ResNetConfig
    dtype: jnp.dtype = ...
    def setup(self):  # -> None:
        ...
    def __call__(
        self, pixel_values=..., deterministic: bool = ..., output_hidden_states=..., return_dict=...
    ):  # -> Any | FlaxImageClassifierOutputWithNoAttention:
        ...

@add_start_docstrings(
    ...,
    RESNET_START_DOCSTRING,
)
class FlaxResNetForImageClassification(FlaxResNetPreTrainedModel):
    module_class = ...

FLAX_VISION_CLASSIF_DOCSTRING = ...
__all__ = ["FlaxResNetForImageClassification", "FlaxResNetModel", "FlaxResNetPreTrainedModel"]
