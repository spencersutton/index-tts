"""
This type stub file was generated by pyright.
"""

import numpy as np
import torch
from typing import Optional, Union
from ...image_processing_utils import BaseImageProcessor
from ...image_utils import ChannelDimension, ImageInput, PILImageResampling
from ...utils import (
    TensorType,
    filter_out_non_signature_kwargs,
    is_tf_available,
    is_torch_available,
    is_torchvision_available,
)

if is_torch_available(): ...
if is_torchvision_available(): ...
if is_tf_available(): ...
logger = ...

class SamImageProcessor(BaseImageProcessor):
    model_input_names = ...
    def __init__(
        self,
        do_resize: bool = ...,
        size: Optional[dict[str, int]] = ...,
        mask_size: Optional[dict[str, int]] = ...,
        resample: PILImageResampling = ...,
        do_rescale: bool = ...,
        rescale_factor: float = ...,
        do_normalize: bool = ...,
        image_mean: Optional[Union[float, list[float]]] = ...,
        image_std: Optional[Union[float, list[float]]] = ...,
        do_pad: bool = ...,
        pad_size: Optional[int] = ...,
        mask_pad_size: Optional[int] = ...,
        do_convert_rgb: bool = ...,
        **kwargs,
    ) -> None: ...
    def pad_image(
        self,
        image: np.ndarray,
        pad_size: dict[str, int],
        data_format: Optional[Union[str, ChannelDimension]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        **kwargs,
    ) -> np.ndarray: ...
    def resize(
        self,
        image: np.ndarray,
        size: dict[str, int],
        resample: PILImageResampling = ...,
        data_format: Optional[Union[str, ChannelDimension]] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        **kwargs,
    ) -> np.ndarray: ...
    def __call__(self, images, segmentation_maps=..., **kwargs): ...
    @filter_out_non_signature_kwargs()
    def preprocess(
        self,
        images: ImageInput,
        segmentation_maps: Optional[ImageInput] = ...,
        do_resize: Optional[bool] = ...,
        size: Optional[dict[str, int]] = ...,
        mask_size: Optional[dict[str, int]] = ...,
        resample: Optional[PILImageResampling] = ...,
        do_rescale: Optional[bool] = ...,
        rescale_factor: Optional[Union[int, float]] = ...,
        do_normalize: Optional[bool] = ...,
        image_mean: Optional[Union[float, list[float]]] = ...,
        image_std: Optional[Union[float, list[float]]] = ...,
        do_pad: Optional[bool] = ...,
        pad_size: Optional[dict[str, int]] = ...,
        mask_pad_size: Optional[dict[str, int]] = ...,
        do_convert_rgb: Optional[bool] = ...,
        return_tensors: Optional[Union[str, TensorType]] = ...,
        data_format: ChannelDimension = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
    ): ...
    def post_process_masks(
        self,
        masks,
        original_sizes,
        reshaped_input_sizes,
        mask_threshold=...,
        binarize=...,
        pad_size=...,
        return_tensors=...,
    ): ...
    def post_process_for_mask_generation(
        self, all_masks, all_scores, all_boxes, crops_nms_thresh, return_tensors=...
    ): ...
    def generate_crop_boxes(
        self,
        image,
        target_size,
        crop_n_layers: int = ...,
        overlap_ratio: float = ...,
        points_per_crop: Optional[int] = ...,
        crop_n_points_downscale_factor: Optional[list[int]] = ...,
        device: Optional[torch.device] = ...,
        input_data_format: Optional[Union[str, ChannelDimension]] = ...,
        return_tensors: str = ...,
    ): ...
    def filter_masks(
        self,
        masks,
        iou_scores,
        original_size,
        cropped_box_image,
        pred_iou_thresh=...,
        stability_score_thresh=...,
        mask_threshold=...,
        stability_score_offset=...,
        return_tensors=...,
    ): ...

__all__ = ["SamImageProcessor"]
