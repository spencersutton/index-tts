from dataclasses import dataclass

import tensorflow as tf

from ...modeling_tf_outputs import TFBaseModelOutput
from ...modeling_tf_utils import TFModelInputType, TFPreTrainedModel, keras, unpack_inputs
from ...utils import ModelOutput, add_start_docstrings, add_start_docstrings_to_model_forward, replace_return_docstrings
from .configuration_sam import SamConfig, SamMaskDecoderConfig, SamPromptEncoderConfig, SamVisionConfig

"""
TensorFlow SAM model. This file was mostly generated by auto-translation from the PyTorch original. In the event of a
discrepancy, the original file should be regarded as the 'reference' version.
"""
logger = ...
_CONFIG_FOR_DOC = ...
_CHECKPOINT_FOR_DOC = ...

@dataclass
class TFSamVisionEncoderOutput(ModelOutput):
    image_embeds: tf.Tensor | None = ...
    last_hidden_state: tf.Tensor | None = ...
    hidden_states: tuple[tf.Tensor, ...] | None = ...
    attentions: tuple[tf.Tensor, ...] | None = ...

@dataclass
class TFSamImageSegmentationOutput(ModelOutput):
    iou_scores: tf.Tensor | None = ...
    pred_masks: tf.Tensor | None = ...
    vision_hidden_states: tuple[tf.Tensor, ...] | None = ...
    vision_attentions: tuple[tf.Tensor, ...] | None = ...
    mask_decoder_attentions: tuple[tf.Tensor, ...] | None = ...

class TFSamPatchEmbeddings(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, pixel_values): ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamMLPBlock(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def call(self, hidden_states: tf.Tensor) -> tf.Tensor: ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamLayerNorm(keras.layers.Layer):
    def __init__(self, normalized_shape, eps=..., data_format=..., **kwargs) -> None: ...
    def build(self, input_shape):  # -> None:
        ...
    def call(self, x: tf.Tensor) -> tf.Tensor: ...

class TFSamAttention(keras.layers.Layer):
    def __init__(self, config, downsample_rate=..., **kwargs) -> None: ...
    def call(self, query: tf.Tensor, key: tf.Tensor, value: tf.Tensor) -> tf.Tensor: ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamTwoWayAttentionBlock(keras.layers.Layer):
    def __init__(
        self, config, attention_downsample_rate: int = ..., skip_first_layer_pe: bool = ..., **kwargs
    ) -> None: ...
    def call(
        self,
        queries: tf.Tensor,
        keys: tf.Tensor,
        query_point_embedding: tf.Tensor,
        key_point_embedding: tf.Tensor,
        output_attentions: bool = ...,
    ):  # -> tuple[Any, Any, Any] | tuple[Any, Any, None]:
        ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamTwoWayTransformer(keras.layers.Layer):
    def __init__(self, config: SamMaskDecoderConfig, **kwargs) -> None: ...
    def call(
        self,
        point_embeddings: tf.Tensor,
        image_embeddings: tf.Tensor,
        image_positional_embeddings: tf.Tensor,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | TFBaseModelOutput: ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamFeedForward(keras.layers.Layer):
    def __init__(
        self, input_dim: int, hidden_dim: int, output_dim: int, num_layers: int, sigmoid_output: bool = ..., **kwargs
    ) -> None: ...
    def call(self, hidden_states): ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamMaskDecoder(keras.layers.Layer):
    def __init__(self, config: SamMaskDecoderConfig, **kwargs) -> None: ...
    def build(self, input_shape=...):  # -> None:
        ...
    def call(
        self,
        image_embeddings: tf.Tensor,
        image_positional_embeddings: tf.Tensor,
        sparse_prompt_embeddings: tf.Tensor,
        dense_prompt_embeddings: tf.Tensor,
        multimask_output: bool,
        output_attentions: bool | None = ...,
    ) -> tuple[tf.Tensor, tf.Tensor]: ...

class TFSamPositionalEmbedding(keras.layers.Layer):
    def __init__(self, config, **kwargs) -> None: ...
    def build(self, input_shape):  # -> None:
        ...
    def call(self, input_coords, input_shape=...): ...

class TFSamMaskEmbedding(keras.layers.Layer):
    def __init__(self, config: SamPromptEncoderConfig, **kwargs) -> None: ...
    def call(self, masks): ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamPromptEncoder(keras.layers.Layer):
    def __init__(self, config: SamPromptEncoderConfig, shared_patch_embedding, **kwargs) -> None: ...
    def build(self, input_shape=...):  # -> None:
        ...
    def call(
        self,
        batch_size: int | None,
        input_points: tuple[tf.Tensor, tf.Tensor] | None,
        input_labels: tf.Tensor | None,
        input_boxes: tf.Tensor | None,
        input_masks: tf.Tensor | None,
    ) -> tuple[tf.Tensor, tf.Tensor]: ...

class TFSamVisionAttention(keras.layers.Layer):
    def __init__(self, config, window_size, **kwargs) -> None: ...
    def build(self, input_shape=...):  # -> None:
        ...
    def get_rel_pos(self, q_size: int, k_size: int, rel_pos: tf.Tensor) -> tf.Tensor: ...
    def get_decomposed_rel_pos(
        self,
        query: tf.Tensor,
        rel_pos_h: tf.Tensor,
        rel_pos_w: tf.Tensor,
        q_size: tuple[int, int],
        k_size: tuple[int, int],
    ) -> tf.Tensor: ...
    def call(self, hidden_states: tf.Tensor, output_attentions=..., training=...) -> tf.Tensor: ...

class TFSamVisionLayer(keras.layers.Layer):
    def __init__(self, config, window_size, **kwargs) -> None: ...
    def window_partition(self, hidden_states: tf.Tensor, window_size: int) -> tuple[tf.Tensor, tuple[int, int]]: ...
    def window_unpartition(
        self, windows: tf.Tensor, window_size: int, padding_shape: tuple[int, int], original_shape: tuple[int, int]
    ) -> tf.Tensor: ...
    def call(
        self, hidden_states: tf.Tensor, output_attentions: bool | None = ..., training: bool | None = ...
    ) -> tuple[tf.Tensor]: ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamVisionNeck(keras.layers.Layer):
    def __init__(self, config: SamVisionConfig, **kwargs) -> None: ...
    def call(self, hidden_states): ...
    def build(self, input_shape=...):  # -> None:
        ...

class TFSamVisionEncoder(keras.layers.Layer):
    def __init__(self, config: SamVisionConfig, **kwargs) -> None: ...
    def build(self, input_shape=...):  # -> None:
        ...
    def get_input_embeddings(self):  # -> TFSamPatchEmbeddings:
        ...
    def call(
        self,
        pixel_values: tf.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool | None = ...,
    ) -> tuple | TFSamVisionEncoderOutput: ...

class TFSamPreTrainedModel(TFPreTrainedModel):
    config_class = SamConfig
    base_model_prefix = ...
    main_input_name = ...

SAM_START_DOCSTRING = ...
SAM_INPUTS_DOCSTRING = ...
SAM_VISION_INPUTS_DOCSTRING = ...

@add_start_docstrings(..., SAM_START_DOCSTRING)
class TFSamVisionModel(TFSamPreTrainedModel):
    config_class = SamVisionConfig
    main_input_name = ...
    def __init__(self, config: SamVisionConfig, **kwargs) -> None: ...
    def build(self, input_shape=...):  # -> None:
        ...
    def get_input_embeddings(self):  # -> TFSamPatchEmbeddings:
        ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(SAM_VISION_INPUTS_DOCSTRING)
    @replace_return_docstrings(output_type=TFSamVisionEncoderOutput, config_class=SamVisionConfig)
    def call(
        self,
        pixel_values: TFModelInputType | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool = ...,
        **kwargs,
    ) -> TFSamVisionEncoderOutput | tuple[tf.Tensor]: ...

@add_start_docstrings(
    ...,
    " optional 2D location and bounding boxes.",
    SAM_START_DOCSTRING,
)
class TFSamModel(TFSamPreTrainedModel):
    _keys_to_ignore_on_load_missing = ...
    def __init__(self, config, **kwargs) -> None: ...
    def get_input_embeddings(self):  # -> TFSamPatchEmbeddings:
        ...
    def get_image_wide_positional_embeddings(self): ...
    def get_image_embeddings(
        self,
        pixel_values,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ): ...
    def get_prompt_embeddings(
        self,
        input_points: tf.Tensor | None = ...,
        input_labels: tf.Tensor | None = ...,
        input_boxes: tf.Tensor | None = ...,
        input_masks: tf.Tensor | None = ...,
    ): ...
    @unpack_inputs
    @add_start_docstrings_to_model_forward(SAM_INPUTS_DOCSTRING)
    def call(
        self,
        pixel_values: TFModelInputType | None = ...,
        input_points: tf.Tensor | None = ...,
        input_labels: tf.Tensor | None = ...,
        input_boxes: tf.Tensor | None = ...,
        input_masks: tf.Tensor | None = ...,
        image_embeddings: tf.Tensor | None = ...,
        multimask_output: bool = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        training: bool = ...,
        **kwargs,
    ) -> TFSamImageSegmentationOutput | tuple[tf.Tensor]: ...
    def serving_output(self, output: TFSamImageSegmentationOutput) -> TFSamImageSegmentationOutput: ...
    def build(self, input_shape=...):  # -> None:
        ...

__all__ = ["TFSamModel", "TFSamPreTrainedModel", "TFSamVisionModel"]
