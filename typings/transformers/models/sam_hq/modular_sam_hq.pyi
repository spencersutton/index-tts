"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import nn
from transformers.modeling_outputs import ModelOutput
from transformers.utils.generic import TransformersKwargs, check_model_inputs
from ...processing_utils import Unpack
from ...utils import auto_docstring
from ..sam.configuration_sam import SamConfig, SamMaskDecoderConfig, SamPromptEncoderConfig, SamVisionConfig
from ..sam.modeling_sam import (
    SamFeedForward,
    SamImageSegmentationOutput,
    SamLayerNorm,
    SamModel,
    SamPreTrainedModel,
    SamTwoWayTransformer,
    SamVisionAttention,
    SamVisionEncoder,
    SamVisionEncoderOutput,
    SamVisionLayer,
    SamVisionModel,
)

logger = ...

class SamHQPromptEncoderConfig(SamPromptEncoderConfig): ...
class SamHQVisionConfig(SamVisionConfig): ...

class SamHQMaskDecoderConfig(SamMaskDecoderConfig):
    def __init__(self, vit_dim=..., **super_kwargs) -> None: ...

class SamHQConfig(SamConfig): ...

class SamHQVisionEncoderOutput(SamVisionEncoderOutput):
    intermediate_embeddings: Optional[list[torch.FloatTensor]] = ...

@dataclass
class SamHQMMaskDecoderOutputs(ModelOutput):
    masks: torch.FloatTensor
    iou_scores: Optional[torch.FloatTensor] = ...
    mask_decoder_attentions: Optional[torch.FloatTensor] = ...

class SamHQImageSegmentationOutput(SamImageSegmentationOutput): ...
class SamHQVisionAttention(SamVisionAttention): ...
class SamHQVisionLayer(SamVisionLayer): ...
class SamHQPreTrainedModel(SamPreTrainedModel): ...

class SamHQVisionEncoder(SamVisionEncoder, SamHQPreTrainedModel):
    _can_record_outputs = ...
    @check_model_inputs
    def forward(
        self, pixel_values: Optional[torch.FloatTensor] = ..., **kwargs: Unpack[TransformersKwargs]
    ) -> Union[tuple, SamHQVisionEncoderOutput]: ...

class SamHQLayerNorm(SamLayerNorm): ...
class SamHQTwoWayTransformer(SamTwoWayTransformer): ...
class SamHQFeedForward(SamFeedForward): ...

class SamHQMaskDecoder(nn.Module):
    def __init__(self, config: SamHQMaskDecoderConfig) -> None: ...
    def forward(
        self,
        image_embeddings: torch.Tensor,
        image_positional_embeddings: torch.Tensor,
        sparse_prompt_embeddings: torch.Tensor,
        dense_prompt_embeddings: torch.Tensor,
        multimask_output: bool,
        hq_token_only: bool,
        intermediate_embeddings: Optional[list[torch.Tensor]] = ...,
        attention_similarity: Optional[torch.Tensor] = ...,
        target_embedding: Optional[torch.Tensor] = ...,
    ) -> SamHQMMaskDecoderOutputs: ...

class SamHQVisionModel(SamVisionModel): ...

@auto_docstring(custom_intro=...)
class SamHQModel(SamModel):
    _tied_weights_keys = ...
    _keys_to_ignore_on_load_missing = ...
    def __init__(self, config) -> None: ...
    @torch.no_grad()
    def get_image_embeddings(self, pixel_values): ...
    def forward(
        self,
        pixel_values: Optional[torch.FloatTensor] = ...,
        input_points: Optional[torch.FloatTensor] = ...,
        input_labels: Optional[torch.LongTensor] = ...,
        input_boxes: Optional[torch.FloatTensor] = ...,
        input_masks: Optional[torch.LongTensor] = ...,
        image_embeddings: Optional[torch.FloatTensor] = ...,
        multimask_output: bool = ...,
        hq_token_only: bool = ...,
        attention_similarity: Optional[torch.FloatTensor] = ...,
        target_embedding: Optional[torch.FloatTensor] = ...,
        intermediate_embeddings: Optional[list[torch.FloatTensor]] = ...,
        **kwargs: Unpack[TransformersKwargs],
    ) -> list[dict[str, torch.Tensor]]: ...

__all__ = [
    "SamHQVisionConfig",
    "SamHQMaskDecoderConfig",
    "SamHQPromptEncoderConfig",
    "SamHQConfig",
    "SamHQModel",
    "SamHQPreTrainedModel",
    "SamHQVisionModel",
]
