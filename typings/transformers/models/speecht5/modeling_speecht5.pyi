"""
This type stub file was generated by pyright.
"""

import torch
from typing import Optional, Union
from torch import nn
from ...cache_utils import Cache
from ...generation import GenerationMixin
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import (
    BaseModelOutput,
    BaseModelOutputWithPastAndCrossAttentions,
    Seq2SeqLMOutput,
    Seq2SeqModelOutput,
    Seq2SeqSpectrogramOutput,
)
from ...modeling_utils import EmbeddingAccessMixin, PreTrainedModel
from ...utils import auto_docstring
from .configuration_speecht5 import SpeechT5Config, SpeechT5HifiGanConfig

logger = ...
_HIDDEN_STATES_START_POSITION = ...

def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int): ...
def shift_spectrograms_right(
    input_values: torch.Tensor, reduction_factor: int = ..., attention_mask: Optional[torch.Tensor] = ...
): ...

class SpeechT5NoLayerNormConvLayer(GradientCheckpointingLayer):
    def __init__(self, config, layer_id=...) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5LayerNormConvLayer(GradientCheckpointingLayer):
    def __init__(self, config, layer_id=...) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5GroupNormConvLayer(GradientCheckpointingLayer):
    def __init__(self, config, layer_id=...) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5SinusoidalPositionalEmbedding(nn.Module):
    def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = ...) -> None: ...
    def make_weights(self, num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = ...): ...
    @staticmethod
    def get_embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = ...): ...
    @torch.no_grad()
    def forward(self, input_ids: torch.Tensor, past_key_values_length: int = ...): ...
    def create_position_ids_from_input_ids(
        self, input_ids: torch.Tensor, padding_idx: int, past_key_values_length: Optional[int] = ...
    ): ...

class SpeechT5PositionalConvEmbedding(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5ScaledPositionalEncoding(nn.Module):
    def __init__(self, dropout, dim, max_len=...) -> None: ...
    def forward(self, emb): ...

class SpeechT5RelativePositionalEncoding(torch.nn.Module):
    def __init__(self, dim, max_length=...) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5SamePadLayer(nn.Module):
    def __init__(self, num_conv_pos_embeddings) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5FeatureEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, input_values): ...

class SpeechT5FeatureProjection(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5SpeechEncoderPrenet(nn.Module):
    def __init__(self, config) -> None: ...
    def freeze_feature_encoder(self): ...
    def forward(
        self,
        input_values: torch.Tensor,
        attention_mask: Optional[torch.LongTensor] = ...,
        mask_time_indices: Optional[torch.FloatTensor] = ...,
    ): ...

class SpeechT5SpeechDecoderPrenet(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, input_values: torch.Tensor, speaker_embeddings: Optional[torch.Tensor] = ...): ...

class SpeechT5BatchNormConvLayer(nn.Module):
    def __init__(self, config, layer_id=...) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5SpeechDecoderPostnet(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor): ...
    def postnet(self, hidden_states: torch.Tensor): ...

class SpeechT5TextEncoderPrenet(nn.Module, EmbeddingAccessMixin):
    def __init__(self, config) -> None: ...
    def forward(self, input_ids: torch.Tensor): ...

class SpeechT5TextDecoderPrenet(nn.Module, EmbeddingAccessMixin):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.LongTensor] = ...,
        past_key_values: Optional[Cache] = ...,
    ): ...

class SpeechT5TextDecoderPostnet(nn.Module, EmbeddingAccessMixin):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor): ...
    def get_output_embeddings(self): ...
    def set_output_embeddings(self, new_embeddings): ...

class SpeechT5Attention(nn.Module):
    def __init__(
        self,
        embed_dim: int,
        num_heads: int,
        dropout: Optional[float] = ...,
        is_decoder: Optional[bool] = ...,
        bias: Optional[bool] = ...,
        layer_idx: Optional[bool] = ...,
    ) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        key_value_states: Optional[torch.Tensor] = ...,
        past_key_value: Optional[Cache] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        layer_head_mask: Optional[torch.Tensor] = ...,
        position_bias: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> tuple[torch.Tensor, Optional[torch.Tensor], Optional[Cache]]: ...

class SpeechT5FeedForward(nn.Module):
    def __init__(self, config, intermediate_size) -> None: ...
    def forward(self, hidden_states): ...

class SpeechT5EncoderLayer(GradientCheckpointingLayer):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        layer_head_mask: Optional[torch.Tensor] = ...,
        position_bias: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ): ...

class SpeechT5DecoderLayer(GradientCheckpointingLayer):
    def __init__(self, config: SpeechT5Config, layer_idx=...) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = ...,
        encoder_hidden_states: Optional[torch.Tensor] = ...,
        encoder_attention_mask: Optional[torch.Tensor] = ...,
        layer_head_mask: Optional[torch.Tensor] = ...,
        cross_attn_layer_head_mask: Optional[torch.Tensor] = ...,
        past_key_value: Optional[Cache] = ...,
        output_attentions: Optional[bool] = ...,
        use_cache: Optional[bool] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ): ...

@auto_docstring
class SpeechT5PreTrainedModel(PreTrainedModel):
    config: SpeechT5Config
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...

class SpeechT5Encoder(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        hidden_states: torch.FloatTensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

class SpeechT5EncoderWithSpeechPrenet(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        input_values: torch.FloatTensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

class SpeechT5EncoderWithTextPrenet(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    def forward(
        self,
        input_values: torch.FloatTensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

class SpeechT5EncoderWithoutPrenet(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        input_values: torch.FloatTensor,
        attention_mask: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

class SpeechT5Decoder(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        hidden_states: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        encoder_hidden_states: Optional[torch.FloatTensor] = ...,
        encoder_attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        past_key_values: Optional[list[torch.FloatTensor]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, BaseModelOutputWithPastAndCrossAttentions]: ...

class SpeechT5DecoderWithSpeechPrenet(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        input_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        encoder_hidden_states: Optional[torch.FloatTensor] = ...,
        encoder_attention_mask: Optional[torch.LongTensor] = ...,
        speaker_embeddings: Optional[torch.Tensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        past_key_values: Optional[list[torch.FloatTensor]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, BaseModelOutputWithPastAndCrossAttentions]: ...

class SpeechT5DecoderWithTextPrenet(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    def forward(
        self,
        input_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        encoder_hidden_states: Optional[torch.FloatTensor] = ...,
        encoder_attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        past_key_values: Optional[list[torch.FloatTensor]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, BaseModelOutputWithPastAndCrossAttentions]: ...

class SpeechT5DecoderWithoutPrenet(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        input_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        encoder_hidden_states: Optional[torch.FloatTensor] = ...,
        encoder_attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.Tensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        past_key_values: Optional[list[torch.FloatTensor]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, BaseModelOutputWithPastAndCrossAttentions]: ...

class SpeechT5GuidedMultiheadAttentionLoss(nn.Module):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self, attentions: torch.FloatTensor, input_masks: torch.BoolTensor, output_masks: torch.BoolTensor
    ) -> torch.Tensor: ...

class SpeechT5SpectrogramLoss(nn.Module):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def forward(
        self,
        attention_mask: torch.LongTensor,
        outputs_before_postnet: torch.FloatTensor,
        outputs_after_postnet: torch.FloatTensor,
        logits: torch.FloatTensor,
        labels: torch.FloatTensor,
        cross_attentions: Optional[torch.FloatTensor] = ...,
    ) -> torch.Tensor: ...

@auto_docstring(custom_intro=...)
class SpeechT5Model(SpeechT5PreTrainedModel):
    def __init__(
        self, config: SpeechT5Config, encoder: Optional[nn.Module] = ..., decoder: Optional[nn.Module] = ...
    ) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    def get_encoder(self): ...
    def get_decoder(self): ...
    def freeze_feature_encoder(self): ...
    @auto_docstring
    def forward(
        self,
        input_values: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        decoder_input_values: Optional[torch.Tensor] = ...,
        decoder_attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        decoder_head_mask: Optional[torch.FloatTensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        encoder_outputs: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        past_key_values: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        use_cache: Optional[bool] = ...,
        speaker_embeddings: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple[torch.FloatTensor], Seq2SeqModelOutput]: ...

@auto_docstring(custom_intro=...)
class SpeechT5ForSpeechToText(SpeechT5PreTrainedModel, GenerationMixin):
    _tied_weights_keys = ...
    def __init__(self, config: SpeechT5Config) -> None: ...
    def get_encoder(self): ...
    def get_decoder(self): ...
    def freeze_feature_encoder(self): ...
    def get_output_embeddings(self): ...
    def set_output_embeddings(self, new_embeddings): ...
    @auto_docstring
    def forward(
        self,
        input_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        decoder_input_ids: Optional[torch.LongTensor] = ...,
        decoder_attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        decoder_head_mask: Optional[torch.FloatTensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        encoder_outputs: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        past_key_values: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        labels: Optional[torch.LongTensor] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, Seq2SeqLMOutput]: ...

@auto_docstring(custom_intro=...)
class SpeechT5ForTextToSpeech(SpeechT5PreTrainedModel):
    main_input_name = ...
    def __init__(self, config: SpeechT5Config) -> None: ...
    @classmethod
    def can_generate(cls) -> bool: ...
    def get_encoder(self): ...
    def get_decoder(self): ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        decoder_input_values: Optional[torch.FloatTensor] = ...,
        decoder_attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        decoder_head_mask: Optional[torch.FloatTensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        encoder_outputs: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        past_key_values: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        speaker_embeddings: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.FloatTensor] = ...,
        stop_labels: Optional[torch.Tensor] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, Seq2SeqSpectrogramOutput]: ...
    @torch.no_grad()
    def generate(
        self,
        input_ids: torch.LongTensor,
        attention_mask: Optional[torch.LongTensor] = ...,
        speaker_embeddings: Optional[torch.FloatTensor] = ...,
        threshold: float = ...,
        minlenratio: float = ...,
        maxlenratio: float = ...,
        vocoder: Optional[nn.Module] = ...,
        output_cross_attentions: bool = ...,
        return_output_lengths: bool = ...,
        **kwargs,
    ) -> Union[torch.FloatTensor, tuple[torch.FloatTensor, torch.FloatTensor]]: ...
    @torch.no_grad()
    def generate_speech(
        self,
        input_ids: torch.LongTensor,
        speaker_embeddings: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        threshold: float = ...,
        minlenratio: float = ...,
        maxlenratio: float = ...,
        vocoder: Optional[nn.Module] = ...,
        output_cross_attentions: bool = ...,
        return_output_lengths: bool = ...,
    ) -> Union[torch.FloatTensor, tuple[torch.FloatTensor, torch.FloatTensor]]: ...

@auto_docstring(custom_intro=...)
class SpeechT5ForSpeechToSpeech(SpeechT5PreTrainedModel):
    def __init__(self, config: SpeechT5Config) -> None: ...
    def get_encoder(self): ...
    def get_decoder(self): ...
    def freeze_feature_encoder(self): ...
    @auto_docstring
    def forward(
        self,
        input_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        decoder_input_values: Optional[torch.FloatTensor] = ...,
        decoder_attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        decoder_head_mask: Optional[torch.FloatTensor] = ...,
        cross_attn_head_mask: Optional[torch.Tensor] = ...,
        encoder_outputs: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        past_key_values: Optional[tuple[tuple[torch.FloatTensor]]] = ...,
        use_cache: Optional[bool] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        speaker_embeddings: Optional[torch.FloatTensor] = ...,
        labels: Optional[torch.FloatTensor] = ...,
        stop_labels: Optional[torch.Tensor] = ...,
        cache_position: Optional[torch.Tensor] = ...,
    ) -> Union[tuple, Seq2SeqSpectrogramOutput]: ...
    @torch.no_grad()
    def generate_speech(
        self,
        input_values: torch.FloatTensor,
        speaker_embeddings: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        threshold: float = ...,
        minlenratio: float = ...,
        maxlenratio: float = ...,
        vocoder: Optional[nn.Module] = ...,
        output_cross_attentions: bool = ...,
        return_output_lengths: bool = ...,
    ) -> torch.FloatTensor: ...

class HifiGanResidualBlock(nn.Module):
    def __init__(self, channels, kernel_size=..., dilation=..., leaky_relu_slope=...) -> None: ...
    def get_padding(self, kernel_size, dilation=...): ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    def forward(self, hidden_states): ...

@auto_docstring(
    custom_intro="""
    HiFi-GAN vocoder.
    """
)
class SpeechT5HifiGan(PreTrainedModel):
    config: SpeechT5HifiGanConfig
    main_input_name = ...
    def __init__(self, config: SpeechT5HifiGanConfig) -> None: ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    @auto_docstring(custom_intro=...)
    def forward(self, spectrogram: torch.FloatTensor) -> torch.FloatTensor: ...

__all__ = [
    "SpeechT5ForSpeechToText",
    "SpeechT5ForSpeechToSpeech",
    "SpeechT5ForTextToSpeech",
    "SpeechT5Model",
    "SpeechT5PreTrainedModel",
    "SpeechT5HifiGan",
]
