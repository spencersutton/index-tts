"""
This type stub file was generated by pyright.
"""

import torch
from typing import Optional, Union
from torch import nn
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutput, ImageClassifierOutput
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_timesformer import TimesformerConfig

logger = ...

class TimesformerPatchEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values): ...

class TimesformerEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values): ...

def drop_path(input: torch.Tensor, drop_prob: float = ..., training: bool = ...) -> torch.Tensor: ...

class TimeSformerDropPath(nn.Module):
    def __init__(self, drop_prob: Optional[float] = ...) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...
    def extra_repr(self) -> str: ...

class TimesformerSelfAttention(nn.Module):
    def __init__(self, config: TimesformerConfig) -> None: ...
    def forward(self, hidden_states, output_attentions: bool = ...): ...

class TimesformerSelfOutput(nn.Module):
    def __init__(self, config: TimesformerConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class TimeSformerAttention(nn.Module):
    def __init__(self, config: TimesformerConfig) -> None: ...
    def forward(
        self, hidden_states: torch.Tensor, output_attentions: bool = ...
    ) -> Union[tuple[torch.Tensor, torch.Tensor], tuple[torch.Tensor]]: ...

class TimesformerIntermediate(nn.Module):
    def __init__(self, config: TimesformerConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class TimesformerOutput(nn.Module):
    def __init__(self, config: TimesformerConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class TimesformerLayer(GradientCheckpointingLayer):
    def __init__(self, config: TimesformerConfig, layer_index: int) -> None: ...
    def forward(self, hidden_states: torch.Tensor, output_attentions: bool = ...): ...

class TimesformerEncoder(nn.Module):
    def __init__(self, config: TimesformerConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        output_attentions: bool = ...,
        output_hidden_states: bool = ...,
        return_dict: bool = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

@auto_docstring
class TimesformerPreTrainedModel(PreTrainedModel):
    config: TimesformerConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...
    _no_split_modules = ...

@auto_docstring
class TimesformerModel(TimesformerPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    @auto_docstring
    def forward(
        self,
        pixel_values: torch.FloatTensor,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.FloatTensor], BaseModelOutput]: ...

@auto_docstring(custom_intro=...)
class TimesformerForVideoClassification(TimesformerPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Optional[torch.Tensor] = ...,
        labels: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, ImageClassifierOutput]: ...

__all__ = ["TimesformerModel", "TimesformerForVideoClassification", "TimesformerPreTrainedModel"]
