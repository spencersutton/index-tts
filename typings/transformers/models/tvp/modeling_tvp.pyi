"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional
from torch import nn
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import ModelOutput
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_tvp import TvpConfig

logger = ...

@dataclass
@auto_docstring
class TvpVideoGroundingOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor, ...]] = ...
    attentions: Optional[tuple[torch.FloatTensor, ...]] = ...

class TvpLoss(nn.Module):
    def __init__(self, losses) -> None: ...
    def loss_iou(self, start_time, end_time, candidates_start_time, candidates_end_time, duration): ...
    def loss_distance(self, start_time, end_time, candidates_start_time, candidates_end_time, duration): ...
    def loss_duration(self, start_time, end_time, candidates_start_time, candidates_end_time, duration): ...
    def forward(self, logits, labels): ...

class TvpVisionModel(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values): ...

class TvpVisualInputEmbedding(nn.Module):
    def __init__(self, config) -> None: ...
    def interpolate_pos_encoding(self, embedding: torch.Tensor, height: int, width: int) -> torch.Tensor: ...
    def add_2d_positional_embeddings(self, grid, interpolate_pos_encoding: bool = ...): ...
    def forward(self, grid, interpolate_pos_encoding: bool = ...): ...

class TvpTextInputEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, input_ids=..., token_type_ids=..., position_ids=..., inputs_embeds=...): ...

class TvpAttention(nn.Module):
    def __init__(self, config) -> None: ...
    def prune_heads(self, heads): ...
    def forward(self, hidden_states, attention_mask=..., head_mask=..., output_attentions: Optional[bool] = ...): ...

class TvpIntermediate(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class TvpOutputLayer(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class TvpEncodeLayer(GradientCheckpointingLayer):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states, attention_mask=..., head_mask=..., output_attentions: Optional[bool] = ...): ...

class TvpEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        hidden_states,
        attention_mask=...,
        head_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ): ...

class TvpPooler(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

@auto_docstring
class TvpPreTrainedModel(PreTrainedModel):
    config: TvpConfig
    base_model_prefix = ...
    supports_gradient_checkpointing = ...

class TvpFrameDownPadPrompter(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values): ...

class TvpFramePadPrompter(nn.Module):
    def __init__(self, config) -> None: ...
    def interpolate_pad_encoding(self, prompt: torch.Tensor, height: int, width: int) -> torch.Tensor: ...
    def forward(self, pixel_values, interpolate_pad_encoding: bool = ...): ...

TVP_PROMPTER_CLASSES_MAPPING = ...

@auto_docstring(custom_intro=...)
class TvpModel(TvpPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, value): ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        pixel_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        interpolate_pos_encoding: bool = ...,
    ): ...

class TvpVideoGroundingHead(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pooler_output): ...

@auto_docstring(custom_intro=...)
class TvpForVideoGrounding(TvpPreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.LongTensor] = ...,
        pixel_values: Optional[torch.FloatTensor] = ...,
        attention_mask: Optional[torch.LongTensor] = ...,
        labels: Optional[tuple[torch.Tensor]] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        interpolate_pos_encoding: bool = ...,
    ): ...

__all__ = ["TvpModel", "TvpPreTrainedModel", "TvpForVideoGrounding"]
