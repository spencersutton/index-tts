from dataclasses import dataclass

import torch

from ...modeling_outputs import ModelOutput, Wav2Vec2BaseModelOutput
from ...modeling_utils import PreTrainedModel
from ..wav2vec2.modeling_wav2vec2 import (
    Wav2Vec2Encoder,
    Wav2Vec2EncoderStableLayerNorm,
    Wav2Vec2FeatureEncoder,
    Wav2Vec2FeatureProjection,
    Wav2Vec2ForAudioFrameClassification,
    Wav2Vec2ForCTC,
    Wav2Vec2ForSequenceClassification,
    Wav2Vec2ForXVector,
    Wav2Vec2GumbelVectorQuantizer,
    Wav2Vec2Model,
    Wav2Vec2PositionalConvEmbedding,
)
from .configuration_unispeech_sat import UniSpeechSatConfig

"""PyTorch UniSpeechSat model."""
logger = ...
_HIDDEN_STATES_START_POSITION = ...

@dataclass
class UniSpeechSatForPreTrainingOutput(ModelOutput):
    loss: torch.FloatTensor | None = ...
    logits: torch.FloatTensor | None = ...
    projected_states: torch.FloatTensor | None = ...
    projected_quantized_states: torch.FloatTensor | None = ...
    codevector_perplexity: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor] | None = ...
    attentions: tuple[torch.FloatTensor] | None = ...

class UniSpeechSatPositionalConvEmbedding(Wav2Vec2PositionalConvEmbedding): ...
class UniSpeechSatFeatureEncoder(Wav2Vec2FeatureEncoder): ...
class UniSpeechSatFeatureProjection(Wav2Vec2FeatureProjection): ...
class UniSpeechSatEncoder(Wav2Vec2Encoder): ...
class UniSpeechSatEncoderStableLayerNorm(Wav2Vec2EncoderStableLayerNorm): ...

class UniSpeechSatGumbelVectorQuantizer(Wav2Vec2GumbelVectorQuantizer):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states):  # -> tuple[Tensor | Any, Tensor]:
        ...

class UniSpeechSatPreTrainedModel(PreTrainedModel):
    config: UniSpeechSatConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...
    _supports_flash_attn = ...
    _supports_sdpa = ...
    _supports_flex_attn = ...

UniSpeechSatBaseModelOutput = Wav2Vec2BaseModelOutput

class UniSpeechSatModel(UniSpeechSatPreTrainedModel, Wav2Vec2Model):
    def __init__(self, config: UniSpeechSatConfig) -> None: ...
    def freeze_feature_extractor(self): ...
    def freeze_feature_encoder(self): ...
    def forward(
        self,
        input_values: torch.Tensor | None,
        attention_mask: torch.Tensor | None = ...,
        mask_time_indices: torch.FloatTensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | UniSpeechSatBaseModelOutput: ...

class UniSpeechSatForPreTraining(UniSpeechSatPreTrainedModel):
    def __init__(self, config: UniSpeechSatConfig) -> None: ...
    def set_gumbel_temperature(self, temperature: int):  # -> None:

        ...
    def freeze_feature_extractor(self):  # -> None:

        ...
    def freeze_feature_encoder(self):  # -> None:

        ...
    @staticmethod
    def compute_contrastive_logits(
        target_features: torch.FloatTensor,
        negative_features: torch.FloatTensor,
        predicted_features: torch.FloatTensor,
        temperature: int = ...,
    ):  # -> Tensor:

        ...
    def forward(
        self,
        input_values: torch.Tensor | None,
        attention_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | UniSpeechSatForPreTrainingOutput: ...

class UniSpeechSatForCTC(Wav2Vec2ForCTC): ...
class UniSpeechSatForSequenceClassification(Wav2Vec2ForSequenceClassification): ...
class UniSpeechSatForAudioFrameClassification(Wav2Vec2ForAudioFrameClassification): ...
class UniSpeechSatForXVector(Wav2Vec2ForXVector): ...

__all__ = [
    "UniSpeechSatForAudioFrameClassification",
    "UniSpeechSatForCTC",
    "UniSpeechSatForPreTraining",
    "UniSpeechSatForSequenceClassification",
    "UniSpeechSatForXVector",
    "UniSpeechSatModel",
    "UniSpeechSatPreTrainedModel",
]
