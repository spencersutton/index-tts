from dataclasses import dataclass

import torch
from torch import nn

from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutput, ImageClassifierOutput
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput
from .configuration_videomae import VideoMAEConfig

"""PyTorch VideoMAE (masked autoencoder) model."""
logger = ...

@dataclass
class VideoMAEDecoderOutput(ModelOutput):
    logits: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor] | None = ...
    attentions: tuple[torch.FloatTensor] | None = ...

@dataclass
class VideoMAEForPreTrainingOutput(ModelOutput):
    loss: torch.FloatTensor | None = ...
    logits: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor] | None = ...
    attentions: tuple[torch.FloatTensor] | None = ...

def get_sinusoid_encoding_table(n_position, d_hid):  # -> Tensor:

    ...

class VideoMAEEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values, bool_masked_pos):  # -> Any:
        ...

class VideoMAEPatchEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values):  # -> Any:
        ...

def eager_attention_forward(
    module: nn.Module,
    query: torch.Tensor,
    key: torch.Tensor,
    value: torch.Tensor,
    attention_mask: torch.Tensor | None,
    scaling: float,
    dropout: float = ...,
    **kwargs,
):  # -> tuple[Tensor, Tensor]:
    ...

class VideoMAESelfAttention(nn.Module):
    def __init__(self, config: VideoMAEConfig) -> None: ...
    def forward(
        self, hidden_states, head_mask: torch.Tensor | None = ..., output_attentions: bool = ...
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class VideoMAESelfOutput(nn.Module):
    def __init__(self, config: VideoMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class VideoMAEAttention(nn.Module):
    def __init__(self, config: VideoMAEConfig) -> None: ...
    def prune_heads(self, heads: set[int]) -> None: ...
    def forward(
        self, hidden_states: torch.Tensor, head_mask: torch.Tensor | None = ..., output_attentions: bool = ...
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class VideoMAEIntermediate(nn.Module):
    def __init__(self, config: VideoMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class VideoMAEOutput(nn.Module):
    def __init__(self, config: VideoMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class VideoMAELayer(GradientCheckpointingLayer):
    def __init__(self, config: VideoMAEConfig) -> None: ...
    def forward(
        self, hidden_states: torch.Tensor, head_mask: torch.Tensor | None = ..., output_attentions: bool = ...
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class VideoMAEEncoder(nn.Module):
    def __init__(self, config: VideoMAEConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool = ...,
        output_hidden_states: bool = ...,
        return_dict: bool = ...,
    ) -> tuple | BaseModelOutput: ...

class VideoMAEPreTrainedModel(PreTrainedModel):
    config: VideoMAEConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...
    _supports_sdpa = ...
    _supports_flash_attn = ...
    _supports_flex_attn = ...
    _supports_attention_backend = ...

class VideoMAEModel(VideoMAEPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self):  # -> VideoMAEPatchEmbeddings:
        ...
    def forward(
        self,
        pixel_values: torch.FloatTensor,
        bool_masked_pos: torch.BoolTensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | BaseModelOutput: ...

class VideoMAEDecoder(nn.Module):
    def __init__(self, config, num_patches) -> None: ...
    def forward(
        self, hidden_states, return_token_num, output_attentions=..., output_hidden_states=..., return_dict=...
    ):  # -> tuple[Any | tuple[Any, ...] | tuple[()], ...] | VideoMAEDecoderOutput:
        ...

class VideoMAEForPreTraining(VideoMAEPreTrainedModel):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        pixel_values: torch.FloatTensor,
        bool_masked_pos: torch.BoolTensor,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | VideoMAEForPreTrainingOutput: ...

class VideoMAEForVideoClassification(VideoMAEPreTrainedModel):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        pixel_values: torch.Tensor | None = ...,
        head_mask: torch.Tensor | None = ...,
        labels: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | ImageClassifierOutput: ...

__all__ = ["VideoMAEForPreTraining", "VideoMAEForVideoClassification", "VideoMAEModel", "VideoMAEPreTrainedModel"]
