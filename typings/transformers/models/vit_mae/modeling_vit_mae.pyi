"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional, Union
from torch import nn
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutput
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput, auto_docstring
from .configuration_vit_mae import ViTMAEConfig

logger = ...

@dataclass
@auto_docstring(custom_intro=...)
class ViTMAEModelOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    mask: Optional[torch.LongTensor] = ...
    ids_restore: Optional[torch.LongTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class ViTMAEDecoderOutput(ModelOutput):
    logits: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class ViTMAEForPreTrainingOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = ...
    logits: Optional[torch.FloatTensor] = ...
    mask: Optional[torch.LongTensor] = ...
    ids_restore: Optional[torch.LongTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

def get_2d_sincos_pos_embed(embed_dim, grid_size, add_cls_token=...): ...
def get_2d_sincos_pos_embed_from_grid(embed_dim, grid): ...
def get_1d_sincos_pos_embed_from_grid(embed_dim, pos): ...

class ViTMAEEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def initialize_weights(self): ...
    def interpolate_pos_encoding(self, embeddings: torch.Tensor, height: int, width: int) -> torch.Tensor: ...
    def random_masking(self, sequence, noise=...): ...
    def forward(self, pixel_values, noise=..., interpolate_pos_encoding: bool = ...): ...

class ViTMAEPatchEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values, interpolate_pos_encoding: bool = ...): ...

def eager_attention_forward(
    module: nn.Module,
    query: torch.Tensor,
    key: torch.Tensor,
    value: torch.Tensor,
    attention_mask: Optional[torch.Tensor],
    scaling: float,
    dropout: float = ...,
    **kwargs,
): ...

class ViTMAESelfAttention(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(
        self, hidden_states, head_mask: Optional[torch.Tensor] = ..., output_attentions: bool = ...
    ) -> Union[tuple[torch.Tensor, torch.Tensor], tuple[torch.Tensor]]: ...

class ViTMAESelfOutput(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class ViTMAEAttention(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def prune_heads(self, heads: set[int]) -> None: ...
    def forward(
        self, hidden_states: torch.Tensor, head_mask: Optional[torch.Tensor] = ..., output_attentions: bool = ...
    ) -> Union[tuple[torch.Tensor, torch.Tensor], tuple[torch.Tensor]]: ...

class ViTMAEIntermediate(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class ViTMAEOutput(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class ViTMAELayer(GradientCheckpointingLayer):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(
        self, hidden_states: torch.Tensor, head_mask: Optional[torch.Tensor] = ..., output_attentions: bool = ...
    ) -> Union[tuple[torch.Tensor, torch.Tensor], tuple[torch.Tensor]]: ...

class ViTMAEEncoder(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        head_mask: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
        output_hidden_states: bool = ...,
        return_dict: bool = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

@auto_docstring
class ViTMAEPreTrainedModel(PreTrainedModel):
    config: ViTMAEConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...
    _supports_sdpa = ...
    _supports_flash_attn = ...
    _supports_flex_attn = ...
    _supports_attention_backend = ...

@auto_docstring
class ViTMAEModel(ViTMAEPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Optional[torch.FloatTensor] = ...,
        noise: Optional[torch.FloatTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        interpolate_pos_encoding: bool = ...,
    ) -> Union[tuple, ViTMAEModelOutput]: ...

class ViTMAEDecoder(nn.Module):
    def __init__(self, config, num_patches) -> None: ...
    def interpolate_pos_encoding(self, embeddings: torch.Tensor) -> torch.Tensor: ...
    def initialize_weights(self, num_patches): ...
    def forward(
        self,
        hidden_states,
        ids_restore,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
        interpolate_pos_encoding: bool = ...,
    ): ...

@auto_docstring(custom_intro=...)
class ViTMAEForPreTraining(ViTMAEPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    def patchify(self, pixel_values, interpolate_pos_encoding: bool = ...): ...
    def unpatchify(self, patchified_pixel_values, original_image_size: Optional[tuple[int, int]] = ...): ...
    def forward_loss(self, pixel_values, pred, mask, interpolate_pos_encoding: bool = ...): ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Optional[torch.FloatTensor] = ...,
        noise: Optional[torch.FloatTensor] = ...,
        head_mask: Optional[torch.FloatTensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        interpolate_pos_encoding: bool = ...,
    ) -> Union[tuple, ViTMAEForPreTrainingOutput]: ...

__all__ = ["ViTMAEForPreTraining", "ViTMAELayer", "ViTMAEModel", "ViTMAEPreTrainedModel"]
