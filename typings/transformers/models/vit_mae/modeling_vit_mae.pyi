from dataclasses import dataclass

import torch
from torch import nn

from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutput
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput
from .configuration_vit_mae import ViTMAEConfig

"""PyTorch ViT MAE (masked autoencoder) model."""
logger = ...

@dataclass
class ViTMAEModelOutput(ModelOutput):
    last_hidden_state: torch.FloatTensor | None = ...
    mask: torch.LongTensor | None = ...
    ids_restore: torch.LongTensor | None = ...
    hidden_states: tuple[torch.FloatTensor] | None = ...
    attentions: tuple[torch.FloatTensor] | None = ...

@dataclass
class ViTMAEDecoderOutput(ModelOutput):
    logits: torch.FloatTensor | None = ...
    hidden_states: tuple[torch.FloatTensor] | None = ...
    attentions: tuple[torch.FloatTensor] | None = ...

@dataclass
class ViTMAEForPreTrainingOutput(ModelOutput):
    loss: torch.FloatTensor | None = ...
    logits: torch.FloatTensor | None = ...
    mask: torch.LongTensor | None = ...
    ids_restore: torch.LongTensor | None = ...
    hidden_states: tuple[torch.FloatTensor] | None = ...
    attentions: tuple[torch.FloatTensor] | None = ...

def get_2d_sincos_pos_embed(embed_dim, grid_size, add_cls_token=...):  # -> NDArray[float64] | NDArray[Any]:

    ...
def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):  # -> NDArray[Any]:
    ...
def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):  # -> NDArray[Any]:

    ...

class ViTMAEEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def initialize_weights(self):  # -> None:
        ...
    def interpolate_pos_encoding(self, embeddings: torch.Tensor, height: int, width: int) -> torch.Tensor: ...
    def random_masking(self, sequence, noise=...):  # -> tuple[Tensor, Tensor, Tensor]:

        ...
    def forward(
        self, pixel_values, noise=..., interpolate_pos_encoding: bool = ...
    ):  # -> tuple[Tensor, Tensor, Tensor]:
        ...

class ViTMAEPatchEmbeddings(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values, interpolate_pos_encoding: bool = ...):  # -> Any:
        ...

def eager_attention_forward(
    module: nn.Module,
    query: torch.Tensor,
    key: torch.Tensor,
    value: torch.Tensor,
    attention_mask: torch.Tensor | None,
    scaling: float,
    dropout: float = ...,
    **kwargs,
):  # -> tuple[Tensor, Tensor]:
    ...

class ViTMAESelfAttention(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(
        self, hidden_states, head_mask: torch.Tensor | None = ..., output_attentions: bool = ...
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class ViTMAESelfOutput(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class ViTMAEAttention(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def prune_heads(self, heads: set[int]) -> None: ...
    def forward(
        self, hidden_states: torch.Tensor, head_mask: torch.Tensor | None = ..., output_attentions: bool = ...
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class ViTMAEIntermediate(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

class ViTMAEOutput(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor: ...

class ViTMAELayer(GradientCheckpointingLayer):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(
        self, hidden_states: torch.Tensor, head_mask: torch.Tensor | None = ..., output_attentions: bool = ...
    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[torch.Tensor]: ...

class ViTMAEEncoder(nn.Module):
    def __init__(self, config: ViTMAEConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        head_mask: torch.Tensor | None = ...,
        output_attentions: bool = ...,
        output_hidden_states: bool = ...,
        return_dict: bool = ...,
    ) -> tuple | BaseModelOutput: ...

class ViTMAEPreTrainedModel(PreTrainedModel):
    config: ViTMAEConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...
    _supports_sdpa = ...
    _supports_flash_attn = ...
    _supports_flex_attn = ...
    _supports_attention_backend = ...

class ViTMAEModel(ViTMAEPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self):  # -> ViTMAEPatchEmbeddings:
        ...
    def forward(
        self,
        pixel_values: torch.FloatTensor | None = ...,
        noise: torch.FloatTensor | None = ...,
        head_mask: torch.FloatTensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        interpolate_pos_encoding: bool = ...,
    ) -> tuple | ViTMAEModelOutput: ...

class ViTMAEDecoder(nn.Module):
    def __init__(self, config, num_patches) -> None: ...
    def interpolate_pos_encoding(self, embeddings: torch.Tensor) -> torch.Tensor: ...
    def initialize_weights(self, num_patches):  # -> None:
        ...
    def forward(
        self,
        hidden_states,
        ids_restore,
        output_attentions=...,
        output_hidden_states=...,
        return_dict=...,
        interpolate_pos_encoding: bool = ...,
    ):  # -> tuple[Any | tuple[Tensor | Any, ...] | tuple[()] | tuple[Any, ...], ...] | ViTMAEDecoderOutput:
        ...

class ViTMAEForPreTraining(ViTMAEPreTrainedModel):
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self):  # -> ViTMAEPatchEmbeddings:
        ...
    def patchify(self, pixel_values, interpolate_pos_encoding: bool = ...):  # -> Tensor:

        ...
    def unpatchify(self, patchified_pixel_values, original_image_size: tuple[int, int] | None = ...):  # -> Tensor:

        ...
    def forward_loss(self, pixel_values, pred, mask, interpolate_pos_encoding: bool = ...): ...
    def forward(
        self,
        pixel_values: torch.FloatTensor | None = ...,
        noise: torch.FloatTensor | None = ...,
        head_mask: torch.FloatTensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        interpolate_pos_encoding: bool = ...,
    ) -> tuple | ViTMAEForPreTrainingOutput: ...

__all__ = ["ViTMAEForPreTraining", "ViTMAELayer", "ViTMAEModel", "ViTMAEPreTrainedModel"]
