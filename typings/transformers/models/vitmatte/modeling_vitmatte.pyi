"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Optional
from torch import nn
from ...modeling_utils import PreTrainedModel
from ...utils import ModelOutput, auto_docstring
from .configuration_vitmatte import VitMatteConfig

"""PyTorch ViTMatte model."""

@dataclass
@auto_docstring(
    custom_intro="""
    Class for outputs of image matting models.
    """
)
class ImageMattingOutput(ModelOutput):
    r"""
    loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided):
        Loss.
    alphas (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):
        Estimated alpha values.
    hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):
        Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +
        one for the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`. Hidden-states
        (also called feature maps) of the model at the output of each stage.
    """

    loss: Optional[torch.FloatTensor] = ...
    alphas: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@auto_docstring
class VitMattePreTrainedModel(PreTrainedModel):
    config: VitMatteConfig
    main_input_name = ...
    supports_gradient_checkpointing = ...
    _no_split_modules = ...

class VitMatteBasicConv3x3(nn.Module):
    """
    Basic convolution layers including: Conv3x3, BatchNorm2d, ReLU layers.
    """
    def __init__(self, config, in_channels, out_channels, stride=..., padding=...) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class VitMatteConvStream(nn.Module):
    """
    Simple ConvStream containing a series of basic conv3x3 layers to extract detail features.
    """
    def __init__(self, config) -> None: ...
    def forward(self, pixel_values):  # -> dict[str, Any]:
        ...

class VitMatteFusionBlock(nn.Module):
    """
    Simple fusion block to fuse features from ConvStream and Plain Vision Transformer.
    """
    def __init__(self, config, in_channels, out_channels) -> None: ...
    def forward(self, features, detailed_feature_map):  # -> Any:
        ...

class VitMatteHead(nn.Module):
    """
    Simple Matting Head, containing only conv3x3 and conv1x1 layers.
    """
    def __init__(self, config) -> None: ...
    def forward(self, hidden_state):  # -> Any:
        ...

class VitMatteDetailCaptureModule(nn.Module):
    """
    Simple and lightweight Detail Capture Module for ViT Matting.
    """
    def __init__(self, config) -> None: ...
    def forward(self, features, pixel_values):  # -> Tensor:
        ...

@auto_docstring(
    custom_intro="""
    ViTMatte framework leveraging any vision backbone e.g. for ADE20k, CityScapes.
    """
)
class VitMatteForImageMatting(VitMattePreTrainedModel):
    def __init__(self, config) -> None: ...
    @auto_docstring
    def forward(
        self,
        pixel_values: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        labels: Optional[torch.Tensor] = ...,
        return_dict: Optional[bool] = ...,
    ):  # -> Any | ImageMattingOutput:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*):
            Ground truth image matting for computing the loss.

        Examples:

        ```python
        >>> from transformers import VitMatteImageProcessor, VitMatteForImageMatting
        >>> import torch
        >>> from PIL import Image
        >>> from huggingface_hub import hf_hub_download

        >>> processor = VitMatteImageProcessor.from_pretrained("hustvl/vitmatte-small-composition-1k")
        >>> model = VitMatteForImageMatting.from_pretrained("hustvl/vitmatte-small-composition-1k")

        >>> filepath = hf_hub_download(
        ...     repo_id="hf-internal-testing/image-matting-fixtures", filename="image.png", repo_type="dataset"
        ... )
        >>> image = Image.open(filepath).convert("RGB")
        >>> filepath = hf_hub_download(
        ...     repo_id="hf-internal-testing/image-matting-fixtures", filename="trimap.png", repo_type="dataset"
        ... )
        >>> trimap = Image.open(filepath).convert("L")

        >>> # prepare image + trimap for the model
        >>> inputs = processor(images=image, trimaps=trimap, return_tensors="pt")

        >>> with torch.no_grad():
        ...     alphas = model(**inputs).alphas
        >>> print(alphas.shape)
        torch.Size([1, 1, 640, 960])
        ```"""
        ...

__all__ = ["VitMattePreTrainedModel", "VitMatteForImageMatting"]
