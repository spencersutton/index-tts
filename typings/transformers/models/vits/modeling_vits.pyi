"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Any, Optional, Union
from torch import nn
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import BaseModelOutput, ModelOutput
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_vits import VitsConfig

logger = ...

@dataclass
@auto_docstring(custom_intro=...)
class VitsModelOutput(ModelOutput):
    waveform: Optional[torch.FloatTensor] = ...
    sequence_lengths: Optional[torch.FloatTensor] = ...
    spectrogram: Optional[tuple[torch.FloatTensor]] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@dataclass
@auto_docstring(custom_intro=...)
class VitsTextEncoderOutput(ModelOutput):
    last_hidden_state: Optional[torch.FloatTensor] = ...
    prior_means: Optional[torch.FloatTensor] = ...
    prior_log_variances: Optional[torch.FloatTensor] = ...
    hidden_states: Optional[tuple[torch.FloatTensor]] = ...
    attentions: Optional[tuple[torch.FloatTensor]] = ...

@torch.jit.script
def fused_add_tanh_sigmoid_multiply(input_a, input_b, num_channels): ...

class VitsWaveNet(torch.nn.Module):
    def __init__(self, config: VitsConfig, num_layers: int) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=...): ...
    def remove_weight_norm(self): ...

class VitsPosteriorEncoder(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=...): ...

class HifiGanResidualBlock(nn.Module):
    def __init__(self, channels, kernel_size=..., dilation=..., leaky_relu_slope=...) -> None: ...
    def get_padding(self, kernel_size, dilation=...): ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    def forward(self, hidden_states): ...

class VitsHifiGan(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def apply_weight_norm(self): ...
    def remove_weight_norm(self): ...
    def forward(
        self, spectrogram: torch.FloatTensor, global_conditioning: Optional[torch.FloatTensor] = ...
    ) -> torch.FloatTensor: ...

class VitsResidualCouplingLayer(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=..., reverse=...): ...

class VitsResidualCouplingBlock(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=..., reverse=...): ...

class VitsDilatedDepthSeparableConv(nn.Module):
    def __init__(self, config: VitsConfig, dropout_rate=...) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=...): ...

class VitsConvFlow(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=..., reverse=...): ...

class VitsElementwiseAffine(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=..., reverse=...): ...

class VitsStochasticDurationPredictor(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=..., durations=..., reverse=..., noise_scale=...): ...

class VitsDurationPredictor(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, inputs, padding_mask, global_conditioning=...): ...

class VitsAttention(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        key_value_states: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        layer_head_mask: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ) -> tuple[torch.Tensor, Optional[torch.Tensor]]: ...

class VitsFeedForward(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states, padding_mask): ...

class VitsEncoderLayer(GradientCheckpointingLayer):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        padding_mask: torch.FloatTensor,
        attention_mask: Optional[torch.Tensor] = ...,
        output_attentions: bool = ...,
    ): ...

class VitsEncoder(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(
        self,
        hidden_states: torch.FloatTensor,
        padding_mask: torch.FloatTensor,
        attention_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple, BaseModelOutput]: ...

class VitsTextEncoder(nn.Module):
    def __init__(self, config: VitsConfig) -> None: ...
    def forward(
        self,
        input_ids: torch.Tensor,
        padding_mask: torch.FloatTensor,
        attention_mask: Optional[torch.Tensor] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
    ) -> Union[tuple[torch.Tensor], VitsTextEncoderOutput]: ...

@auto_docstring
class VitsPreTrainedModel(PreTrainedModel):
    config: VitsConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...

@auto_docstring(custom_intro=...)
class VitsModel(VitsPreTrainedModel):
    def __init__(self, config: VitsConfig) -> None: ...
    def get_encoder(self): ...
    @auto_docstring
    def forward(
        self,
        input_ids: Optional[torch.Tensor] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        speaker_id: Optional[int] = ...,
        output_attentions: Optional[bool] = ...,
        output_hidden_states: Optional[bool] = ...,
        return_dict: Optional[bool] = ...,
        labels: Optional[torch.FloatTensor] = ...,
    ) -> Union[tuple[Any], VitsModelOutput]: ...

__all__ = ["VitsModel", "VitsPreTrainedModel"]
