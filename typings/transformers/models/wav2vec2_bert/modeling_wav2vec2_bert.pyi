"""
This type stub file was generated by pyright.
"""

import torch
from typing import Optional, Union
from torch import nn
from ...modeling_layers import GradientCheckpointingLayer
from ...modeling_outputs import (
    CausalLMOutput,
    SequenceClassifierOutput,
    TokenClassifierOutput,
    Wav2Vec2BaseModelOutput,
    XVectorOutput,
)
from ...modeling_utils import PreTrainedModel
from ...utils import auto_docstring
from .configuration_wav2vec2_bert import Wav2Vec2BertConfig

class Wav2Vec2BertRotaryPositionalEmbedding(nn.Module):
    """Rotary positional embedding
    Reference : https://blog.eleuther.ai/rotary-embeddings/ Paper: https://huggingface.co/papers/2104.09864
    """
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states):  # -> Tensor:
        ...

class Wav2Vec2BertRelPositionalEmbedding(nn.Module):
    """Relative positional encoding module."""
    def __init__(self, config) -> None: ...
    def extend_pe(self, x):  # -> None:
        ...
    def forward(self, hidden_states: torch.Tensor):  # -> Tensor:
        ...

class Wav2Vec2BertFeatureProjection(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states):  # -> tuple[Any, Any]:
        ...

class Wav2Vec2BertFeedForward(nn.Module):
    def __init__(self, config, act_fn=..., hidden_size=...) -> None: ...
    def forward(self, hidden_states):  # -> Any:
        ...

class Wav2Vec2BertConvolutionModule(nn.Module):
    """Convolution block used in the conformer block"""
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states, attention_mask=...):  # -> Any:
        ...

class Wav2Vec2BertSelfAttention(nn.Module):
    """Construct an Wav2Vec2BertSelfAttention object.
    Can be enhanced with rotary or relative position embeddings.
    """
    def __init__(self, config, is_adapter_attention=...) -> None: ...
    def forward(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor | None = ...,
        relative_position_embeddings: torch.Tensor | None = ...,
        output_attentions: bool = ...,
    ) -> tuple[torch.Tensor, torch.Tensor | None, tuple[torch.Tensor] | None]: ...

class Wav2Vec2BertEncoderLayer(GradientCheckpointingLayer):
    """Conformer block based on https://huggingface.co/papers/2005.08100."""
    def __init__(self, config) -> None: ...
    def forward(
        self,
        hidden_states,
        attention_mask: torch.Tensor | None = ...,
        relative_position_embeddings: torch.Tensor | None = ...,
        output_attentions: bool = ...,
        conv_attention_mask: torch.Tensor | None = ...,
    ):  # -> tuple[Any, Any]:
        ...

class Wav2Vec2BertEncoder(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self, hidden_states, attention_mask=..., output_attentions=..., output_hidden_states=..., return_dict=...
    ):  # -> tuple[Any | tuple[Any, ...] | tuple[()] | tuple[Any | None, ...], ...] | BaseModelOutput:
        ...

class Wav2Vec2BertAdapter(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states, attention_mask=...):  # -> Any:
        ...

class Wav2Vec2BertAdapterLayer(nn.Module):
    def __init__(self, config) -> None: ...
    def forward(
        self,
        hidden_states,
        attention_mask: torch.Tensor | None = ...,
        output_attentions: bool = ...,
        sub_sampled_lengths: torch.Tensor | None = ...,
    ):  # -> Any:
        ...

@auto_docstring
class Wav2Vec2BertPreTrainedModel(PreTrainedModel):
    config: Wav2Vec2BertConfig
    base_model_prefix = ...
    main_input_name = ...
    supports_gradient_checkpointing = ...

Wav2Vec2BertBaseModelOutput = Wav2Vec2BaseModelOutput

@auto_docstring
class Wav2Vec2BertModel(Wav2Vec2BertPreTrainedModel):
    def __init__(self, config: Wav2Vec2BertConfig) -> None: ...
    @auto_docstring
    def forward(
        self,
        input_features: torch.Tensor | None,
        attention_mask: torch.Tensor | None = ...,
        mask_time_indices: torch.FloatTensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | Wav2Vec2BertBaseModelOutput:
        r"""
        mask_time_indices (`torch.BoolTensor` of shape `(batch_size, sequence_length)`, *optional*):
            Indices to mask extracted features for contrastive loss. When in training mode, model learns to predict
            masked extracted features in *config.proj_codevector_dim* space.
        """
        ...

_HIDDEN_STATES_START_POSITION = ...

@auto_docstring(
    custom_intro="""
    Wav2Vec2Bert Model with a `language modeling` head on top for Connectionist Temporal Classification (CTC).
    """
)
class Wav2Vec2BertForCTC(Wav2Vec2BertPreTrainedModel):
    def __init__(self, config, target_lang: str | None = ...) -> None:
        r"""
        target_lang (`str`, *optional*):
            Language id of adapter weights. Adapter weights are stored in the format adapter.<lang>.safetensors or
            adapter.<lang>.bin. Only relevant when using an instance of [`UniSpeechSatForCTC`] with adapters. Uses 'eng' by
            default.
        """
        ...

    @auto_docstring
    def forward(
        self,
        input_features: torch.Tensor | None,
        attention_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        labels: torch.Tensor | None = ...,
    ) -> tuple | CausalLMOutput:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size, target_length)`, *optional*):
            Labels for connectionist temporal classification. Note that `target_length` has to be smaller or equal to
            the sequence length of the output logits. Indices are selected in `[-100, 0, ..., config.vocab_size - 1]`.
            All labels set to `-100` are ignored (masked), the loss is only computed for labels in `[0, ...,
            config.vocab_size - 1]`.
        """
        ...

@auto_docstring(
    custom_intro="""
    Wav2Vec2Bert Model with a sequence classification head on top (a linear layer over the pooled output) for tasks like
    SUPERB Keyword Spotting.
    """
)
class Wav2Vec2BertForSequenceClassification(Wav2Vec2BertPreTrainedModel):
    def __init__(self, config) -> None: ...
    def freeze_base_model(self):  # -> None:
        """
        Calling this function will disable the gradient computation for the base model so that its parameters will not
        be updated during training. Only the classification head will be updated.
        """
        ...

    @auto_docstring
    def forward(
        self,
        input_features: torch.Tensor | None,
        attention_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        labels: torch.Tensor | None = ...,
    ) -> tuple | SequenceClassifierOutput:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,
            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If
            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).
        """
        ...

@auto_docstring
class Wav2Vec2BertForAudioFrameClassification(Wav2Vec2BertPreTrainedModel):
    def __init__(self, config) -> None: ...
    def freeze_base_model(self):  # -> None:
        """
        Calling this function will disable the gradient computation for the base model so that its parameters will not
        be updated during training. Only the classification head will be updated.
        """
        ...

    @auto_docstring
    def forward(
        self,
        input_features: torch.Tensor | None,
        attention_mask: torch.Tensor | None = ...,
        labels: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
    ) -> tuple | TokenClassifierOutput:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,
            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If
            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).
        """
        ...

class AMSoftmaxLoss(nn.Module):
    def __init__(self, input_dim, num_labels, scale=..., margin=...) -> None: ...
    def forward(self, hidden_states, labels):  # -> Any:
        ...

class TDNNLayer(nn.Module):
    def __init__(self, config, layer_id=...) -> None: ...
    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor: ...

@auto_docstring(
    custom_intro="""
    Wav2Vec2Bert Model with an XVector feature extraction head on top for tasks like Speaker Verification.
    """
)
class Wav2Vec2BertForXVector(Wav2Vec2BertPreTrainedModel):
    def __init__(self, config) -> None: ...
    def freeze_base_model(self):  # -> None:
        """
        Calling this function will disable the gradient computation for the base model so that its parameters will not
        be updated during training. Only the classification head will be updated.
        """
        ...

    @auto_docstring
    def forward(
        self,
        input_features: torch.Tensor | None,
        attention_mask: torch.Tensor | None = ...,
        output_attentions: bool | None = ...,
        output_hidden_states: bool | None = ...,
        return_dict: bool | None = ...,
        labels: torch.Tensor | None = ...,
    ) -> tuple | XVectorOutput:
        r"""
        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,
            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If
            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).
        """
        ...

__all__ = [
    "Wav2Vec2BertForAudioFrameClassification",
    "Wav2Vec2BertForCTC",
    "Wav2Vec2BertForSequenceClassification",
    "Wav2Vec2BertForXVector",
    "Wav2Vec2BertModel",
    "Wav2Vec2BertPreTrainedModel",
]
