"""
This type stub file was generated by pyright.
"""

import torch
from typing import Callable, Optional, Union
from ...generation import GenerationConfig, GenerationMixin
from ...generation.logits_process import LogitsProcessorList
from ...generation.stopping_criteria import StoppingCriteriaList
from ...modeling_outputs import BaseModelOutput

logger = ...

class WhisperGenerationMixin(GenerationMixin):
    def generate(
        self,
        input_features: Optional[torch.Tensor] = ...,
        generation_config: Optional[GenerationConfig] = ...,
        logits_processor: Optional[LogitsProcessorList] = ...,
        stopping_criteria: Optional[StoppingCriteriaList] = ...,
        prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], list[int]]] = ...,
        synced_gpus: bool = ...,
        return_timestamps: Optional[bool] = ...,
        task: Optional[str] = ...,
        language: Optional[Union[str, list[str]]] = ...,
        is_multilingual: Optional[bool] = ...,
        prompt_ids: Optional[torch.Tensor] = ...,
        prompt_condition_type: Optional[str] = ...,
        condition_on_prev_tokens: Optional[bool] = ...,
        temperature: Optional[Union[float, tuple[float, ...]]] = ...,
        compression_ratio_threshold: Optional[float] = ...,
        logprob_threshold: Optional[float] = ...,
        no_speech_threshold: Optional[float] = ...,
        num_segment_frames: Optional[int] = ...,
        attention_mask: Optional[torch.Tensor] = ...,
        time_precision: float = ...,
        time_precision_features: float = ...,
        return_token_timestamps: Optional[bool] = ...,
        return_segments: bool = ...,
        return_dict_in_generate: Optional[bool] = ...,
        force_unique_generate_call: Optional[bool] = ...,
        monitor_progress: Optional[Callable[[torch.Tensor], None]] = ...,
        **kwargs,
    ): ...
    def generate_with_fallback(
        self,
        segment_input,
        decoder_input_ids,
        cur_bsz,
        seek,
        batch_idx_map,
        temperatures,
        generation_config,
        logits_processor,
        stopping_criteria,
        prefix_allowed_tokens_fn,
        synced_gpus,
        return_token_timestamps,
        do_condition_on_prev_tokens,
        is_shortform,
        batch_size,
        attention_mask,
        kwargs,
    ): ...
    def detect_language(
        self,
        input_features: Optional[torch.FloatTensor] = ...,
        encoder_outputs: Optional[Union[torch.FloatTensor, BaseModelOutput]] = ...,
        generation_config: Optional[GenerationConfig] = ...,
        num_segment_frames: int = ...,
    ) -> torch.Tensor: ...
