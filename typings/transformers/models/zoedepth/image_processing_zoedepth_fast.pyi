import torch

from ...image_processing_utils import BatchFeature
from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs
from ...image_utils import ImageInput, SizeDict
from ...processing_utils import Unpack
from ...utils import TensorType, is_torch_available, is_torchvision_available
from .modeling_zoedepth import ZoeDepthDepthEstimatorOutput

"""Fast Image processor class for ZoeDepth."""
if is_torch_available(): ...
if is_torchvision_available(): ...
logger = ...

class ZoeDepthFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):
    do_pad: bool | None
    keep_aspect_ratio: bool | None
    ensure_multiple_of: int | None

class ZoeDepthImageProcessorFast(BaseImageProcessorFast):
    do_pad = ...
    do_rescale = ...
    do_normalize = ...
    image_mean = ...
    image_std = ...
    do_resize = ...
    size = ...
    resample = ...
    keep_aspect_ratio = ...
    ensure_multiple_of = ...
    valid_kwargs = ZoeDepthFastImageProcessorKwargs
    def __init__(self, **kwargs: Unpack[ZoeDepthFastImageProcessorKwargs]) -> None: ...
    def preprocess(self, images: ImageInput, **kwargs: Unpack[ZoeDepthFastImageProcessorKwargs]) -> BatchFeature: ...
    def resize(
        self,
        images: torch.Tensor,
        size: SizeDict,
        keep_aspect_ratio: bool = ...,
        ensure_multiple_of: int = ...,
        interpolation: F.InterpolationMode | None = ...,
    ) -> torch.Tensor: ...
    def post_process_depth_estimation(
        self,
        outputs: ZoeDepthDepthEstimatorOutput,
        source_sizes: TensorType | list[tuple[int, int]] | None = ...,
        target_sizes: TensorType | list[tuple[int, int]] | None = ...,
        outputs_flipped: ZoeDepthDepthEstimatorOutput | None = ...,
        do_remove_padding: bool | None = ...,
    ) -> list[dict[str, TensorType]]: ...

__all__ = ["ZoeDepthImageProcessorFast"]
