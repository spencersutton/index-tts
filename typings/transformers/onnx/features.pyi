from collections.abc import Callable
from typing import TYPE_CHECKING

from transformers import PreTrainedModel, TFPreTrainedModel

from .. import PretrainedConfig, is_tf_available, is_torch_available
from .config import OnnxConfig

if TYPE_CHECKING: ...
logger = ...
if is_torch_available(): ...
if is_tf_available(): ...
if not is_torch_available() and not is_tf_available(): ...

def supported_features_mapping(
    *supported_features: str, onnx_config_cls: str | None = ...
) -> dict[str, Callable[[PretrainedConfig], OnnxConfig]]: ...

class FeaturesManager:
    _TASKS_TO_AUTOMODELS = ...
    _TASKS_TO_TF_AUTOMODELS = ...
    if is_torch_available():
        _TASKS_TO_AUTOMODELS = ...
    if is_tf_available():
        _TASKS_TO_TF_AUTOMODELS = ...
    _SUPPORTED_MODEL_TYPE = ...
    AVAILABLE_FEATURES = ...
    @staticmethod
    def get_supported_features_for_model_type(
        model_type: str, model_name: str | None = ...
    ) -> dict[str, Callable[[PretrainedConfig], OnnxConfig]]: ...
    @staticmethod
    def feature_to_task(feature: str) -> str: ...
    @staticmethod
    def get_model_class_for_feature(feature: str, framework: str = ...) -> type: ...
    @staticmethod
    def determine_framework(model: str, framework: str | None = ...) -> str: ...
    @staticmethod
    def get_model_from_feature(
        feature: str, model: str, framework: str | None = ..., cache_dir: str | None = ...
    ) -> PreTrainedModel | TFPreTrainedModel: ...
    @staticmethod
    def check_supported_model_or_raise(
        model: PreTrainedModel | TFPreTrainedModel, feature: str = ...
    ) -> tuple[str, Callable]: ...
    def get_config(self: str, feature: str) -> OnnxConfig: ...
