"""
This type stub file was generated by pyright.
"""

import numpy as np
from typing import Optional, TYPE_CHECKING, Union
from ..data import SquadExample
from ..modelcard import ModelCard
from ..tokenization_utils import PreTrainedTokenizer
from ..utils import add_end_docstrings, is_tf_available, is_torch_available
from .base import ArgumentHandler, ChunkPipeline, build_pipeline_init_args
from ..modeling_tf_utils import TFPreTrainedModel
from ..modeling_utils import PreTrainedModel
from torch.utils.data import Dataset

logger = ...
if TYPE_CHECKING: ...
if is_tf_available():
    Dataset = ...
if is_torch_available(): ...

def decode_spans(
    start: np.ndarray, end: np.ndarray, topk: int, max_answer_len: int, undesired_tokens: np.ndarray
) -> tuple: ...
def select_starts_ends(
    start, end, p_mask, attention_mask, min_null_score=..., top_k=..., handle_impossible_answer=..., max_answer_len=...
): ...

class QuestionAnsweringArgumentHandler(ArgumentHandler):
    _load_processor = ...
    _load_image_processor = ...
    _load_feature_extractor = ...
    _load_tokenizer = ...
    def normalize(self, item): ...
    def __call__(self, *args, **kwargs): ...

@add_end_docstrings(build_pipeline_init_args(has_tokenizer=True))
class QuestionAnsweringPipeline(ChunkPipeline):
    default_input_names = ...
    handle_impossible_answer = ...
    def __init__(
        self,
        model: Union[PreTrainedModel, TFPreTrainedModel],
        tokenizer: PreTrainedTokenizer,
        modelcard: Optional[ModelCard] = ...,
        framework: Optional[str] = ...,
        task: str = ...,
        **kwargs,
    ) -> None: ...
    @staticmethod
    def create_sample(
        question: Union[str, list[str]], context: Union[str, list[str]]
    ) -> Union[SquadExample, list[SquadExample]]: ...
    def __call__(self, *args, **kwargs): ...
    def preprocess(self, example, padding=..., doc_stride=..., max_question_len=..., max_seq_len=...): ...
    def postprocess(
        self, model_outputs, top_k=..., handle_impossible_answer=..., max_answer_len=..., align_to_words=...
    ): ...
    def get_answer(self, answers: list[dict], target: str) -> Optional[dict]: ...
    def get_indices(
        self, enc: tokenizers.Encoding, s: int, e: int, sequence_index: int, align_to_words: bool
    ) -> tuple[int, int]: ...
    def span_to_answer(self, text: str, start: int, end: int) -> dict[str, Union[str, int]]: ...
