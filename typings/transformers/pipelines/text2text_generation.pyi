import enum
from typing import Any

from ..utils import add_end_docstrings, is_tf_available, is_torch_available
from .base import Pipeline, build_pipeline_init_args

if is_tf_available(): ...
if is_torch_available(): ...
logger = ...

class ReturnType(enum.Enum):
    TENSORS = ...
    TEXT = ...

class Text2TextGenerationPipeline(Pipeline):
    _pipeline_calls_generate = ...
    _load_processor = ...
    _load_image_processor = ...
    _load_feature_extractor = ...
    _load_tokenizer = ...
    _default_generation_config = ...
    return_name = ...
    def __init__(self, *args, **kwargs) -> None: ...
    def check_inputs(self, input_length: int, min_length: int, max_length: int):  # -> Literal[True]:

        ...
    def __call__(self, *args: str | list[str], **kwargs: Any) -> list[dict[str, str]]: ...
    def preprocess(self, inputs, truncation=..., **kwargs):  # -> BatchEncoding | Any:
        ...
    def postprocess(self, model_outputs, return_type=..., clean_up_tokenization_spaces=...):  # -> list[Any]:
        ...

class SummarizationPipeline(Text2TextGenerationPipeline):
    return_name = ...
    def __call__(self, *args, **kwargs):  # -> list[dict[str, str]]:

        ...
    def check_inputs(self, input_length: int, min_length: int, max_length: int) -> bool: ...

class TranslationPipeline(Text2TextGenerationPipeline):
    return_name = ...
    def check_inputs(self, input_length: int, min_length: int, max_length: int):  # -> Literal[True]:
        ...
    def preprocess(self, *args, truncation=..., src_lang=..., tgt_lang=...):  # -> Any | BatchEncoding:
        ...
    def __call__(self, *args, **kwargs):  # -> list[dict[str, str]]:

        ...
