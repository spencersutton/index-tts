"""
This type stub file was generated by pyright.
"""

import numpy as np
from typing import Any, Optional, Union, overload
from ..utils import ExplicitEnum, add_end_docstrings, is_tf_available, is_torch_available
from .base import ArgumentHandler, ChunkPipeline, build_pipeline_init_args

if is_tf_available(): ...
if is_torch_available(): ...

class TokenClassificationArgumentHandler(ArgumentHandler):
    def __call__(self, inputs: Union[str, list[str]], **kwargs): ...

class AggregationStrategy(ExplicitEnum):
    NONE = ...
    SIMPLE = ...
    FIRST = ...
    AVERAGE = ...
    MAX = ...

@add_end_docstrings(build_pipeline_init_args(has_tokenizer=True), ...)
class TokenClassificationPipeline(ChunkPipeline):
    default_input_names = ...
    _load_processor = ...
    _load_image_processor = ...
    _load_feature_extractor = ...
    _load_tokenizer = ...
    def __init__(self, args_parser=..., *args, **kwargs) -> None: ...
    @overload
    def __call__(self, inputs: str, **kwargs: Any) -> list[dict[str, str]]: ...
    @overload
    def __call__(self, inputs: list[str], **kwargs: Any) -> list[list[dict[str, str]]]: ...
    def __call__(
        self, inputs: Union[str, list[str]], **kwargs: Any
    ) -> Union[list[dict[str, str]], list[list[dict[str, str]]]]: ...
    def preprocess(self, sentence, offset_mapping=..., **preprocess_params): ...
    def postprocess(self, all_outputs, aggregation_strategy=..., ignore_labels=...): ...
    def aggregate_overlapping_entities(self, entities): ...
    def gather_pre_entities(
        self,
        sentence: str,
        input_ids: np.ndarray,
        scores: np.ndarray,
        offset_mapping: Optional[list[tuple[int, int]]],
        special_tokens_mask: np.ndarray,
        aggregation_strategy: AggregationStrategy,
        word_ids: Optional[list[Optional[int]]] = ...,
        word_to_chars_map: Optional[list[tuple[int, int]]] = ...,
    ) -> list[dict]: ...
    def aggregate(self, pre_entities: list[dict], aggregation_strategy: AggregationStrategy) -> list[dict]: ...
    def aggregate_word(self, entities: list[dict], aggregation_strategy: AggregationStrategy) -> dict: ...
    def aggregate_words(self, entities: list[dict], aggregation_strategy: AggregationStrategy) -> list[dict]: ...
    def group_sub_entities(self, entities: list[dict]) -> dict: ...
    def get_tag(self, entity_name: str) -> tuple[str, str]: ...
    def group_entities(self, entities: list[dict]) -> list[dict]: ...

NerPipeline = TokenClassificationPipeline
