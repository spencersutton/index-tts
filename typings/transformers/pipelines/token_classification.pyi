from typing import Any, overload

import numpy as np

from ..utils import ExplicitEnum, add_end_docstrings, is_tf_available, is_torch_available
from .base import ArgumentHandler, ChunkPipeline, build_pipeline_init_args

if is_tf_available(): ...
if is_torch_available(): ...

class TokenClassificationArgumentHandler(ArgumentHandler):
    def __call__(
        self, inputs: str | list[str], **kwargs
    ):  # -> tuple[list[str], Any, None, Any | None] | tuple[list[str], Any, list[list[Any]] | Any | list[Any] | None, Any | None]:
        ...

class AggregationStrategy(ExplicitEnum):
    NONE = ...
    SIMPLE = ...
    FIRST = ...
    AVERAGE = ...
    MAX = ...

class TokenClassificationPipeline(ChunkPipeline):
    default_input_names = ...
    _load_processor = ...
    _load_image_processor = ...
    _load_feature_extractor = ...
    _load_tokenizer = ...
    def __init__(self, args_parser=..., *args, **kwargs) -> None: ...
    @overload
    def __call__(self, inputs: str, **kwargs: Any) -> list[dict[str, str]]: ...
    @overload
    def __call__(self, inputs: list[str], **kwargs: Any) -> list[list[dict[str, str]]]: ...
    def __call__(self, inputs: str | list[str], **kwargs: Any) -> list[dict[str, str]] | list[list[dict[str, str]]]: ...
    def preprocess(self, sentence, offset_mapping=..., **preprocess_params):  # -> Generator[dict[Any, Any], Any, None]:
        ...
    def postprocess(self, all_outputs, aggregation_strategy=..., ignore_labels=...):  # -> list[Any]:
        ...
    def aggregate_overlapping_entities(self, entities):  # -> list[Any]:
        ...
    def gather_pre_entities(
        self,
        sentence: str,
        input_ids: np.ndarray,
        scores: np.ndarray,
        offset_mapping: list[tuple[int, int]] | None,
        special_tokens_mask: np.ndarray,
        aggregation_strategy: AggregationStrategy,
        word_ids: list[int | None] | None = ...,
        word_to_chars_map: list[tuple[int, int]] | None = ...,
    ) -> list[dict]: ...
    def aggregate(self, pre_entities: list[dict], aggregation_strategy: AggregationStrategy) -> list[dict]: ...
    def aggregate_word(self, entities: list[dict], aggregation_strategy: AggregationStrategy) -> dict: ...
    def aggregate_words(self, entities: list[dict], aggregation_strategy: AggregationStrategy) -> list[dict]: ...
    def group_sub_entities(self, entities: list[dict]) -> dict: ...
    def get_tag(self, entity_name: str) -> tuple[str, str]: ...
    def group_entities(self, entities: list[dict]) -> list[dict]: ...

NerPipeline = TokenClassificationPipeline
