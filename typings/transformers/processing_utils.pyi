"""
This type stub file was generated by pyright.
"""

import os
import sys
import typing
import numpy as np
from dataclasses import dataclass
from typing import Any, Optional, TypeVar, TypedDict, Union
from transformers.utils import is_torch_available
from .image_utils import ChannelDimension, PILImageResampling, is_vision_available
from .video_utils import VideoMetadata
from .tokenization_utils_base import PaddingStrategy, PreTokenizedInput, TextInput, TruncationStrategy
from .utils import PushToHubMixin, TensorType
from .utils.deprecation import deprecate_kwarg

if is_vision_available(): ...
if is_torch_available(): ...
logger = ...
SpecificProcessorType = TypeVar("SpecificProcessorType", bound=ProcessorMixin)
transformers_module = ...
AUTO_TO_BASE_CLASS_MAPPING = ...
if sys.version_info >= (3, 11):
    Unpack = typing.Unpack
else: ...

class TextKwargs(TypedDict, total=False):
    text_pair: Optional[Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput]]]
    text_target: Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput]]
    text_pair_target: Optional[Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput]]]
    add_special_tokens: Optional[bool]
    padding: Union[bool, str, PaddingStrategy]
    truncation: Union[bool, str, TruncationStrategy]
    max_length: Optional[int]
    stride: Optional[int]
    is_split_into_words: Optional[bool]
    pad_to_multiple_of: Optional[int]
    return_token_type_ids: Optional[bool]
    return_attention_mask: Optional[bool]
    return_overflowing_tokens: Optional[bool]
    return_special_tokens_mask: Optional[bool]
    return_offsets_mapping: Optional[bool]
    return_length: Optional[bool]
    verbose: Optional[bool]
    padding_side: Optional[str]
    return_mm_token_type_ids: Optional[bool]
    ...

class ImagesKwargs(TypedDict, total=False):
    do_resize: Optional[bool]
    size: Optional[dict[str, int]]
    size_divisor: Optional[int]
    crop_size: Optional[dict[str, int]]
    resample: Optional[Union[PILImageResampling, int]]
    do_rescale: Optional[bool]
    rescale_factor: Optional[float]
    do_normalize: Optional[bool]
    image_mean: Optional[Union[float, list[float]]]
    image_std: Optional[Union[float, list[float]]]
    do_pad: Optional[bool]
    pad_size: Optional[dict[str, int]]
    do_center_crop: Optional[bool]
    data_format: Optional[ChannelDimension]
    input_data_format: Optional[Union[str, ChannelDimension]]
    device: Optional[str]
    ...

class VideosKwargs(TypedDict, total=False):
    do_convert_rgb: Optional[bool]
    do_resize: Optional[bool]
    size: Optional[dict[str, int]]
    size_divisor: Optional[int]
    default_to_square: Optional[bool]
    resample: Optional[PILImageResampling]
    do_rescale: Optional[bool]
    rescale_factor: Optional[float]
    do_normalize: Optional[bool]
    image_mean: Optional[Union[float, list[float]]]
    image_std: Optional[Union[float, list[float]]]
    do_pad: Optional[bool]
    do_center_crop: Optional[bool]
    crop_size: Optional[dict[str, int]]
    data_format: Optional[ChannelDimension]
    input_data_format: Optional[Union[str, ChannelDimension]]
    device: Optional[str]
    do_sample_frames: Optional[bool]
    video_metadata: Optional[Union[VideoMetadata, dict]]
    fps: Optional[Union[int, float]]
    num_frames: Optional[int]
    ...

class AudioKwargs(TypedDict, total=False):
    sampling_rate: Optional[int]
    raw_speech: Optional[Union[np.ndarray, list[float], list[np.ndarray], list[list[float]]]]
    padding: Optional[Union[bool, str, PaddingStrategy]]
    max_length: Optional[int]
    truncation: Optional[bool]
    pad_to_multiple_of: Optional[int]
    return_attention_mask: Optional[bool]
    ...

class CommonKwargs(TypedDict, total=False):
    return_tensors: Optional[Union[str, TensorType]]
    ...

class ProcessingKwargs(TextKwargs, ImagesKwargs, VideosKwargs, AudioKwargs, CommonKwargs, total=False):
    common_kwargs: CommonKwargs = ...
    text_kwargs: TextKwargs = ...
    images_kwargs: ImagesKwargs = ...
    videos_kwargs: VideosKwargs = ...
    audio_kwargs: AudioKwargs = ...

class TokenizerChatTemplateKwargs(TypedDict, total=False):
    tools: Optional[list[dict]] = ...
    documents: Optional[list[dict[str, str]]] = ...
    add_generation_prompt: Optional[bool] = ...
    continue_final_message: Optional[bool] = ...
    return_assistant_tokens_mask: Optional[bool] = ...

class ChatTemplateLoadKwargs(TypedDict, total=False):
    video_load_backend: Optional[str] = ...
    sampling_rate: Optional[int] = ...
    load_audio_from_video: Optional[bool] = ...

class ProcessorChatTemplateKwargs(ChatTemplateLoadKwargs, TokenizerChatTemplateKwargs, total=False):
    tokenize: Optional[bool] = ...
    return_dict: Optional[bool] = ...

class AllKwargsForChatTemplate(
    TextKwargs, ImagesKwargs, VideosKwargs, AudioKwargs, CommonKwargs, ProcessorChatTemplateKwargs
):
    processor_kwargs: ProcessingKwargs = ...
    mm_load_kwargs: ChatTemplateLoadKwargs = ...
    template_kwargs: ProcessorChatTemplateKwargs = ...

@dataclass
class MultiModalData:
    num_image_tokens: list[int] = ...
    num_video_tokens: list[int] = ...
    num_audio_tokens: list[int] = ...
    num_image_patches: list[int] = ...
    def __contains__(self, key): ...
    def __getitem__(self, key): ...

class ProcessorMixin(PushToHubMixin):
    attributes = ...
    optional_attributes = ...
    optional_call_args: list[str] = ...
    feature_extractor_class = ...
    tokenizer_class = ...
    _auto_class = ...
    def __init__(self, *args, **kwargs) -> None: ...
    def check_argument_for_proper_class(self, argument_name, argument): ...
    def to_dict(self) -> dict[str, Any]: ...
    def to_json_string(self) -> str: ...
    def to_json_file(self, json_file_path: Union[str, os.PathLike]): ...
    def __repr__(self): ...
    def save_pretrained(self, save_directory, push_to_hub: bool = ..., **kwargs): ...
    @classmethod
    def get_processor_dict(
        cls, pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs
    ) -> tuple[dict[str, Any], dict[str, Any]]: ...
    @classmethod
    def from_args_and_dict(cls, args, processor_dict: dict[str, Any], **kwargs): ...
    @classmethod
    def from_pretrained(
        cls,
        pretrained_model_name_or_path: Union[str, os.PathLike],
        cache_dir: Optional[Union[str, os.PathLike]] = ...,
        force_download: bool = ...,
        local_files_only: bool = ...,
        token: Optional[Union[str, bool]] = ...,
        revision: str = ...,
        **kwargs,
    ) -> typing.Self: ...
    @classmethod
    def register_for_auto_class(cls, auto_class=...): ...
    @staticmethod
    def get_possibly_dynamic_module(module_name): ...
    @property
    def model_input_names(self): ...
    @staticmethod
    def validate_init_kwargs(processor_config, valid_kwargs): ...
    @deprecate_kwarg("video_fps", version="4.58", new_name="fps")
    def apply_chat_template(
        self,
        conversation: Union[list[dict[str, str]], list[list[dict[str, str]]]],
        chat_template: Optional[str] = ...,
        **kwargs: Unpack[AllKwargsForChatTemplate],
    ) -> str: ...
    def post_process_image_text_to_text(self, generated_outputs, skip_special_tokens=..., **kwargs): ...

if ProcessorMixin.push_to_hub.__doc__ is not None: ...
