"""
This type stub file was generated by pyright.
"""

from typing import TYPE_CHECKING, Union

import torch

from ..utils import is_torch_available
from .base import HfQuantizer

if TYPE_CHECKING: ...
if is_torch_available(): ...
logger = ...

class BitNetHfQuantizer(HfQuantizer):
    """
    1.58-bit quantization from BitNet quantization method:
    Before loading: it converts the linear layers into BitLinear layers during loading.

    Check out the paper introducing this method: https://huggingface.co/papers/2402.17764
    """

    requires_parameters_quantization = ...
    requires_calibration = ...
    required_packages = ...
    def __init__(self, quantization_config, **kwargs) -> None: ...
    def validate_environment(self, *args, **kwargs):  # -> None:
        ...
    def adjust_max_memory(self, max_memory: dict[str, int | str]) -> dict[str, int | str]: ...
    def adjust_target_dtype(self, target_dtype: torch.dtype) -> torch.dtype: ...
    def is_serializable(self, safe_serialization=...):  # -> Literal[True]:
        ...
    @property
    def is_trainable(self) -> bool: ...
    @property
    def is_qat_trainable(self) -> bool:
        """Flag indicating whether the quantized model can carry out quantization aware training"""
        ...
