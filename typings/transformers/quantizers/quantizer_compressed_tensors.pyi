import torch

from ..utils import is_torch_available
from ..utils.quantization_config import CompressedTensorsConfig
from .base import HfQuantizer

if is_torch_available(): ...
logger = ...

class CompressedTensorsHfQuantizer(HfQuantizer):
    requires_calibration = ...
    required_packages = ...
    def __init__(self, quantization_config: CompressedTensorsConfig, **kwargs) -> None: ...
    def update_missing_keys_after_loading(self, model, missing_keys: list[str], prefix: str) -> list[str]: ...
    def update_unexpected_keys(self, model, unexpected_keys: list[str], prefix: str) -> list[str]: ...
    def validate_environment(self, *args, **kwargs):  # -> None:
        ...
    def update_torch_dtype(self, torch_dtype: torch.dtype) -> torch.dtype: ...
    def update_tp_plan(self, config): ...
    @property
    def is_trainable(self):  # -> Literal[True]:
        ...
    def is_qat_trainable(self) -> bool: ...
    def is_serializable(self, safe_serialization=...) -> bool: ...
