from typing import Any

from ..modeling_utils import PreTrainedModel
from ..utils import is_accelerate_available
from .base import HfQuantizer

if is_accelerate_available(): ...
logger = ...
CHECKPOINT_KEYS = ...

class QuarkHfQuantizer(HfQuantizer):
    requires_calibration = ...
    required_packages = ...
    requires_parameters_quantization = ...
    def __init__(self, quantization_config, **kwargs) -> None: ...
    def validate_environment(self, *args, **kwargs):  # -> None:
        ...
    def check_quantized_param(
        self, model: PreTrainedModel, param_value: torch.Tensor, param_name: str, state_dict: dict[str, Any], **kwargs
    ) -> bool: ...
    def create_quantized_param(
        self, model, param, param_name, param_device, state_dict, unexpected_keys
    ) -> torch.nn.Parameter: ...
    def is_serializable(self, safe_serialization=...):  # -> Literal[False]:
        ...
    @property
    def is_trainable(self):  # -> Literal[False]:
        ...
