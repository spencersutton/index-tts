"""
This type stub file was generated by pyright.
"""

import torch
import datasets
import optuna
from collections.abc import Iterator
from typing import Any, Callable, Optional, TYPE_CHECKING, Union
from packaging import version
from torch import nn
from torch.utils.data import DataLoader, Dataset, IterableDataset
from .data.data_collator import DataCollator
from .feature_extraction_utils import FeatureExtractionMixin
from .image_processing_utils import BaseImageProcessor
from .modeling_utils import PreTrainedModel
from .processing_utils import ProcessorMixin
from .tokenization_utils_base import PreTrainedTokenizerBase
from .trainer_callback import TrainerCallback
from .trainer_utils import BestRun, EvalLoopOutput, EvalPrediction, HPSearchBackend, PredictionOutput
from .training_args import TrainingArguments
from .utils import (
    is_accelerate_available,
    is_datasets_available,
    is_in_notebook,
    is_peft_available,
    is_safetensors_available,
    is_sagemaker_mp_enabled,
    is_torch_xla_available,
)
from .utils.deprecation import deprecate_kwarg
from .utils.import_utils import requires

DEFAULT_CALLBACKS = ...
DEFAULT_PROGRESS_CALLBACK = ...
if is_in_notebook():
    DEFAULT_PROGRESS_CALLBACK = ...
if is_datasets_available(): ...
if is_torch_xla_available():
    IS_XLA_FSDPV2_POST_2_2 = ...
else:
    IS_XLA_FSDPV2_POST_2_2 = ...
if is_sagemaker_mp_enabled():
    IS_SAGEMAKER_MP_POST_1_10 = ...
else:
    IS_SAGEMAKER_MP_POST_1_10 = ...
if is_safetensors_available(): ...
if is_peft_available(): ...
if is_accelerate_available():
    DATA_SAMPLERS = ...
if is_accelerate_available("0.28.0"): ...

def safe_globals(): ...

if TYPE_CHECKING: ...
logger = ...
TRAINING_ARGS_NAME = ...
TRAINER_STATE_NAME = ...
OPTIMIZER_NAME = ...
SCALER_NAME = ...
OPTIMIZER_NAME_BIN = ...
SCHEDULER_NAME = ...
FSDP_MODEL_NAME = ...

@requires(backends=("torch", "accelerate"))
class Trainer:
    @deprecate_kwarg("tokenizer", new_name="processing_class", version="5.0.0", raise_if_both_names=True)
    def __init__(
        self,
        model: Union[PreTrainedModel, nn.Module, None] = ...,
        args: TrainingArguments = ...,
        data_collator: Optional[DataCollator] = ...,
        train_dataset: Optional[Union[Dataset, IterableDataset, datasets.Dataset]] = ...,
        eval_dataset: Optional[Union[Dataset, dict[str, Dataset], datasets.Dataset]] = ...,
        processing_class: Optional[
            Union[PreTrainedTokenizerBase, BaseImageProcessor, FeatureExtractionMixin, ProcessorMixin]
        ] = ...,
        model_init: Optional[Callable[[], PreTrainedModel]] = ...,
        compute_loss_func: Optional[Callable] = ...,
        compute_metrics: Optional[Callable[[EvalPrediction], dict]] = ...,
        callbacks: Optional[list[TrainerCallback]] = ...,
        optimizers: tuple[Optional[torch.optim.Optimizer], Optional[torch.optim.lr_scheduler.LambdaLR]] = ...,
        optimizer_cls_and_kwargs: Optional[tuple[type[torch.optim.Optimizer], dict[str, Any]]] = ...,
        preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = ...,
    ) -> None: ...
    @property
    def tokenizer(self) -> Optional[PreTrainedTokenizerBase]: ...
    @tokenizer.setter
    def tokenizer(self, processing_class) -> None: ...
    def add_callback(self, callback): ...
    def pop_callback(self, callback): ...
    def remove_callback(self, callback): ...
    def get_train_dataloader(self) -> DataLoader: ...
    def get_eval_dataloader(self, eval_dataset: Optional[Union[str, Dataset]] = ...) -> DataLoader: ...
    def get_test_dataloader(self, test_dataset: Dataset) -> DataLoader: ...
    def create_optimizer_and_scheduler(self, num_training_steps: int): ...
    def get_decay_parameter_names(self, model) -> list[str]: ...
    def create_optimizer(self): ...
    def get_num_trainable_parameters(self): ...
    def get_learning_rates(self): ...
    def get_optimizer_group(self, param: Optional[Union[str, torch.nn.parameter.Parameter]] = ...): ...
    @staticmethod
    def get_optimizer_cls_and_kwargs(
        args: TrainingArguments, model: Optional[PreTrainedModel] = ...
    ) -> tuple[Any, Any]: ...
    def create_scheduler(self, num_training_steps: int, optimizer: torch.optim.Optimizer = ...): ...
    def num_examples(self, dataloader: DataLoader) -> int: ...
    @staticmethod
    def num_tokens(train_dl: DataLoader, max_steps: Optional[int] = ...) -> int: ...
    def call_model_init(self, trial=...): ...
    def torch_jit_model_eval(self, model, dataloader, training=...): ...
    def compare_trainer_and_checkpoint_args(self, training_args, trainer_state): ...
    def train(
        self,
        resume_from_checkpoint: Optional[Union[str, bool]] = ...,
        trial: Union[optuna.Trial, dict[str, Any], None] = ...,
        ignore_keys_for_eval: Optional[list[str]] = ...,
        **kwargs,
    ): ...
    def get_tp_size(self) -> int: ...
    def get_total_train_batch_size(self, args) -> int: ...
    def hyperparameter_search(
        self,
        hp_space: Optional[Callable[[optuna.Trial], dict[str, float]]] = ...,
        compute_objective: Optional[Callable[[dict[str, float]], float]] = ...,
        n_trials: int = ...,
        direction: Union[str, list[str]] = ...,
        backend: Optional[Union[str, HPSearchBackend]] = ...,
        hp_name: Optional[Callable[[optuna.Trial], str]] = ...,
        **kwargs,
    ) -> Union[BestRun, list[BestRun]]: ...
    def log(self, logs: dict[str, float], start_time: Optional[float] = ...) -> None: ...
    def compute_loss_context_manager(self): ...
    def autocast_smart_context_manager(self, cache_enabled: Optional[bool] = ...): ...
    def training_step(
        self,
        model: nn.Module,
        inputs: dict[str, Union[torch.Tensor, Any]],
        num_items_in_batch: Optional[torch.Tensor] = ...,
    ) -> torch.Tensor: ...
    def compute_loss(
        self,
        model: nn.Module,
        inputs: dict[str, Union[torch.Tensor, Any]],
        return_outputs: bool = ...,
        num_items_in_batch: Optional[torch.Tensor] = ...,
    ): ...
    def is_local_process_zero(self) -> bool: ...
    def is_world_process_zero(self) -> bool: ...
    def save_model(self, output_dir: Optional[str] = ..., _internal_call: bool = ...): ...
    def store_flos(self): ...
    def evaluate(
        self,
        eval_dataset: Optional[Union[Dataset, dict[str, Dataset]]] = ...,
        ignore_keys: Optional[list[str]] = ...,
        metric_key_prefix: str = ...,
    ) -> dict[str, float]: ...
    def predict(
        self, test_dataset: Dataset, ignore_keys: Optional[list[str]] = ..., metric_key_prefix: str = ...
    ) -> PredictionOutput: ...
    def evaluation_loop(
        self,
        dataloader: DataLoader,
        description: str,
        prediction_loss_only: Optional[bool] = ...,
        ignore_keys: Optional[list[str]] = ...,
        metric_key_prefix: str = ...,
    ) -> EvalLoopOutput: ...
    def prediction_step(
        self,
        model: nn.Module,
        inputs: dict[str, Union[torch.Tensor, Any]],
        prediction_loss_only: bool,
        ignore_keys: Optional[list[str]] = ...,
    ) -> tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]: ...
    def floating_point_ops(self, inputs: dict[str, Union[torch.Tensor, Any]]): ...
    def init_hf_repo(self, token: Optional[str] = ...): ...
    def create_model_card(
        self,
        language: Optional[str] = ...,
        license: Optional[str] = ...,
        tags: Union[str, list[str], None] = ...,
        model_name: Optional[str] = ...,
        finetuned_from: Optional[str] = ...,
        tasks: Union[str, list[str], None] = ...,
        dataset_tags: Union[str, list[str], None] = ...,
        dataset: Union[str, list[str], None] = ...,
        dataset_args: Union[str, list[str], None] = ...,
    ): ...
    def push_to_hub(
        self,
        commit_message: Optional[str] = ...,
        blocking: bool = ...,
        token: Optional[str] = ...,
        revision: Optional[str] = ...,
        **kwargs,
    ) -> str: ...
    def prediction_loop(
        self,
        dataloader: DataLoader,
        description: str,
        prediction_loss_only: Optional[bool] = ...,
        ignore_keys: Optional[list[str]] = ...,
        metric_key_prefix: str = ...,
    ) -> EvalLoopOutput: ...
    def create_accelerator_and_postprocess(self): ...
    def propagate_args_to_deepspeed(self, auto_find_batch_size=...): ...
    def get_batch_samples(
        self, epoch_iterator: Iterator, num_batches: int, device: torch.device
    ) -> tuple[list, Optional[torch.Tensor]]: ...
    def set_initial_training_values(
        self, args: TrainingArguments, dataloader: DataLoader, total_train_batch_size: int
    ): ...
