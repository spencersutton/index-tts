import importlib.machinery
from enum import Enum
from functools import lru_cache
from types import ModuleType
from typing import Any

"""
Import utilities: Utilities related to imports and our lazy inits.
"""
logger = ...
ENV_VARS_TRUE_VALUES = ...
ENV_VARS_TRUE_AND_AUTO_VALUES = ...
USE_TF = ...
USE_TORCH = ...
USE_JAX = ...
USE_TORCH_XLA = ...
FORCE_TF_AVAILABLE = ...
TORCH_FX_REQUIRED_VERSION = ...
ACCELERATE_MIN_VERSION = ...
SCHEDULEFREE_MIN_VERSION = ...
FSDP_MIN_VERSION = ...
GGUF_MIN_VERSION = ...
XLA_FSDPV2_MIN_VERSION = ...
HQQ_MIN_VERSION = ...
VPTQ_MIN_VERSION = ...
TORCHAO_MIN_VERSION = ...
AUTOROUND_MIN_VERSION = ...
TRITON_MIN_VERSION = ...
_apex_available = ...
_apollo_torch_available = ...
_aqlm_available = ...
_av_available = ...
_decord_available = ...
_torchcodec_available = ...
_libcst_available = ...
_bitsandbytes_available = ...
_eetq_available = ...
_fbgemm_gpu_available = ...
_galore_torch_available = ...
_lomo_available = ...
_grokadamw_available = ...
_torch_optimi_available = ...
_bs4_available = ...
_coloredlogs_available = ...
_cv2_available = ...
_yt_dlp_available = ...
_datasets_available = ...
_detectron2_available = ...
_faiss_available = ...
_faiss_version = ...
_ftfy_available = ...
_g2p_en_available = ...
_hadamard_available = ...
_jieba_available = ...
_jinja_available = ...
_kenlm_available = ...
_keras_nlp_available = ...
_levenshtein_available = ...
_librosa_available = ...
_natten_available = ...
_nltk_available = ...
_onnx_available = ...
_openai_available = ...
_optimum_available = ...
_auto_gptq_available = ...
_gptqmodel_available = ...
_auto_awq_available = ...
_quark_available = ...
_qutlass_available = ...
_is_optimum_quanto_available = ...
_is_optimum_quanto_available = ...
_compressed_tensors_available = ...
_pandas_available = ...
_peft_available = ...
_phonemizer_available = ...
_uroman_available = ...
_psutil_available = ...
_py3nvml_available = ...
_pyctcdecode_available = ...
_pygments_available = ...
_pytesseract_available = ...
_pytest_available = ...
_pytorch_quantization_available = ...
_rjieba_available = ...
_sacremoses_available = ...
_safetensors_available = ...
_scipy_available = ...
_sentencepiece_available = ...
_is_seqio_available = ...
_sklearn_available = ...
if _sklearn_available: ...
_smdistributed_available = ...
_soundfile_available = ...
_spacy_available = ...
_tensorflow_probability_available = ...
_tensorflow_text_available = ...
_tf2onnx_available = ...
_timm_available = ...
_tokenizers_available = ...
_torchaudio_available = ...
_torchdistx_available = ...
_mlx_available = ...
_num2words_available = ...
_tiktoken_available = ...
_blobfile_available = ...
_liger_kernel_available = ...
_spqr_available = ...
_rich_available = ...
_kernels_available = ...
_matplotlib_available = ...
_mistral_common_available = ...
_torch_version = ...
_torch_available = ...
if USE_TORCH in ENV_VARS_TRUE_AND_AUTO_VALUES and USE_TF not in ENV_VARS_TRUE_VALUES: ...
else:
    _torch_available = ...
_tf_version = ...
_tf_available = ...
if FORCE_TF_AVAILABLE in ENV_VARS_TRUE_VALUES:
    _tf_available = ...
_essentia_available = ...
_essentia_version = ...
_pydantic_available = ...
_pydantic_version = ...
_fastapi_available = ...
_fastapi_version = ...
_uvicorn_available = ...
_uvicorn_version = ...
_pretty_midi_available = ...
_pretty_midi_version = ...
ccl_version = ...
_is_ccl_available = ...
ccl_version = ...
_flax_available = ...
if USE_JAX in ENV_VARS_TRUE_AND_AUTO_VALUES: ...
_torch_xla_available = ...
if USE_TORCH_XLA in ENV_VARS_TRUE_VALUES: ...

def is_kenlm_available():  # -> tuple[bool, str] | bool:
    ...
def is_kernels_available():  # -> tuple[bool, str] | bool:
    ...
def is_cv2_available():  # -> bool:
    ...
def is_yt_dlp_available():  # -> bool:
    ...
def is_torch_available():  # -> bool:
    ...
def is_libcst_available():  # -> tuple[bool, str] | bool:
    ...
def is_accelerate_available(min_version: str = ...):  # -> bool:
    ...
def is_torch_accelerator_available():  # -> bool:
    ...
def is_torch_deterministic():  # -> bool:

    ...
def is_triton_available(min_version: str = ...):  # -> bool:
    ...
def is_hadamard_available():  # -> tuple[bool, str] | bool:
    ...
def is_hqq_available(min_version: str = ...):  # -> bool:
    ...
def is_pygments_available():  # -> tuple[bool, str] | bool:
    ...
def get_torch_version():  # -> str:
    ...
def get_torch_major_and_minor_version() -> str: ...
def is_torch_sdpa_available():  # -> bool:
    ...
def is_torch_flex_attn_available():  # -> bool:
    ...
def is_torchvision_available():  # -> bool:
    ...
def is_torchvision_v2_available():  # -> bool:
    ...
def is_galore_torch_available():  # -> tuple[bool, str] | bool:
    ...
def is_apollo_torch_available():  # -> tuple[bool, str] | bool:
    ...
def is_torch_optimi_available():  # -> bool:
    ...
def is_lomo_available():  # -> tuple[bool, str] | bool:
    ...
def is_grokadamw_available():  # -> tuple[bool, str] | bool:
    ...
def is_schedulefree_available(min_version: str = ...):  # -> bool:
    ...
def is_pyctcdecode_available():  # -> tuple[bool, str] | bool:
    ...
def is_librosa_available():  # -> tuple[bool, str] | bool:
    ...
def is_essentia_available():  # -> bool:
    ...
def is_pydantic_available():  # -> bool:
    ...
def is_fastapi_available():  # -> bool:
    ...
def is_uvicorn_available():  # -> bool:
    ...
def is_openai_available():  # -> tuple[bool, str] | bool:
    ...
def is_pretty_midi_available():  # -> bool:
    ...
def is_torch_cuda_available():  # -> bool:
    ...
def is_cuda_platform():  # -> bool:
    ...
def is_rocm_platform():  # -> bool:
    ...
def is_mamba_ssm_available():  # -> tuple[bool, str] | bool:
    ...
def is_mamba_2_ssm_available():  # -> bool:
    ...
def is_causal_conv1d_available():  # -> tuple[bool, str] | bool:
    ...
def is_xlstm_available():  # -> tuple[bool, str] | bool:
    ...
def is_mambapy_available():  # -> tuple[bool, str] | bool:
    ...
def is_torch_mps_available(min_version: str | None = ...):  # -> bool:
    ...
def is_torch_bf16_gpu_available() -> bool: ...
def is_torch_bf16_cpu_available() -> bool: ...
def is_torch_bf16_available():  # -> bool:
    ...
@lru_cache
def is_torch_fp16_available_on_device(device):  # -> bool:
    ...
@lru_cache
def is_torch_bf16_available_on_device(device):  # -> bool:
    ...
def is_torch_tf32_available():  # -> bool:
    ...
def is_torch_fx_available():  # -> bool:
    ...
def is_peft_available():  # -> tuple[bool, str] | bool:
    ...
def is_bs4_available():  # -> bool:
    ...
def is_tf_available():  # -> bool:
    ...
def is_coloredlogs_available():  # -> tuple[bool, str] | bool:
    ...
def is_tf2onnx_available():  # -> tuple[bool, str] | bool:
    ...
def is_onnx_available():  # -> tuple[bool, str] | bool:
    ...
def is_flax_available():  # -> bool:
    ...
def is_flute_available():  # -> bool:
    ...
def is_ftfy_available():  # -> tuple[bool, str] | bool:
    ...
def is_g2p_en_available():  # -> tuple[bool, str] | bool:
    ...
@lru_cache
def is_torch_xla_available(check_is_tpu=..., check_is_gpu=...):  # -> bool:

    ...
@lru_cache
def is_torch_neuroncore_available(check_device=...):  # -> bool:
    ...
@lru_cache
def is_torch_npu_available(check_device=...):  # -> Literal[False]:

    ...
@lru_cache
def is_torch_mlu_available(check_device=...):  # -> Literal[False]:

    ...
@lru_cache
def is_torch_musa_available(check_device=...):  # -> Literal[False]:

    ...
@lru_cache
def is_torch_hpu_available():  # -> bool:

    ...
@lru_cache
def is_habana_gaudi1():  # -> Literal[False]:
    ...
def is_torchdynamo_available():  # -> bool:
    ...
def is_torch_compile_available():  # -> bool:
    ...
def is_torchdynamo_compiling():  # -> bool:
    ...
def is_torchdynamo_exporting():  # -> bool:
    ...
def is_torch_tensorrt_fx_available():  # -> bool:
    ...
def is_datasets_available():  # -> tuple[bool, str] | bool:
    ...
def is_detectron2_available():  # -> tuple[bool, str] | bool:
    ...
def is_rjieba_available():  # -> tuple[bool, str] | bool:
    ...
def is_psutil_available():  # -> tuple[bool, str] | bool:
    ...
def is_py3nvml_available():  # -> tuple[bool, str] | bool:
    ...
def is_sacremoses_available():  # -> tuple[bool, str] | bool:
    ...
def is_apex_available():  # -> tuple[bool, str] | bool:
    ...
def is_aqlm_available():  # -> tuple[bool, str] | bool:
    ...
def is_vptq_available(min_version: str = ...):  # -> bool:
    ...
def is_av_available():  # -> bool:
    ...
def is_decord_available():  # -> bool:
    ...
def is_torchcodec_available():  # -> bool:
    ...
def is_ninja_available():  # -> bool:

    ...
def is_ipex_available(min_version: str = ...):  # -> bool:
    ...
@lru_cache
def is_torch_xpu_available(check_device=...):  # -> bool:

    ...
@lru_cache
def is_bitsandbytes_available(check_library_only=...) -> bool: ...
def is_bitsandbytes_multi_backend_available() -> bool: ...
def is_flash_attn_2_available():  # -> bool:
    ...
@lru_cache
def is_flash_attn_3_available():  # -> bool:
    ...
@lru_cache
def is_flash_attn_greater_or_equal_2_10():  # -> bool:
    ...
@lru_cache
def is_flash_attn_greater_or_equal(library_version: str):  # -> bool:
    ...
@lru_cache
def is_torch_greater_or_equal(library_version: str, accept_dev: bool = ...):  # -> bool:

    ...
@lru_cache
def is_torch_less_or_equal(library_version: str, accept_dev: bool = ...):  # -> bool:

    ...
@lru_cache
def is_huggingface_hub_greater_or_equal(library_version: str, accept_dev: bool = ...):  # -> bool:
    ...
def is_torchdistx_available():  # -> tuple[bool, str] | bool:
    ...
def is_faiss_available():  # -> bool:
    ...
def is_scipy_available():  # -> tuple[bool, str] | bool:
    ...
def is_sklearn_available():  # -> bool:
    ...
def is_sentencepiece_available():  # -> tuple[bool, str] | bool:
    ...
def is_seqio_available():  # -> tuple[bool, str] | bool:
    ...
def is_gguf_available(min_version: str = ...):  # -> bool:
    ...
def is_protobuf_available():  # -> bool:
    ...
def is_fsdp_available(min_version: str = ...):  # -> bool:
    ...
def is_optimum_available():  # -> tuple[bool, str] | bool:
    ...
def is_auto_awq_available():  # -> bool:
    ...
def is_auto_round_available(min_version: str = ...):  # -> bool:
    ...
def is_optimum_quanto_available():  # -> bool:
    ...
def is_quark_available():  # -> tuple[bool, str] | bool:
    ...
def is_fp_quant_available():  # -> bool:
    ...
def is_qutlass_available():  # -> tuple[bool, str] | bool:
    ...
def is_compressed_tensors_available():  # -> bool:
    ...
def is_auto_gptq_available():  # -> tuple[bool, str] | bool:
    ...
def is_gptqmodel_available():  # -> tuple[bool, str] | bool:
    ...
def is_eetq_available():  # -> tuple[bool, str] | bool:
    ...
def is_fbgemm_gpu_available():  # -> tuple[bool, str] | bool:
    ...
def is_levenshtein_available():  # -> tuple[bool, str] | bool:
    ...
def is_optimum_neuron_available():  # -> tuple[bool, str] | bool:
    ...
def is_safetensors_available():  # -> tuple[bool, str] | bool:
    ...
def is_tokenizers_available():  # -> tuple[bool, str] | bool:
    ...
@lru_cache
def is_vision_available():  # -> bool:
    ...
def is_pytesseract_available():  # -> tuple[bool, str] | bool:
    ...
def is_pytest_available():  # -> tuple[bool, str] | bool:
    ...
def is_spacy_available():  # -> tuple[bool, str] | bool:
    ...
def is_tensorflow_text_available():  # -> tuple[bool, str] | bool:
    ...
def is_keras_nlp_available():  # -> tuple[bool, str] | bool:
    ...
def is_in_notebook():  # -> bool:
    ...
def is_pytorch_quantization_available():  # -> tuple[bool, str] | bool:
    ...
def is_tensorflow_probability_available():  # -> tuple[bool, str] | bool:
    ...
def is_pandas_available():  # -> tuple[bool, str] | bool:
    ...
def is_sagemaker_dp_enabled():  # -> bool:
    ...
def is_sagemaker_mp_enabled():  # -> bool:
    ...
def is_training_run_on_sagemaker():  # -> bool:
    ...
def is_soundfile_available():  # -> tuple[bool, str] | bool:
    ...
def is_timm_available():  # -> tuple[bool, str] | bool:
    ...
def is_natten_available():  # -> tuple[bool, str] | bool:
    ...
def is_nltk_available():  # -> tuple[bool, str] | bool:
    ...
def is_torchaudio_available():  # -> tuple[bool, str] | bool:
    ...
def is_torchao_available(min_version: str = ...):  # -> bool:
    ...
def is_speech_available():  # -> tuple[bool, str] | bool:
    ...
def is_spqr_available():  # -> tuple[bool, str] | bool:
    ...
def is_phonemizer_available():  # -> tuple[bool, str] | bool:
    ...
def is_uroman_available():  # -> tuple[bool, str] | bool:
    ...
def torch_only_method(fn):  # -> Callable[..., Any]:
    ...
def is_ccl_available():  # -> bool:
    ...
def is_sudachi_available():  # -> bool:
    ...
def get_sudachi_version():  # -> str:
    ...
def is_sudachi_projection_available():  # -> bool:
    ...
def is_jumanpp_available():  # -> bool:
    ...
def is_cython_available():  # -> bool:
    ...
def is_jieba_available():  # -> tuple[bool, str] | bool:
    ...
def is_jinja_available():  # -> tuple[bool, str] | bool:
    ...
def is_mlx_available():  # -> tuple[bool, str] | bool:
    ...
def is_num2words_available():  # -> tuple[bool, str] | bool:
    ...
def is_tiktoken_available():  # -> tuple[bool, str] | bool:
    ...
def is_liger_kernel_available():  # -> bool:
    ...
def is_rich_available():  # -> tuple[bool, str] | bool:
    ...
def is_matplotlib_available():  # -> tuple[bool, str] | bool:
    ...
def is_mistral_common_available():  # -> tuple[bool, str] | bool:
    ...
def check_torch_load_is_safe():  # -> None:
    ...

AV_IMPORT_ERROR = ...
YT_DLP_IMPORT_ERROR = ...
DECORD_IMPORT_ERROR = ...
TORCHCODEC_IMPORT_ERROR = ...
CV2_IMPORT_ERROR = ...
DATASETS_IMPORT_ERROR = ...
TOKENIZERS_IMPORT_ERROR = ...
SENTENCEPIECE_IMPORT_ERROR = ...
PROTOBUF_IMPORT_ERROR = ...
FAISS_IMPORT_ERROR = ...
PYTORCH_IMPORT_ERROR = ...
TORCHVISION_IMPORT_ERROR = ...
PYTORCH_IMPORT_ERROR_WITH_TF = ...
TF_IMPORT_ERROR_WITH_PYTORCH = ...
BS4_IMPORT_ERROR = ...
SKLEARN_IMPORT_ERROR = ...
TENSORFLOW_IMPORT_ERROR = ...
DETECTRON2_IMPORT_ERROR = ...
FLAX_IMPORT_ERROR = ...
FTFY_IMPORT_ERROR = ...
LEVENSHTEIN_IMPORT_ERROR = ...
G2P_EN_IMPORT_ERROR = ...
PYTORCH_QUANTIZATION_IMPORT_ERROR = ...
TENSORFLOW_PROBABILITY_IMPORT_ERROR = ...
TENSORFLOW_TEXT_IMPORT_ERROR = ...
TORCHAUDIO_IMPORT_ERROR = ...
PANDAS_IMPORT_ERROR = ...
PHONEMIZER_IMPORT_ERROR = ...
UROMAN_IMPORT_ERROR = ...
SACREMOSES_IMPORT_ERROR = ...
SCIPY_IMPORT_ERROR = ...
KERAS_NLP_IMPORT_ERROR = ...
SPEECH_IMPORT_ERROR = ...
TIMM_IMPORT_ERROR = ...
NATTEN_IMPORT_ERROR = ...
NUMEXPR_IMPORT_ERROR = ...
NLTK_IMPORT_ERROR = ...
VISION_IMPORT_ERROR = ...
PYDANTIC_IMPORT_ERROR = ...
FASTAPI_IMPORT_ERROR = ...
UVICORN_IMPORT_ERROR = ...
OPENAI_IMPORT_ERROR = ...
PYTESSERACT_IMPORT_ERROR = ...
PYCTCDECODE_IMPORT_ERROR = ...
ACCELERATE_IMPORT_ERROR = ...
CCL_IMPORT_ERROR = ...
ESSENTIA_IMPORT_ERROR = ...
LIBROSA_IMPORT_ERROR = ...
PRETTY_MIDI_IMPORT_ERROR = ...
CYTHON_IMPORT_ERROR = ...
JIEBA_IMPORT_ERROR = ...
PEFT_IMPORT_ERROR = ...
JINJA_IMPORT_ERROR = ...
RICH_IMPORT_ERROR = ...
MISTRAL_COMMON_IMPORT_ERROR = ...
BACKENDS_MAPPING = ...

def requires_backends(obj, backends):  # -> None:
    ...

class DummyObject(type):
    is_dummy = ...
    def __getattribute__(cls, key):  # -> Any | None:
        ...

def is_torch_fx_proxy(x):  # -> bool:
    ...

type BACKENDS_T = frozenset[str]
type IMPORT_STRUCTURE_T = dict[BACKENDS_T, dict[str, set[str]]]

class _LazyModule(ModuleType):
    def __init__(
        self,
        name: str,
        module_file: str,
        import_structure: IMPORT_STRUCTURE_T,
        module_spec: importlib.machinery.ModuleSpec | None = ...,
        extra_objects: dict[str, object] | None = ...,
        explicit_import_shortcut: dict[str, list[str]] | None = ...,
    ) -> None: ...
    def __dir__(self):  # -> Iterable[str]:
        ...
    def __getattr__(self, name: str) -> Any: ...
    def __reduce__(self):  # -> tuple[type[Self], tuple[str, str | None, IMPORT_STRUCTURE_T]]:
        ...

class OptionalDependencyNotAvailable(BaseException): ...

def direct_transformers_import(path: str, file=...) -> ModuleType: ...

class VersionComparison(Enum):
    EQUAL = ...
    NOT_EQUAL = ...
    GREATER_THAN = ...
    LESS_THAN = ...
    GREATER_THAN_OR_EQUAL = ...
    LESS_THAN_OR_EQUAL = ...
    @staticmethod
    def from_string(version_string: str) -> VersionComparison: ...

@lru_cache
def split_package_version(package_version_str) -> tuple[str, str, str]: ...

class Backend:
    def __init__(self, backend_requirement: str) -> None: ...
    def is_satisfied(self) -> bool: ...
    @property
    def error_message(self):  # -> str:
        ...

def requires(*, backends=...):  # -> Callable[..., Any]:

    ...

BASE_FILE_REQUIREMENTS = ...

def fetch__all__(file_content):  # -> list[Any]:

    ...
@lru_cache
def create_import_structure_from_path(module_path):  # -> dict[Any, Any]:

    ...
def spread_import_structure(nested_import_structure):  # -> dict[Any, Any]:

    ...
@lru_cache
def define_import_structure(module_path: str, prefix: str | None = ...) -> IMPORT_STRUCTURE_T: ...
def clear_import_cache():  # -> None:

    ...
