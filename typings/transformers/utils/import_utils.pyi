"""
This type stub file was generated by pyright.
"""

import importlib.machinery
from enum import Enum
from functools import lru_cache
from types import ModuleType
from typing import Any, Optional, TypeAlias

logger = ...
ENV_VARS_TRUE_VALUES = ...
ENV_VARS_TRUE_AND_AUTO_VALUES = ...
USE_TF = ...
USE_TORCH = ...
USE_JAX = ...
USE_TORCH_XLA = ...
FORCE_TF_AVAILABLE = ...
TORCH_FX_REQUIRED_VERSION = ...
ACCELERATE_MIN_VERSION = ...
SCHEDULEFREE_MIN_VERSION = ...
FSDP_MIN_VERSION = ...
GGUF_MIN_VERSION = ...
XLA_FSDPV2_MIN_VERSION = ...
HQQ_MIN_VERSION = ...
VPTQ_MIN_VERSION = ...
TORCHAO_MIN_VERSION = ...
AUTOROUND_MIN_VERSION = ...
TRITON_MIN_VERSION = ...
_apex_available = ...
_apollo_torch_available = ...
_aqlm_available = ...
_av_available = ...
_decord_available = ...
_torchcodec_available = ...
_libcst_available = ...
_bitsandbytes_available = ...
_eetq_available = ...
_fbgemm_gpu_available = ...
_galore_torch_available = ...
_lomo_available = ...
_grokadamw_available = ...
_torch_optimi_available = ...
_bs4_available = ...
_coloredlogs_available = ...
_cv2_available = ...
_yt_dlp_available = ...
_datasets_available = ...
_detectron2_available = ...
_faiss_available = ...
_faiss_version = ...
_ftfy_available = ...
_g2p_en_available = ...
_hadamard_available = ...
_jieba_available = ...
_jinja_available = ...
_kenlm_available = ...
_keras_nlp_available = ...
_levenshtein_available = ...
_librosa_available = ...
_natten_available = ...
_nltk_available = ...
_onnx_available = ...
_openai_available = ...
_optimum_available = ...
_auto_gptq_available = ...
_gptqmodel_available = ...
_auto_awq_available = ...
_quark_available = ...
_qutlass_available = ...
_is_optimum_quanto_available = ...
_is_optimum_quanto_available = ...
_compressed_tensors_available = ...
_pandas_available = ...
_peft_available = ...
_phonemizer_available = ...
_uroman_available = ...
_psutil_available = ...
_py3nvml_available = ...
_pyctcdecode_available = ...
_pygments_available = ...
_pytesseract_available = ...
_pytest_available = ...
_pytorch_quantization_available = ...
_rjieba_available = ...
_sacremoses_available = ...
_safetensors_available = ...
_scipy_available = ...
_sentencepiece_available = ...
_is_seqio_available = ...
_sklearn_available = ...
if _sklearn_available: ...
_smdistributed_available = ...
_soundfile_available = ...
_spacy_available = ...
_tensorflow_probability_available = ...
_tensorflow_text_available = ...
_tf2onnx_available = ...
_timm_available = ...
_tokenizers_available = ...
_torchaudio_available = ...
_torchdistx_available = ...
_mlx_available = ...
_num2words_available = ...
_tiktoken_available = ...
_blobfile_available = ...
_liger_kernel_available = ...
_spqr_available = ...
_rich_available = ...
_kernels_available = ...
_matplotlib_available = ...
_mistral_common_available = ...
_torch_version = ...
_torch_available = ...
if USE_TORCH in ENV_VARS_TRUE_AND_AUTO_VALUES and USE_TF not in ENV_VARS_TRUE_VALUES: ...
else:
    _torch_available = ...
_tf_version = ...
_tf_available = ...
if FORCE_TF_AVAILABLE in ENV_VARS_TRUE_VALUES:
    _tf_available = ...
else: ...
_essentia_available = ...
_essentia_version = ...
_pydantic_available = ...
_pydantic_version = ...
_fastapi_available = ...
_fastapi_version = ...
_uvicorn_available = ...
_uvicorn_version = ...
_pretty_midi_available = ...
_pretty_midi_version = ...
ccl_version = ...
_is_ccl_available = ...
ccl_version = ...
_flax_available = ...
if USE_JAX in ENV_VARS_TRUE_AND_AUTO_VALUES: ...
_torch_xla_available = ...
if USE_TORCH_XLA in ENV_VARS_TRUE_VALUES: ...

def is_kenlm_available(): ...
def is_kernels_available(): ...
def is_cv2_available(): ...
def is_yt_dlp_available(): ...
def is_torch_available(): ...
def is_libcst_available(): ...
def is_accelerate_available(min_version: str = ...): ...
def is_torch_accelerator_available(): ...
def is_torch_deterministic(): ...
def is_triton_available(min_version: str = ...): ...
def is_hadamard_available(): ...
def is_hqq_available(min_version: str = ...): ...
def is_pygments_available(): ...
def get_torch_version(): ...
def get_torch_major_and_minor_version() -> str: ...
def is_torch_sdpa_available(): ...
def is_torch_flex_attn_available(): ...
def is_torchvision_available(): ...
def is_torchvision_v2_available(): ...
def is_galore_torch_available(): ...
def is_apollo_torch_available(): ...
def is_torch_optimi_available(): ...
def is_lomo_available(): ...
def is_grokadamw_available(): ...
def is_schedulefree_available(min_version: str = ...): ...
def is_pyctcdecode_available(): ...
def is_librosa_available(): ...
def is_essentia_available(): ...
def is_pydantic_available(): ...
def is_fastapi_available(): ...
def is_uvicorn_available(): ...
def is_openai_available(): ...
def is_pretty_midi_available(): ...
def is_torch_cuda_available(): ...
def is_cuda_platform(): ...
def is_rocm_platform(): ...
def is_mamba_ssm_available(): ...
def is_mamba_2_ssm_available(): ...
def is_causal_conv1d_available(): ...
def is_xlstm_available(): ...
def is_mambapy_available(): ...
def is_torch_mps_available(min_version: Optional[str] = ...): ...
def is_torch_bf16_gpu_available() -> bool: ...
def is_torch_bf16_cpu_available() -> bool: ...
def is_torch_bf16_available(): ...
@lru_cache
def is_torch_fp16_available_on_device(device): ...
@lru_cache
def is_torch_bf16_available_on_device(device): ...
def is_torch_tf32_available(): ...
def is_torch_fx_available(): ...
def is_peft_available(): ...
def is_bs4_available(): ...
def is_tf_available(): ...
def is_coloredlogs_available(): ...
def is_tf2onnx_available(): ...
def is_onnx_available(): ...
def is_flax_available(): ...
def is_flute_available(): ...
def is_ftfy_available(): ...
def is_g2p_en_available(): ...
@lru_cache
def is_torch_xla_available(check_is_tpu=..., check_is_gpu=...): ...
@lru_cache
def is_torch_neuroncore_available(check_device=...): ...
@lru_cache
def is_torch_npu_available(check_device=...): ...
@lru_cache
def is_torch_mlu_available(check_device=...): ...
@lru_cache
def is_torch_musa_available(check_device=...): ...
@lru_cache
def is_torch_hpu_available(): ...
@lru_cache
def is_habana_gaudi1(): ...
def is_torchdynamo_available(): ...
def is_torch_compile_available(): ...
def is_torchdynamo_compiling(): ...
def is_torchdynamo_exporting(): ...
def is_torch_tensorrt_fx_available(): ...
def is_datasets_available(): ...
def is_detectron2_available(): ...
def is_rjieba_available(): ...
def is_psutil_available(): ...
def is_py3nvml_available(): ...
def is_sacremoses_available(): ...
def is_apex_available(): ...
def is_aqlm_available(): ...
def is_vptq_available(min_version: str = ...): ...
def is_av_available(): ...
def is_decord_available(): ...
def is_torchcodec_available(): ...
def is_ninja_available(): ...
def is_ipex_available(min_version: str = ...): ...
@lru_cache
def is_torch_xpu_available(check_device=...): ...
@lru_cache
def is_bitsandbytes_available(check_library_only=...) -> bool: ...
def is_bitsandbytes_multi_backend_available() -> bool: ...
def is_flash_attn_2_available(): ...
@lru_cache
def is_flash_attn_3_available(): ...
@lru_cache
def is_flash_attn_greater_or_equal_2_10(): ...
@lru_cache
def is_flash_attn_greater_or_equal(library_version: str): ...
@lru_cache
def is_torch_greater_or_equal(library_version: str, accept_dev: bool = ...): ...
@lru_cache
def is_torch_less_or_equal(library_version: str, accept_dev: bool = ...): ...
@lru_cache
def is_huggingface_hub_greater_or_equal(library_version: str, accept_dev: bool = ...): ...
def is_torchdistx_available(): ...
def is_faiss_available(): ...
def is_scipy_available(): ...
def is_sklearn_available(): ...
def is_sentencepiece_available(): ...
def is_seqio_available(): ...
def is_gguf_available(min_version: str = ...): ...
def is_protobuf_available(): ...
def is_fsdp_available(min_version: str = ...): ...
def is_optimum_available(): ...
def is_auto_awq_available(): ...
def is_auto_round_available(min_version: str = ...): ...
def is_optimum_quanto_available(): ...
def is_quark_available(): ...
def is_fp_quant_available(): ...
def is_qutlass_available(): ...
def is_compressed_tensors_available(): ...
def is_auto_gptq_available(): ...
def is_gptqmodel_available(): ...
def is_eetq_available(): ...
def is_fbgemm_gpu_available(): ...
def is_levenshtein_available(): ...
def is_optimum_neuron_available(): ...
def is_safetensors_available(): ...
def is_tokenizers_available(): ...
@lru_cache
def is_vision_available(): ...
def is_pytesseract_available(): ...
def is_pytest_available(): ...
def is_spacy_available(): ...
def is_tensorflow_text_available(): ...
def is_keras_nlp_available(): ...
def is_in_notebook(): ...
def is_pytorch_quantization_available(): ...
def is_tensorflow_probability_available(): ...
def is_pandas_available(): ...
def is_sagemaker_dp_enabled(): ...
def is_sagemaker_mp_enabled(): ...
def is_training_run_on_sagemaker(): ...
def is_soundfile_available(): ...
def is_timm_available(): ...
def is_natten_available(): ...
def is_nltk_available(): ...
def is_torchaudio_available(): ...
def is_torchao_available(min_version: str = ...): ...
def is_speech_available(): ...
def is_spqr_available(): ...
def is_phonemizer_available(): ...
def is_uroman_available(): ...
def torch_only_method(fn): ...
def is_ccl_available(): ...
def is_sudachi_available(): ...
def get_sudachi_version(): ...
def is_sudachi_projection_available(): ...
def is_jumanpp_available(): ...
def is_cython_available(): ...
def is_jieba_available(): ...
def is_jinja_available(): ...
def is_mlx_available(): ...
def is_num2words_available(): ...
def is_tiktoken_available(): ...
def is_liger_kernel_available(): ...
def is_rich_available(): ...
def is_matplotlib_available(): ...
def is_mistral_common_available(): ...
def check_torch_load_is_safe(): ...

AV_IMPORT_ERROR = ...
YT_DLP_IMPORT_ERROR = ...
DECORD_IMPORT_ERROR = ...
TORCHCODEC_IMPORT_ERROR = ...
CV2_IMPORT_ERROR = ...
DATASETS_IMPORT_ERROR = ...
TOKENIZERS_IMPORT_ERROR = ...
SENTENCEPIECE_IMPORT_ERROR = ...
PROTOBUF_IMPORT_ERROR = ...
FAISS_IMPORT_ERROR = ...
PYTORCH_IMPORT_ERROR = ...
TORCHVISION_IMPORT_ERROR = ...
PYTORCH_IMPORT_ERROR_WITH_TF = ...
TF_IMPORT_ERROR_WITH_PYTORCH = ...
BS4_IMPORT_ERROR = ...
SKLEARN_IMPORT_ERROR = ...
TENSORFLOW_IMPORT_ERROR = ...
DETECTRON2_IMPORT_ERROR = ...
FLAX_IMPORT_ERROR = ...
FTFY_IMPORT_ERROR = ...
LEVENSHTEIN_IMPORT_ERROR = ...
G2P_EN_IMPORT_ERROR = ...
PYTORCH_QUANTIZATION_IMPORT_ERROR = ...
TENSORFLOW_PROBABILITY_IMPORT_ERROR = ...
TENSORFLOW_TEXT_IMPORT_ERROR = ...
TORCHAUDIO_IMPORT_ERROR = ...
PANDAS_IMPORT_ERROR = ...
PHONEMIZER_IMPORT_ERROR = ...
UROMAN_IMPORT_ERROR = ...
SACREMOSES_IMPORT_ERROR = ...
SCIPY_IMPORT_ERROR = ...
KERAS_NLP_IMPORT_ERROR = ...
SPEECH_IMPORT_ERROR = ...
TIMM_IMPORT_ERROR = ...
NATTEN_IMPORT_ERROR = ...
NUMEXPR_IMPORT_ERROR = ...
NLTK_IMPORT_ERROR = ...
VISION_IMPORT_ERROR = ...
PYDANTIC_IMPORT_ERROR = ...
FASTAPI_IMPORT_ERROR = ...
UVICORN_IMPORT_ERROR = ...
OPENAI_IMPORT_ERROR = ...
PYTESSERACT_IMPORT_ERROR = ...
PYCTCDECODE_IMPORT_ERROR = ...
ACCELERATE_IMPORT_ERROR = ...
CCL_IMPORT_ERROR = ...
ESSENTIA_IMPORT_ERROR = ...
LIBROSA_IMPORT_ERROR = ...
PRETTY_MIDI_IMPORT_ERROR = ...
CYTHON_IMPORT_ERROR = ...
JIEBA_IMPORT_ERROR = ...
PEFT_IMPORT_ERROR = ...
JINJA_IMPORT_ERROR = ...
RICH_IMPORT_ERROR = ...
MISTRAL_COMMON_IMPORT_ERROR = ...
BACKENDS_MAPPING = ...

def requires_backends(obj, backends): ...

class DummyObject(type):
    is_dummy = ...
    def __getattribute__(cls, key): ...

def is_torch_fx_proxy(x): ...

BACKENDS_T: TypeAlias = frozenset[str]
IMPORT_STRUCTURE_T: TypeAlias = dict[BACKENDS_T, dict[str, set[str]]]

class _LazyModule(ModuleType):
    def __init__(
        self,
        name: str,
        module_file: str,
        import_structure: IMPORT_STRUCTURE_T,
        module_spec: Optional[importlib.machinery.ModuleSpec] = ...,
        extra_objects: Optional[dict[str, object]] = ...,
        explicit_import_shortcut: Optional[dict[str, list[str]]] = ...,
    ) -> None: ...
    def __dir__(self): ...
    def __getattr__(self, name: str) -> Any: ...
    def __reduce__(self): ...

class OptionalDependencyNotAvailable(BaseException): ...

def direct_transformers_import(path: str, file=...) -> ModuleType: ...

class VersionComparison(Enum):
    EQUAL = ...
    NOT_EQUAL = ...
    GREATER_THAN = ...
    LESS_THAN = ...
    GREATER_THAN_OR_EQUAL = ...
    LESS_THAN_OR_EQUAL = ...
    @staticmethod
    def from_string(version_string: str) -> VersionComparison: ...

@lru_cache
def split_package_version(package_version_str) -> tuple[str, str, str]: ...

class Backend:
    def __init__(self, backend_requirement: str) -> None: ...
    def is_satisfied(self) -> bool: ...
    @property
    def error_message(self): ...

def requires(*, backends=...): ...

BASE_FILE_REQUIREMENTS = ...

def fetch__all__(file_content): ...
@lru_cache
def create_import_structure_from_path(module_path): ...
def spread_import_structure(nested_import_structure): ...
@lru_cache
def define_import_structure(module_path: str, prefix: Optional[str] = ...) -> IMPORT_STRUCTURE_T: ...
def clear_import_cache(): ...
