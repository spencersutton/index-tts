"""
This type stub file was generated by pyright.
"""

import numpy as np
import PIL.Image
import torch
from collections.abc import Iterable
from dataclasses import dataclass
from typing import Callable, Optional, TypeAlias, Union
from .image_transforms import PaddingMode
from .image_utils import ChannelDimension
from .utils import is_torch_available, is_vision_available

if is_vision_available(): ...
if is_torch_available(): ...
logger = ...
VideoInput: TypeAlias = Union[
    list[PIL.Image.Image],
    np.ndarray,
    torch.Tensor,
    list[np.ndarray],
    list[torch.Tensor],
    list[list[PIL.Image.Image]],
    list[list[np.ndarrray]],
    list[list[torch.Tensor]],
]

@dataclass
class VideoMetadata:
    total_num_frames: int
    fps: float
    duration: float
    video_backend: str
    def __getitem__(self, item): ...

def is_valid_video_frame(frame): ...
def is_valid_video(video): ...
def valid_videos(videos): ...
def is_batched_video(videos): ...
def is_scaled_video(video: np.ndarray) -> bool: ...
def convert_pil_frames_to_video(videos: list[VideoInput]) -> list[Union[np.ndarray, torch.Tensor]]: ...
def make_batched_videos(videos) -> list[Union[np.ndarray, torch.Tensor]]: ...
def get_video_size(video: np.ndarray, channel_dim: ChannelDimension = ...) -> tuple[int, int]: ...
def get_uniform_frame_indices(total_num_frames: int, num_frames: Optional[int] = ...): ...
def default_sample_indices_fn(metadata: VideoMetadata, num_frames=..., fps=..., **kwargs): ...
def read_video_opencv(video_path: str, sample_indices_fn: Callable, **kwargs): ...
def read_video_decord(video_path: str, sample_indices_fn: Optional[Callable] = ..., **kwargs): ...
def read_video_pyav(video_path: str, sample_indices_fn: Callable, **kwargs): ...
def read_video_torchvision(video_path: str, sample_indices_fn: Callable, **kwargs): ...
def read_video_torchcodec(video_path: str, sample_indices_fn: Callable, **kwargs): ...

VIDEO_DECODERS = ...

def load_video(
    video: Union[str, VideoInput],
    num_frames: Optional[int] = ...,
    fps: Optional[Union[int, float]] = ...,
    backend: str = ...,
    sample_indices_fn: Optional[Callable] = ...,
    **kwargs,
) -> np.array: ...
def convert_to_rgb(
    video: np.array,
    data_format: Optional[ChannelDimension] = ...,
    input_data_format: Optional[Union[str, ChannelDimension]] = ...,
) -> np.array: ...
def pad(
    video: np.ndarray,
    padding: Union[int, tuple[int, int], Iterable[tuple[int, int]]],
    mode: PaddingMode = ...,
    constant_values: Union[float, Iterable[float]] = ...,
    data_format: Optional[Union[str, ChannelDimension]] = ...,
    input_data_format: Optional[Union[str, ChannelDimension]] = ...,
) -> np.ndarray: ...
def group_videos_by_shape(
    videos: list[torch.Tensor],
) -> tuple[dict[tuple[int, int], list[torch.Tensor]], dict[int, tuple[tuple[int, int], int]]]: ...
def reorder_videos(
    processed_videos: dict[tuple[int, int], torch.Tensor], grouped_videos_index: dict[int, tuple[int, int]]
) -> list[torch.Tensor]: ...
