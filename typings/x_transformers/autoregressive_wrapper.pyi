"""
This type stub file was generated by pyright.
"""

from collections.abc import Callable

import torch
from torch import Tensor
from torch.nn import Module

"""
This type stub file was generated by pyright.
"""

def exists(val): ...
def default(val, d): ...
def identity(t, *args, **kwargs): ...
def join(arr, delimiter=...): ...
def cast_tuple(t, length=...): ...
def eval_decorator(fn): ...
def log(t, eps=...): ...
def gumbel_noise(t): ...
def gumbel_sample(logits, temperature=..., eps=...): ...
def modify_cached_kv(cache, fn): ...
def pad_at_dim(t, pad: tuple[int, int], dim=..., value=...): ...
def align_right(t, lens, pad_id=...): ...
def top_p(logits, thres=...): ...
def top_k(logits, frac_num_tokens=..., k=...): ...
def top_a(logits, min_p_pow=..., min_p_ratio=...): ...
def min_p(logits, min_p=...): ...

FILTER_LOGITS_FN = ...

def contrastive_decode_fn(expert_logits, amateur_logits, alpha=..., beta=...):
    """
    Appendix A Algorithm 2
    https://arxiv.org/abs/2309.09117
    """

class AutoregressiveWrapper(Module):
    def __init__(
        self, net, ignore_index=..., pad_value=..., mask_prob=..., add_attn_z_loss=..., next_embed_loss_weight=...
    ) -> None: ...
    @torch.no_grad()
    @eval_decorator
    def beam_search(
        self,
        prompts,
        seq_len,
        beams=...,
        return_beams_and_scores=...,
        eos_token=...,
        temperature=...,
        stochastic=...,
        prompt_lens: Tensor | None = ...,
        filter_logits_fn: str | Callable = ...,
        restrict_to_max_seq_len=...,
        filter_kwargs: dict = ...,
        cache_kv=...,
        **kwargs,
    ): ...
    @torch.no_grad()
    @eval_decorator
    def generate(
        self,
        prompts: list[Tensor] | Tensor,
        seq_len,
        eos_token=...,
        temperature=...,
        prompt_lens: Tensor | None = ...,
        filter_logits_fn: str | Callable = ...,
        restrict_to_max_seq_len=...,
        amateur_model: Module | tuple[Module] | None = ...,
        filter_kwargs: dict = ...,
        contrastive_decode_kwargs: dict | tuple[dict] = ...,
        cache_kv=...,
        **kwargs,
    ): ...
    def forward(self, x, return_outputs=..., prepend_embeds=..., **kwargs): ...
