import torch
from torch import Tensor
from torch.autograd import Function
from torch.nn import Module
from x_transformers.autoregressive_wrapper import eval_decorator
from x_transformers.x_transformers import TransformerWrapper

"""
This type stub file was generated by pyright.
"""

def exists(v): ...
def default(v, d): ...
def flip(x, dim=..., lens=...): ...

class DetachMultiple(Function):
    @classmethod
    def forward(self, ctx, *tensors): ...
    @classmethod
    def backward(self, ctx, *grads): ...

detach_multiple = ...

class BeliefStateWrapper(Module):
    def __init__(
        self,
        forward_decoder: TransformerWrapper,
        backward_decoder: TransformerWrapper | None = ...,
        train_frac_forward_backward_pairs: float = ...,
        text_head: Module | None = ...,
        backward_ar_loss_weight: float = ...,
        pred_distance=...,
        pred_distance_loss_weight: float = ...,
        cond_on_distance=...,
        cond_on_distance_prob=...,
        max_pred_distance=...,
    ) -> None: ...
    @torch.no_grad()
    @eval_decorator
    def generate_with_suffix_cond(
        self,
        prompts,
        seq_len,
        temperature=...,
        cache_kv=...,
        suffix: Tensor | None = ...,
        filter_logits_fn=...,
        filter_kwargs=...,
        decode_backwards=...,
        **kwargs,
    ): ...
    def forward(self, seq, lens: Tensor | None = ..., loss_weight_by_fb_indices: callable | None = ...): ...
