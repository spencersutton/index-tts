import torch
from torch.nn import Module

"""
This type stub file was generated by pyright.
"""

def exists(v): ...
def default(v, d): ...
def log(t, eps=...): ...
def pack_with_inverse(t, pattern): ...

NAT = ...

def binary_entropy(logits): ...

class BinaryMapper(Module):
    def __init__(self, bits=..., kl_loss_threshold=...) -> None: ...
    def forward(self, logits, temperature=..., straight_through=..., calc_aux_loss=...): ...

class FreeTransformer(Module):
    def __init__(
        self,
        *,
        num_tokens,
        dim,
        dec_head_depth,
        dec_tail_depth,
        max_seq_len,
        enc_depth=...,
        dim_latent=...,
        attn_dim_head=...,
        heads=...,
        latent_bits=...,
        per_token_latents=...,
        kl_loss_threshold=...,
        binary_mapper_kwargs: dict = ...,
        enc_kwargs: dict = ...,
        dec_kwargs: dict = ...,
        kl_loss_weight=...,
        latent_dropout_prob=...,
        pad_id=...,
        **kwargs,
    ) -> None: ...
    @property
    def device(self): ...
    def encode_to_latents(
        self,
        decoder_head_embeds,
        mask=...,
        return_kl_loss=...,
        per_token_latents=...,
    ): ...
    @torch.no_grad()
    def generate(
        self,
        prompts,
        seq_len,
        latents=...,
        filter_logits_fn=...,
        logit_filter_kwargs: dict = ...,
        use_kv_cache=...,
    ): ...
    def forward(self, seq, seq_for_latents=..., return_all_losses=...): ...
